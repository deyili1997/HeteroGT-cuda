{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "105bbf2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Disabling PyTorch because PyTorch >= 2.1 is required but found 1.13.1\n",
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import random\n",
    "from model import SetGNN \n",
    "import pickle\n",
    "from tokenizer import EHRTokenizer\n",
    "from dataset import FinetuneHGDataset, batcher_SetGNN_finetune\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "from train import PHENO_ORDER, train_with_early_stopping\n",
    "from set_seed import set_random_seed\n",
    "import pandas as pd\n",
    "from print_hg import summarize_hypergraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb757cdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89793d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    \"dataset\": \"MIMIC-III\", \n",
    "    \"task\": \"death\",  # options: death, stay, readmission, next_diag_12m\n",
    "    \"special_tokens\":[\"[PAD]\", \"[CLS]\"],\n",
    "    \"predicted_token_type\": [\"diag\", \"med\"],\n",
    "    \"batch_size\": 256,\n",
    "    \"lr\": 1e-3,\n",
    "    \"epochs\": 500,\n",
    "    \"model_name\": \"HG\",\n",
    "    \"early_stop_patience\": 10,\n",
    "    # model hyperparameters\n",
    "    \"level\": \"visit\",  # \"visit\" or \"patient\"\n",
    "    \"hg_all_num_layers\": 3,\n",
    "    \"hg_use_type_embed\": True,\n",
    "    \"MLP_num_layers\": 2,\n",
    "    \"hg_aggregate\": \"mean\",\n",
    "    \"hg_dropout\": 0.0,\n",
    "    \"normtype\": \"all_one\",\n",
    "    \"add_self_loop\": True,\n",
    "    \"hg_normalization\": \"ln\",\n",
    "    \"hg_hidden_size\": 48,\n",
    "    \"PMA\": True,\n",
    "    \"hg_num_heads\": 4,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c32fba6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data_path = f\"/home/lideyi/HeteroGT-cuda/data_process/{args['dataset']}-processed/mimic.pkl\"\n",
    "\n",
    "if args[\"task\"] == \"next_diag_6m\":\n",
    "    finetune_data_path = f\"/home/lideyi/HeteroGT-cuda/data_process/{args['dataset']}-processed/mimic_nextdiag_6m.pkl\"\n",
    "elif args[\"task\"] == \"next_diag_12m\":\n",
    "    finetune_data_path = f\"/home/lideyi/HeteroGT-cuda/data_process/{args['dataset']}-processed/mimic_nextdiag_12m.pkl\"\n",
    "else:\n",
    "    finetune_data_path = f\"/home/lideyi/HeteroGT-cuda/data_process/{args['dataset']}-processed/mimic_downstream.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ab08e48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max admissions per patient: 8\n"
     ]
    }
   ],
   "source": [
    "ehr_full_data = pickle.load(open(full_data_path, 'rb'))\n",
    "diag_sentences = ehr_full_data[\"ICD9_CODE\"].values.tolist()\n",
    "med_sentences = ehr_full_data[\"NDC\"].values.tolist()\n",
    "lab_sentences = [[]]\n",
    "pro_sentences = [[]]\n",
    "age_gender_sentences = [\"[PAD]\"] + [str(c) + \"_\" + gender \\\n",
    "    for c in set(ehr_full_data[\"AGE\"].values.tolist()) for gender in [\"M\", \"F\"]] # PAD token special for age_gender vocabulary\n",
    "max_admissions = ehr_full_data.groupby(\"SUBJECT_ID\")[\"HADM_ID\"].nunique().max()\n",
    "args[\"max_adm_len\"] = max_admissions\n",
    "print(f\"Max admissions per patient: {max_admissions}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42864fb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age and gender vocabulary size: 37\n",
      "Global vocabulary size: 2145\n",
      "Label vocabulary size: 18\n"
     ]
    }
   ],
   "source": [
    "tokenizer = EHRTokenizer(age_gender_sentences, diag_sentences, med_sentences, lab_sentences, \n",
    "                         pro_sentences, special_tokens=args[\"special_tokens\"])\n",
    "args[\"age_gender_vocab_size\"] = tokenizer.token_number(\"age_gender\")\n",
    "args[\"global_vocab_size\"] = len(tokenizer.vocab.id2word)\n",
    "args[\"label_vocab_size\"] = len(PHENO_ORDER)\n",
    "print(f\"Age and gender vocabulary size: {args['age_gender_vocab_size']}\")\n",
    "print(f\"Global vocabulary size: {args['global_vocab_size']}\")\n",
    "print(f\"Label vocabulary size: {args['label_vocab_size']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f7ff21ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, val_data, test_data = pickle.load(open(finetune_data_path, 'rb'))\n",
    "train_data[\"EXP_FLAG\"] = 1\n",
    "val_data[\"EXP_FLAG\"] = 1\n",
    "test_data[\"EXP_FLAG\"] = 1\n",
    "\n",
    "# for transductiove learning, otherwise the graph is too sparse\n",
    "all_exp_ids = pd.concat([\n",
    "    train_data[\"SUBJECT_ID\"],\n",
    "    val_data[\"SUBJECT_ID\"],\n",
    "    test_data[\"SUBJECT_ID\"]\n",
    "]).unique()\n",
    "\n",
    "non_exp_data = ehr_full_data[~ehr_full_data[\"SUBJECT_ID\"].isin(all_exp_ids)].copy(deep = True)\n",
    "non_exp_data[\"EXP_FLAG\"] = 0\n",
    "\n",
    "# concat\n",
    "train_data_full = pd.concat([train_data, non_exp_data], axis = 0)\n",
    "val_data_full = pd.concat([val_data, non_exp_data], axis = 0)\n",
    "test_data_full = pd.concat([test_data, non_exp_data], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "598dd8df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27362 30541 30535\n"
     ]
    }
   ],
   "source": [
    "# output: input_ids (a patient has multiple visits), labels\n",
    "train_dataset = FinetuneHGDataset(train_data_full, tokenizer, token_type=args[\"predicted_token_type\"], task=args[\"task\"], level=args[\"level\"])\n",
    "val_dataset = FinetuneHGDataset(val_data_full, tokenizer, token_type=args[\"predicted_token_type\"], task=args[\"task\"], level=args[\"level\"])\n",
    "test_dataset = FinetuneHGDataset(test_data_full, tokenizer, token_type=args[\"predicted_token_type\"], task=args[\"task\"], level=args[\"level\"])\n",
    "print(len(train_dataset), len(val_dataset), len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "42afdd7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "835 854\n"
     ]
    }
   ],
   "source": [
    "long_adm_seq_crite = 3\n",
    "val_long_seq_idx, test_long_seq_idx = [], []\n",
    "for i in range(len(val_dataset)):\n",
    "    hadm_id = list(val_dataset.records.keys())[i]\n",
    "    exp_flag = val_dataset.exp_flags[hadm_id]\n",
    "    num_adms = len(val_dataset.records[hadm_id])\n",
    "    if num_adms >= long_adm_seq_crite and exp_flag == True:\n",
    "        val_long_seq_idx.append(i)\n",
    "for i in range(len(test_dataset)):\n",
    "    hadm_id = list(test_dataset.records.keys())[i]\n",
    "    exp_flag = test_dataset.exp_flags[hadm_id]\n",
    "    num_adms = len(test_dataset.records[hadm_id])\n",
    "    if num_adms >= long_adm_seq_crite and exp_flag == True:\n",
    "        test_long_seq_idx.append(i)\n",
    "print(len(val_long_seq_idx), len(test_long_seq_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d0769b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_full_graph = True\n",
    "train_batch_size = len(train_dataset) if use_full_graph else args[\"batch_size\"]\n",
    "val_batch_size = len(val_dataset) if use_full_graph else args[\"batch_size\"]\n",
    "test_batch_size = len(test_dataset) if use_full_graph else args[\"batch_size\"]\n",
    "train_dataloader = DataLoader(train_dataset, collate_fn=batcher_SetGNN_finetune(device = device), batch_size = train_batch_size, shuffle = True)\n",
    "val_dataloader = DataLoader(val_dataset, collate_fn=batcher_SetGNN_finetune(device = device), batch_size = val_batch_size, shuffle = False)\n",
    "test_dataloader = DataLoader(test_dataset, collate_fn=batcher_SetGNN_finetune(device = device), batch_size = test_batch_size, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3a3e5d45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(edge_index=[2, 588516], n_x=[1], num_hyperedges=[1], totedges=32434, norm=[588516])\n",
      "torch.Size([27362])\n",
      "torch.Size([27362])\n",
      "torch.Size([3131])\n"
     ]
    }
   ],
   "source": [
    "# exmain HG properties\n",
    "batch = next(iter(train_dataloader))\n",
    "HG_sample, global_node_ids, last_visit_indices, exp_flags, labels = batch\n",
    "print(HG_sample)\n",
    "print(last_visit_indices.shape)\n",
    "print(exp_flags.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "92a62432",
   "metadata": {},
   "outputs": [],
   "source": [
    "if args[\"task\"] in [\"death\", \"stay\", \"readmission\"]:\n",
    "    eval_metric = \"prauc\"\n",
    "    task_type = \"binary\"\n",
    "    loss_fn = F.binary_cross_entropy_with_logits\n",
    "else:\n",
    "    eval_metric = \"prauc\"\n",
    "    task_type = \"l2r\"\n",
    "    loss_fn = lambda x, y: F.binary_cross_entropy_with_logits(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "33afa400",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2746317213, 1181241943, 958682846, 3163119785, 1812140441, 127978094, 939042955, 2340505846, 946785248, 2530876844]\n"
     ]
    }
   ],
   "source": [
    "random.seed(42)\n",
    "seeds = [random.randint(0, 2**32 - 1) for _ in range(8)]\n",
    "print(seeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71af0347",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Random seed set to 2746317213\n",
      "Training with seed: 2746317213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|██████████| 1/1 [00:06<00:00,  6.05s/it]\n",
      "Running inference: 100%|██████████| 1/1 [00:06<00:00,  6.46s/it]\n",
      "Running inference: 100%|██████████| 1/1 [00:06<00:00,  6.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Average Loss: 0.7069\n",
      "Validation: {'precision': 0.2683906199802949, 'recall': 0.9846788450148223, 'f1': 0.4218099171173868, 'auc': 0.5322707686930724, 'prauc': 0.2729564731502202}\n",
      "Test:       {'precision': 0.2864015394479051, 'recall': 0.9889258028738155, 'f1': 0.44416811389985345, 'auc': 0.5283754758482544, 'prauc': 0.28580978378396515}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|██████████| 1/1 [00:05<00:00,  5.40s/it]\n",
      "Running inference: 100%|██████████| 1/1 [00:07<00:00,  7.07s/it]\n",
      "Running inference: 100%|██████████| 1/1 [00:06<00:00,  6.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 002, Average Loss: 0.7008\n",
      "Validation: {'precision': 0.28586723768685607, 'recall': 0.9440188568005656, 'f1': 0.43884399040405847, 'auc': 0.5540362029319155, 'prauc': 0.2848938562047667}\n",
      "Test:       {'precision': 0.3046524160224454, 'recall': 0.9390919158309021, 'f1': 0.46005696090035453, 'auc': 0.5478981183713002, 'prauc': 0.2969665044792387}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|██████████| 1/1 [00:05<00:00,  5.26s/it]\n",
      "Running inference: 100%|██████████| 1/1 [00:06<00:00,  6.68s/it]\n",
      "Running inference: 100%|██████████| 1/1 [00:06<00:00,  6.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 003, Average Loss: 0.6947\n",
      "Validation: {'precision': 0.2971718024476632, 'recall': 0.8296994696474385, 'f1': 0.43760683372209846, 'auc': 0.5647498211927272, 'prauc': 0.2912676831829576}\n",
      "Test:       {'precision': 0.3109421208273956, 'recall': 0.8150609080796509, 'f1': 0.45015290119960555, 'auc': 0.5559521470598228, 'prauc': 0.3025905442375967}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|██████████| 1/1 [00:05<00:00,  5.44s/it]\n",
      "Running inference: 100%|██████████| 1/1 [00:07<00:00,  7.03s/it]\n",
      "Running inference: 100%|██████████| 1/1 [00:06<00:00,  6.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 004, Average Loss: 0.6871\n",
      "Validation: {'precision': 0.3102417821235799, 'recall': 0.6729522687055218, 'f1': 0.4246931901749902, 'auc': 0.5753277771397759, 'prauc': 0.29942442579251816}\n",
      "Test:       {'precision': 0.3190233431705956, 'recall': 0.6583610188224898, 'f1': 0.42978492240396904, 'auc': 0.565780558555125, 'prauc': 0.31019668957088736}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|██████████| 1/1 [00:05<00:00,  5.48s/it]\n",
      "Running inference: 100%|██████████| 1/1 [00:06<00:00,  6.23s/it]\n",
      "Running inference: 100%|██████████| 1/1 [00:07<00:00,  7.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 005, Average Loss: 0.6811\n",
      "Validation: {'precision': 0.32398373983608136, 'recall': 0.469652327634239, 'f1': 0.38344959824574415, 'auc': 0.5872601846054954, 'prauc': 0.3097389821069248}\n",
      "Test:       {'precision': 0.33449747768593524, 'recall': 0.47729789589990423, 'f1': 0.3933378915709, 'auc': 0.5775542175259879, 'prauc': 0.32028077903320507}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|██████████| 1/1 [00:05<00:00,  5.02s/it]\n",
      "Running inference: 100%|██████████| 1/1 [00:06<00:00,  6.60s/it]\n",
      "Running inference: 100%|██████████| 1/1 [00:06<00:00,  6.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 006, Average Loss: 0.6734\n",
      "Validation: {'precision': 0.36216216215889946, 'recall': 0.23688862698740787, 'f1': 0.28642678538405386, 'auc': 0.6008117256182439, 'prauc': 0.3224175847405204}\n",
      "Test:       {'precision': 0.38593622240076914, 'recall': 0.2613510520472794, 'f1': 0.3116540064079978, 'auc': 0.5902966840928933, 'prauc': 0.3325338306861316}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|██████████| 1/1 [00:05<00:00,  5.84s/it]\n",
      "Running inference: 100%|██████████| 1/1 [00:06<00:00,  6.89s/it]\n",
      "Running inference: 100%|██████████| 1/1 [00:06<00:00,  6.90s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 007, Average Loss: 0.6668\n",
      "Validation: {'precision': 0.2990353697653043, 'recall': 0.05480259281051973, 'f1': 0.09262947945294031, 'auc': 0.6146252660712257, 'prauc': 0.33543052777301724}\n",
      "Test:       {'precision': 0.31044776118476275, 'recall': 0.05758582502736664, 'f1': 0.09715086144156891, 'auc': 0.6037671720223139, 'prauc': 0.34595038287962954}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "final_metrics, final_long_seq_metrics = [], []\n",
    "\n",
    "for seed in seeds:\n",
    "    set_random_seed(seed)\n",
    "    print(f\"Training with seed: {seed}\")\n",
    "    \n",
    "    # Initialize model, optimizer, and loss function\n",
    "    model = SetGNN(args, tokenizer).to(device)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=args[\"lr\"])\n",
    "    \n",
    "    best_test_metric, best_test_long_seq_metric = train_with_early_stopping(\n",
    "        model, \n",
    "        train_dataloader, \n",
    "        val_dataloader, \n",
    "        test_dataloader,\n",
    "        optimizer, \n",
    "        loss_fn, \n",
    "        device, \n",
    "        args,\n",
    "        val_long_seq_idx,\n",
    "        test_long_seq_idx,\n",
    "        task_type=task_type,\n",
    "        eval_metric = \"prauc\")\n",
    "    \n",
    "    final_metrics.append(best_test_metric)\n",
    "    final_long_seq_metrics.append(best_test_long_seq_metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9abd8e-1f4b-47bf-bed3-337489bcc79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def topk_avg_performance_formatted(performances, long_seq_performances, k=5):\n",
    "    metrics = [\"f1\", \"auc\", \"prauc\"]\n",
    "    scores = {m: np.array([p[m] for p in performances]) for m in metrics}\n",
    "\n",
    "    # 计算排名（值越大排名越靠前）\n",
    "    ranks = {m: (-scores[m]).argsort().argsort() + 1 for m in metrics}\n",
    "    avg_ranks = np.mean(np.stack([ranks[m] for m in metrics], axis=1), axis=1)\n",
    "\n",
    "    # 选 top-k\n",
    "    topk_idx = np.argsort(avg_ranks)[:k]\n",
    "    final_avg = {m: np.mean([performances[i][m] for i in topk_idx]) for m in performances[0].keys()}\n",
    "    final_std = {m: np.std([performances[i][m] for i in topk_idx], ddof=0) for m in performances[0].keys()}\n",
    "    final_long_seq_avg = {m: np.mean([long_seq_performances[i][m] for i in topk_idx]) for m in long_seq_performances[0].keys()}\n",
    "    final_long_seq_std = {m: np.std([long_seq_performances[i][m] for i in topk_idx], ddof=0) for m in long_seq_performances[0].keys()}\n",
    "\n",
    "    # 打印结果（转百分比，均保留两位小数）\n",
    "    print(\"Final Metrics:\")\n",
    "    for m in performances[0].keys():\n",
    "        mean_val = final_avg[m] * 100\n",
    "        std_val = final_std[m] * 100\n",
    "        print(f\"{m}: {mean_val:.2f} ± {std_val:.2f}\")\n",
    "    print(\"\\nFinal Long Sequence Metrics:\")\n",
    "    for m in long_seq_performances[0].keys():\n",
    "        mean_val = final_long_seq_avg[m] * 100\n",
    "        std_val = final_long_seq_std[m] * 100\n",
    "        print(f\"{m}: {mean_val:.2f} ± {std_val:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e4b92e-35fc-46b9-8f3d-4713b4c71cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_per_class_performance(dfs, col_name=\"prauc\"):\n",
    "    \"\"\"\n",
    "    输入一个 DataFrame 列表，对每个疾病在所有表格的指定列计算 mean ± std 并打印。\n",
    "\n",
    "    参数:\n",
    "        dfs (list[pd.DataFrame]): 多个表格组成的列表\n",
    "        col_name (str): 要计算的指标列名 (默认: \"prauc\")\n",
    "    \"\"\"\n",
    "    # 拼接所有表格\n",
    "    all_values = pd.concat(dfs, axis=0)\n",
    "\n",
    "    # 按疾病分组，计算 mean 和 std\n",
    "    grouped = all_values.groupby(all_values.index)[col_name].agg([\"mean\", \"std\"])\n",
    "\n",
    "    # 打印\n",
    "    for disease, row in grouped.iterrows():\n",
    "        mean_val = row[\"mean\"] * 100\n",
    "        std_val = row[\"std\"] * 100\n",
    "        print(f\"{disease}: {mean_val:.2f} ± {std_val:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a55c99e-6f60-468f-a7a7-1b67f170d599",
   "metadata": {},
   "outputs": [],
   "source": [
    "if task_type == \"binary\":\n",
    "    topk_avg_performance_formatted(final_metrics, final_long_seq_metrics)\n",
    "else:\n",
    "    final_metrics_global = [metrics[\"global\"] for metrics in final_metrics]\n",
    "    final_metrics_per_class = [metrics[\"per_class\"] for metrics in final_metrics]\n",
    "    final_long_seq_metrics_global = [metrics[\"global\"] for metrics in final_long_seq_metrics]\n",
    "    final_long_seq_metrics_per_class = [metrics[\"per_class\"] for metrics in final_long_seq_metrics]\n",
    "    topk_avg_performance_formatted(final_metrics_global, final_long_seq_metrics_global)\n",
    "    print(\"\\nPer-class performance, all patients:\")\n",
    "    print_per_class_performance(final_metrics_per_class, col_name=\"prauc\")\n",
    "    print(\"\\nPer-class performance, long seq:\")\n",
    "    print_per_class_performance(final_long_seq_metrics_per_class, col_name=\"prauc\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "heart-cuda",
   "language": "python",
   "name": "heart-cuda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
