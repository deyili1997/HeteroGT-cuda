{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "105bbf2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Disabling PyTorch because PyTorch >= 2.1 is required but found 1.13.1\n",
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import random\n",
    "from model import SetGNN \n",
    "import pickle\n",
    "from tokenizer import EHRTokenizer\n",
    "from dataset import FinetuneHGDataset, batcher_SetGNN_finetune\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "from train import PHENO_ORDER, train_with_early_stopping\n",
    "from set_seed import set_random_seed\n",
    "import pandas as pd\n",
    "from print_hg import summarize_hypergraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb757cdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89793d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    \"dataset\": \"MIMIC-III\", \n",
    "    \"task\": \"stay\",  # options: death, stay, readmission, next_diag_12m\n",
    "    \"special_tokens\":[\"[PAD]\", \"[CLS]\"],\n",
    "    \"predicted_token_type\": [\"diag\", \"med\"],\n",
    "    \"batch_size\": 256,\n",
    "    \"lr\": 1e-3,\n",
    "    \"epochs\": 500,\n",
    "    \"model_name\": \"HG\",\n",
    "    \"early_stop_patience\": 10,\n",
    "    # model hyperparameters\n",
    "    \"level\": \"visit\",  # \"visit\" or \"patient\"\n",
    "    \"hg_all_num_layers\": 3,\n",
    "    \"hg_use_type_embed\": True,\n",
    "    \"MLP_num_layers\": 2,\n",
    "    \"hg_aggregate\": \"mean\",\n",
    "    \"hg_dropout\": 0.0,\n",
    "    \"normtype\": \"all_one\",\n",
    "    \"add_self_loop\": True,\n",
    "    \"hg_normalization\": \"ln\",\n",
    "    \"hg_hidden_size\": 48,\n",
    "    \"PMA\": True,\n",
    "    \"hg_num_heads\": 4,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c32fba6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data_path = f\"/home/lideyi/HeteroGT-cuda/data_process/{args['dataset']}-processed/mimic.pkl\"\n",
    "\n",
    "if args[\"task\"] == \"next_diag_6m\":\n",
    "    finetune_data_path = f\"/home/lideyi/HeteroGT-cuda/data_process/{args['dataset']}-processed/mimic_nextdiag_6m.pkl\"\n",
    "elif args[\"task\"] == \"next_diag_12m\":\n",
    "    finetune_data_path = f\"/home/lideyi/HeteroGT-cuda/data_process/{args['dataset']}-processed/mimic_nextdiag_12m.pkl\"\n",
    "else:\n",
    "    finetune_data_path = f\"/home/lideyi/HeteroGT-cuda/data_process/{args['dataset']}-processed/mimic_downstream.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ab08e48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max admissions per patient: 8\n"
     ]
    }
   ],
   "source": [
    "ehr_full_data = pickle.load(open(full_data_path, 'rb'))\n",
    "diag_sentences = ehr_full_data[\"ICD9_CODE\"].values.tolist()\n",
    "med_sentences = ehr_full_data[\"NDC\"].values.tolist()\n",
    "lab_sentences = [[]]\n",
    "pro_sentences = [[]]\n",
    "age_gender_sentences = [\"[PAD]\"] + [str(c) + \"_\" + gender \\\n",
    "    for c in set(ehr_full_data[\"AGE\"].values.tolist()) for gender in [\"M\", \"F\"]] # PAD token special for age_gender vocabulary\n",
    "max_admissions = ehr_full_data.groupby(\"SUBJECT_ID\")[\"HADM_ID\"].nunique().max()\n",
    "args[\"max_adm_len\"] = max_admissions\n",
    "print(f\"Max admissions per patient: {max_admissions}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42864fb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age and gender vocabulary size: 37\n",
      "Global vocabulary size: 2145\n",
      "Label vocabulary size: 18\n"
     ]
    }
   ],
   "source": [
    "tokenizer = EHRTokenizer(age_gender_sentences, diag_sentences, med_sentences, lab_sentences, \n",
    "                         pro_sentences, special_tokens=args[\"special_tokens\"])\n",
    "args[\"age_gender_vocab_size\"] = tokenizer.token_number(\"age_gender\")\n",
    "args[\"global_vocab_size\"] = len(tokenizer.vocab.id2word)\n",
    "args[\"label_vocab_size\"] = len(PHENO_ORDER)\n",
    "print(f\"Age and gender vocabulary size: {args['age_gender_vocab_size']}\")\n",
    "print(f\"Global vocabulary size: {args['global_vocab_size']}\")\n",
    "print(f\"Label vocabulary size: {args['label_vocab_size']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f7ff21ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, val_data, test_data = pickle.load(open(finetune_data_path, 'rb'))\n",
    "train_data[\"EXP_FLAG\"] = 1\n",
    "val_data[\"EXP_FLAG\"] = 1\n",
    "test_data[\"EXP_FLAG\"] = 1\n",
    "\n",
    "# for transductiove learning, otherwise the graph is too sparse\n",
    "all_exp_ids = pd.concat([\n",
    "    train_data[\"SUBJECT_ID\"],\n",
    "    val_data[\"SUBJECT_ID\"],\n",
    "    test_data[\"SUBJECT_ID\"]\n",
    "]).unique()\n",
    "\n",
    "non_exp_data = ehr_full_data[~ehr_full_data[\"SUBJECT_ID\"].isin(all_exp_ids)].copy(deep = True)\n",
    "non_exp_data[\"EXP_FLAG\"] = 0\n",
    "\n",
    "# concat\n",
    "train_data_full = pd.concat([train_data, non_exp_data], axis = 0)\n",
    "val_data_full = pd.concat([val_data, non_exp_data], axis = 0)\n",
    "test_data_full = pd.concat([test_data, non_exp_data], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "598dd8df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27362 30541 30535\n"
     ]
    }
   ],
   "source": [
    "# output: input_ids (a patient has multiple visits), labels\n",
    "train_dataset = FinetuneHGDataset(train_data_full, tokenizer, token_type=args[\"predicted_token_type\"], task=args[\"task\"], level=args[\"level\"])\n",
    "val_dataset = FinetuneHGDataset(val_data_full, tokenizer, token_type=args[\"predicted_token_type\"], task=args[\"task\"], level=args[\"level\"])\n",
    "test_dataset = FinetuneHGDataset(test_data_full, tokenizer, token_type=args[\"predicted_token_type\"], task=args[\"task\"], level=args[\"level\"])\n",
    "print(len(train_dataset), len(val_dataset), len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "42afdd7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "835 854\n"
     ]
    }
   ],
   "source": [
    "long_adm_seq_crite = 3\n",
    "val_long_seq_idx, test_long_seq_idx = [], []\n",
    "for i in range(len(val_dataset)):\n",
    "    hadm_id = list(val_dataset.records.keys())[i]\n",
    "    exp_flag = val_dataset.exp_flags[hadm_id]\n",
    "    num_adms = len(val_dataset.records[hadm_id])\n",
    "    if num_adms >= long_adm_seq_crite and exp_flag == True:\n",
    "        val_long_seq_idx.append(i)\n",
    "for i in range(len(test_dataset)):\n",
    "    hadm_id = list(test_dataset.records.keys())[i]\n",
    "    exp_flag = test_dataset.exp_flags[hadm_id]\n",
    "    num_adms = len(test_dataset.records[hadm_id])\n",
    "    if num_adms >= long_adm_seq_crite and exp_flag == True:\n",
    "        test_long_seq_idx.append(i)\n",
    "print(len(val_long_seq_idx), len(test_long_seq_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d0769b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_full_graph = True\n",
    "train_batch_size = len(train_dataset) if use_full_graph else args[\"batch_size\"]\n",
    "val_batch_size = len(val_dataset) if use_full_graph else args[\"batch_size\"]\n",
    "test_batch_size = len(test_dataset) if use_full_graph else args[\"batch_size\"]\n",
    "train_dataloader = DataLoader(train_dataset, collate_fn=batcher_SetGNN_finetune(device = device), batch_size = train_batch_size, shuffle = True)\n",
    "val_dataloader = DataLoader(val_dataset, collate_fn=batcher_SetGNN_finetune(device = device), batch_size = val_batch_size, shuffle = False)\n",
    "test_dataloader = DataLoader(test_dataset, collate_fn=batcher_SetGNN_finetune(device = device), batch_size = test_batch_size, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3a3e5d45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(edge_index=[2, 588516], n_x=[1], num_hyperedges=[1], totedges=32434, norm=[588516])\n",
      "torch.Size([27362])\n",
      "torch.Size([27362])\n",
      "torch.Size([3131])\n"
     ]
    }
   ],
   "source": [
    "# exmain HG properties\n",
    "batch = next(iter(train_dataloader))\n",
    "HG_sample, global_node_ids, last_visit_indices, exp_flags, labels = batch\n",
    "print(HG_sample)\n",
    "print(last_visit_indices.shape)\n",
    "print(exp_flags.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "92a62432",
   "metadata": {},
   "outputs": [],
   "source": [
    "if args[\"task\"] in [\"death\", \"stay\", \"readmission\"]:\n",
    "    eval_metric = \"prauc\"\n",
    "    task_type = \"binary\"\n",
    "    loss_fn = F.binary_cross_entropy_with_logits\n",
    "else:\n",
    "    eval_metric = \"prauc\"\n",
    "    task_type = \"l2r\"\n",
    "    loss_fn = lambda x, y: F.binary_cross_entropy_with_logits(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "33afa400",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2746317213, 1181241943, 958682846, 3163119785, 1812140441, 127978094, 939042955, 2340505846, 946785248, 2530876844]\n"
     ]
    }
   ],
   "source": [
    "random.seed(42)\n",
    "seeds = [random.randint(0, 2**32 - 1) for _ in range(8)]\n",
    "print(seeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "71af0347",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Random seed set to 2746317213\n",
      "Training with seed: 2746317213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|██████████| 1/1 [00:06<00:00,  6.48s/it]\n",
      "Running inference: 100%|██████████| 1/1 [00:06<00:00,  6.37s/it]\n",
      "Running inference: 100%|██████████| 1/1 [00:07<00:00,  7.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Average Loss: 0.6951\n",
      "Validation: {'precision': 0.5120129870121558, 'recall': 0.9890247726529037, 'f1': 0.6747245649761735, 'auc': 0.6190537120502642, 'prauc': 0.598620561041141}\n",
      "Test:       {'precision': 0.5110967114846734, 'recall': 0.9893383505770168, 'f1': 0.6740012772839191, 'auc': 0.6002771364446504, 'prauc': 0.5820235645510048}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|██████████| 1/1 [00:05<00:00,  5.45s/it]\n",
      "Running inference: 100%|██████████| 1/1 [00:07<00:00,  7.27s/it]\n",
      "Running inference: 100%|██████████| 1/1 [00:06<00:00,  6.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 002, Average Loss: 0.6899\n",
      "Validation: {'precision': 0.5336564351094352, 'recall': 0.9322671683884219, 'f1': 0.6787671186558181, 'auc': 0.630481421989981, 'prauc': 0.608324412716509}\n",
      "Test:       {'precision': 0.5278276481139537, 'recall': 0.9219190968926877, 'f1': 0.6713095055859991, 'auc': 0.6088273947311862, 'prauc': 0.5904922519428956}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|██████████| 1/1 [00:05<00:00,  5.30s/it]\n",
      "Running inference: 100%|██████████| 1/1 [00:06<00:00,  6.93s/it]\n",
      "Running inference: 100%|██████████| 1/1 [00:06<00:00,  6.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 003, Average Loss: 0.6861\n",
      "Validation: {'precision': 0.5522651500283344, 'recall': 0.883035434302656, 'f1': 0.6795366748005842, 'auc': 0.6344464093720112, 'prauc': 0.611903202005045}\n",
      "Test:       {'precision': 0.5441934205300353, 'recall': 0.8610849796147347, 'f1': 0.6669095277359367, 'auc': 0.6118767009589041, 'prauc': 0.5934872857313174}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|██████████| 1/1 [00:05<00:00,  5.46s/it]\n",
      "Running inference: 100%|██████████| 1/1 [00:07<00:00,  7.08s/it]\n",
      "Running inference: 100%|██████████| 1/1 [00:07<00:00,  7.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 004, Average Loss: 0.6830\n",
      "Validation: {'precision': 0.5624072896788251, 'recall': 0.8322358105963241, 'f1': 0.6712190139006903, 'auc': 0.6378402046686236, 'prauc': 0.6148499943660005}\n",
      "Test:       {'precision': 0.5534229046693252, 'recall': 0.8137347130736478, 'f1': 0.6587966440752542, 'auc': 0.614741786447897, 'prauc': 0.5958292006962916}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|██████████| 1/1 [00:05<00:00,  5.57s/it]\n",
      "Running inference: 100%|██████████| 1/1 [00:06<00:00,  6.36s/it]\n",
      "Running inference: 100%|██████████| 1/1 [00:07<00:00,  7.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 005, Average Loss: 0.6780\n",
      "Validation: {'precision': 0.5698636262003803, 'recall': 0.7993101285644425, 'f1': 0.6653615195448392, 'auc': 0.6409764862774744, 'prauc': 0.6181587638695761}\n",
      "Test:       {'precision': 0.5591204846296632, 'recall': 0.7814361868899924, 'f1': 0.6518440966267824, 'auc': 0.6178974474354308, 'prauc': 0.5987615745727706}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|██████████| 1/1 [00:05<00:00,  5.03s/it]\n",
      "Running inference: 100%|██████████| 1/1 [00:06<00:00,  6.69s/it]\n",
      "Running inference: 100%|██████████| 1/1 [00:06<00:00,  6.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 006, Average Loss: 0.6754\n",
      "Validation: {'precision': 0.5745320083185244, 'recall': 0.7795547193453134, 'f1': 0.6615220813289375, 'auc': 0.6441725496437258, 'prauc': 0.6224804242474331}\n",
      "Test:       {'precision': 0.5636363636350498, 'recall': 0.7582314205056186, 'f1': 0.6466105045330219, 'auc': 0.6214028258253317, 'prauc': 0.6030895044780165}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|██████████| 1/1 [00:06<00:00,  6.23s/it]\n",
      "Running inference: 100%|██████████| 1/1 [00:07<00:00,  7.06s/it]\n",
      "Running inference: 100%|██████████| 1/1 [00:06<00:00,  6.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 007, Average Loss: 0.6705\n",
      "Validation: {'precision': 0.5813288878290513, 'recall': 0.7654437127602213, 'f1': 0.6608012944960965, 'auc': 0.6470956263967707, 'prauc': 0.6261997426963574}\n",
      "Test:       {'precision': 0.568416007666982, 'recall': 0.7438068359964133, 'f1': 0.6443901064703499, 'auc': 0.6247370198621163, 'prauc': 0.6072457486213239}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|██████████| 1/1 [00:05<00:00,  5.70s/it]\n",
      "Running inference:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_metrics, final_long_seq_metrics = [], []\n",
    "\n",
    "for seed in seeds:\n",
    "    set_random_seed(seed)\n",
    "    print(f\"Training with seed: {seed}\")\n",
    "    \n",
    "    # Initialize model, optimizer, and loss function\n",
    "    model = SetGNN(args, tokenizer).to(device)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=args[\"lr\"])\n",
    "    \n",
    "    best_test_metric, best_test_long_seq_metric = train_with_early_stopping(\n",
    "        model, \n",
    "        train_dataloader, \n",
    "        val_dataloader, \n",
    "        test_dataloader,\n",
    "        optimizer, \n",
    "        loss_fn, \n",
    "        device, \n",
    "        args,\n",
    "        val_long_seq_idx,\n",
    "        test_long_seq_idx,\n",
    "        task_type=task_type,\n",
    "        eval_metric = \"prauc\")\n",
    "    \n",
    "    final_metrics.append(best_test_metric)\n",
    "    final_long_seq_metrics.append(best_test_long_seq_metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9abd8e-1f4b-47bf-bed3-337489bcc79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def topk_avg_performance_formatted(performances, long_seq_performances, k=5):\n",
    "    metrics = [\"f1\", \"auc\", \"prauc\"]\n",
    "    scores = {m: np.array([p[m] for p in performances]) for m in metrics}\n",
    "\n",
    "    # 计算排名（值越大排名越靠前）\n",
    "    ranks = {m: (-scores[m]).argsort().argsort() + 1 for m in metrics}\n",
    "    avg_ranks = np.mean(np.stack([ranks[m] for m in metrics], axis=1), axis=1)\n",
    "\n",
    "    # 选 top-k\n",
    "    topk_idx = np.argsort(avg_ranks)[:k]\n",
    "    final_avg = {m: np.mean([performances[i][m] for i in topk_idx]) for m in performances[0].keys()}\n",
    "    final_std = {m: np.std([performances[i][m] for i in topk_idx], ddof=0) for m in performances[0].keys()}\n",
    "    final_long_seq_avg = {m: np.mean([long_seq_performances[i][m] for i in topk_idx]) for m in long_seq_performances[0].keys()}\n",
    "    final_long_seq_std = {m: np.std([long_seq_performances[i][m] for i in topk_idx], ddof=0) for m in long_seq_performances[0].keys()}\n",
    "\n",
    "    # 打印结果（转百分比，均保留两位小数）\n",
    "    print(\"Final Metrics:\")\n",
    "    for m in performances[0].keys():\n",
    "        mean_val = final_avg[m] * 100\n",
    "        std_val = final_std[m] * 100\n",
    "        print(f\"{m}: {mean_val:.2f} ± {std_val:.2f}\")\n",
    "    print(\"\\nFinal Long Sequence Metrics:\")\n",
    "    for m in long_seq_performances[0].keys():\n",
    "        mean_val = final_long_seq_avg[m] * 100\n",
    "        std_val = final_long_seq_std[m] * 100\n",
    "        print(f\"{m}: {mean_val:.2f} ± {std_val:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e4b92e-35fc-46b9-8f3d-4713b4c71cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_per_class_performance(dfs, col_name=\"prauc\"):\n",
    "    \"\"\"\n",
    "    输入一个 DataFrame 列表，对每个疾病在所有表格的指定列计算 mean ± std 并打印。\n",
    "\n",
    "    参数:\n",
    "        dfs (list[pd.DataFrame]): 多个表格组成的列表\n",
    "        col_name (str): 要计算的指标列名 (默认: \"prauc\")\n",
    "    \"\"\"\n",
    "    # 拼接所有表格\n",
    "    all_values = pd.concat(dfs, axis=0)\n",
    "\n",
    "    # 按疾病分组，计算 mean 和 std\n",
    "    grouped = all_values.groupby(all_values.index)[col_name].agg([\"mean\", \"std\"])\n",
    "\n",
    "    # 打印\n",
    "    for disease, row in grouped.iterrows():\n",
    "        mean_val = row[\"mean\"] * 100\n",
    "        std_val = row[\"std\"] * 100\n",
    "        print(f\"{disease}: {mean_val:.2f} ± {std_val:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a55c99e-6f60-468f-a7a7-1b67f170d599",
   "metadata": {},
   "outputs": [],
   "source": [
    "if task_type == \"binary\":\n",
    "    topk_avg_performance_formatted(final_metrics, final_long_seq_metrics)\n",
    "else:\n",
    "    final_metrics_global = [metrics[\"global\"] for metrics in final_metrics]\n",
    "    final_metrics_per_class = [metrics[\"per_class\"] for metrics in final_metrics]\n",
    "    final_long_seq_metrics_global = [metrics[\"global\"] for metrics in final_long_seq_metrics]\n",
    "    final_long_seq_metrics_per_class = [metrics[\"per_class\"] for metrics in final_long_seq_metrics]\n",
    "    topk_avg_performance_formatted(final_metrics_global, final_long_seq_metrics_global)\n",
    "    print(\"\\nPer-class performance, all patients:\")\n",
    "    print_per_class_performance(final_metrics_per_class, col_name=\"prauc\")\n",
    "    print(\"\\nPer-class performance, long seq:\")\n",
    "    print_per_class_performance(final_long_seq_metrics_per_class, col_name=\"prauc\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "heart-cuda",
   "language": "python",
   "name": "heart-cuda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
