{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "105bbf2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Disabling PyTorch because PyTorch >= 2.1 is required but found 1.13.1\n",
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import random\n",
    "from model import SetGNN \n",
    "import pickle\n",
    "from tokenizer import EHRTokenizer\n",
    "from dataset import FinetuneHGDataset, batcher_SetGNN_finetune\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "from train import PHENO_ORDER, train_with_early_stopping\n",
    "from set_seed import set_random_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb757cdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89793d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    \"dataset\": \"MIMIC-III\", \n",
    "    \"task\": \"stay\",  # options: death, stay, readmission, next_diag_6m, next_diag_12m\n",
    "    \"special_tokens\":[\"[PAD]\", \"[CLS]\"],\n",
    "    \"predicted_token_type\": [\"diag\", \"med\", \"lab\", \"pro\"],\n",
    "    \"batch_size\": 256,\n",
    "    \"lr\": 1e-3,\n",
    "    \"epochs\": 500,\n",
    "    \"model_name\": \"HG\",\n",
    "    \"early_stop_patience\": 10,\n",
    "    # model hyperparameters\n",
    "    \"level\": \"visit\",  # \"visit\" or \"patient\"\n",
    "    \"hg_all_num_layers\": 3,\n",
    "    \"hg_use_type_embed\": True,\n",
    "    \"MLP_num_layers\": 2,\n",
    "    \"hg_aggregate\": \"mean\",\n",
    "    \"hg_dropout\": 0.0,\n",
    "    \"normtype\": \"all_one\",\n",
    "    \"add_self_loop\": True,\n",
    "    \"hg_normalization\": \"ln\",\n",
    "    \"hg_hidden_size\": 128,\n",
    "    \"PMA\": True,\n",
    "    \"hg_num_heads\": 4,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c32fba6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data_path = f\"/home/lideyi/HeteroGT-cuda/data_process/{args['dataset']}-processed/mimic.pkl\"\n",
    "\n",
    "if args[\"task\"] == \"next_diag_6m\":\n",
    "    finetune_data_path = f\"/home/lideyi/HeteroGT-cuda/data_process/{args['dataset']}-processed/mimic_nextdiag_6m.pkl\"\n",
    "elif args[\"task\"] == \"next_diag_12m\":\n",
    "    finetune_data_path = f\"/home/lideyi/HeteroGT-cuda/data_process/{args['dataset']}-processed/mimic_nextdiag_12m.pkl\"\n",
    "else:\n",
    "    finetune_data_path = f\"/home/lideyi/HeteroGT-cuda/data_process/{args['dataset']}-processed/mimic_downstream.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ab08e48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max admissions per patient: 8\n"
     ]
    }
   ],
   "source": [
    "ehr_full_data = pickle.load(open(full_data_path, 'rb'))\n",
    "diag_sentences = ehr_full_data[\"ICD9_CODE\"].values.tolist()\n",
    "med_sentences = ehr_full_data[\"NDC\"].values.tolist()\n",
    "lab_sentences = ehr_full_data[\"LAB_TEST\"].values.tolist()\n",
    "pro_sentences = ehr_full_data[\"PRO_CODE\"].values.tolist()\n",
    "age_gender_sentences = [\"[PAD]\"] + [str(c) + \"_\" + gender \\\n",
    "    for c in set(ehr_full_data[\"AGE\"].values.tolist()) for gender in [\"M\", \"F\"]] # PAD token special for age_gender vocabulary\n",
    "max_admissions = ehr_full_data.groupby(\"SUBJECT_ID\")[\"HADM_ID\"].nunique().max()\n",
    "args[\"max_adm_len\"] = max_admissions\n",
    "print(f\"Max admissions per patient: {max_admissions}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42864fb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age and gender vocabulary size: 37\n",
      "Global vocabulary size: 4446\n",
      "Label vocabulary size: 18\n"
     ]
    }
   ],
   "source": [
    "tokenizer = EHRTokenizer(age_gender_sentences, diag_sentences, med_sentences, lab_sentences, \n",
    "                         pro_sentences, special_tokens=args[\"special_tokens\"])\n",
    "args[\"age_gender_vocab_size\"] = tokenizer.token_number(\"age_gender\")\n",
    "args[\"global_vocab_size\"] = len(tokenizer.vocab.id2word)\n",
    "args[\"label_vocab_size\"] = len(PHENO_ORDER)\n",
    "print(f\"Age and gender vocabulary size: {args['age_gender_vocab_size']}\")\n",
    "print(f\"Global vocabulary size: {args['global_vocab_size']}\")\n",
    "print(f\"Label vocabulary size: {args['label_vocab_size']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f7ff21ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3131 6310 6304\n"
     ]
    }
   ],
   "source": [
    "train_data, val_data, test_data = pickle.load(open(finetune_data_path, 'rb'))\n",
    "\n",
    "# output: input_ids (a patient has multiple visits), labels\n",
    "train_dataset = FinetuneHGDataset(train_data, tokenizer, token_type=args[\"predicted_token_type\"], task=args[\"task\"], level=args[\"level\"])\n",
    "val_dataset = FinetuneHGDataset(val_data, tokenizer, token_type=args[\"predicted_token_type\"], task=args[\"task\"], level=args[\"level\"])\n",
    "test_dataset = FinetuneHGDataset(test_data, tokenizer, token_type=args[\"predicted_token_type\"], task=args[\"task\"], level=args[\"level\"])\n",
    "print(len(train_dataset), len(val_dataset), len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42afdd7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "835 854\n"
     ]
    }
   ],
   "source": [
    "long_adm_seq_crite = 3\n",
    "val_long_seq_idx, test_long_seq_idx = [], []\n",
    "for i in range(len(val_dataset)):\n",
    "    hadm_id = list(val_dataset.records.keys())[i]\n",
    "    num_adms = len(val_dataset.records[hadm_id])\n",
    "    if num_adms >= long_adm_seq_crite:\n",
    "        val_long_seq_idx.append(i)\n",
    "for i in range(len(test_dataset)):\n",
    "    hadm_id = list(test_dataset.records.keys())[i]\n",
    "    num_adms = len(test_dataset.records[hadm_id])\n",
    "    if num_adms >= long_adm_seq_crite:\n",
    "        test_long_seq_idx.append(i)\n",
    "print(len(val_long_seq_idx), len(test_long_seq_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d0769b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_full_graph = True\n",
    "train_batch_size = len(train_dataset) if use_full_graph else args[\"batch_size\"]\n",
    "val_batch_size = len(val_dataset) if use_full_graph else args[\"batch_size\"]\n",
    "test_batch_size = len(test_dataset) if use_full_graph else args[\"batch_size\"]\n",
    "train_dataloader = DataLoader(train_dataset, collate_fn=batcher_SetGNN_finetune(device = device), batch_size = train_batch_size, shuffle = True)\n",
    "val_dataloader = DataLoader(val_dataset, collate_fn=batcher_SetGNN_finetune(device = device), batch_size = val_batch_size, shuffle = False)\n",
    "test_dataloader = DataLoader(test_dataset, collate_fn=batcher_SetGNN_finetune(device = device), batch_size = test_batch_size, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "92a62432",
   "metadata": {},
   "outputs": [],
   "source": [
    "if args[\"task\"] in [\"death\", \"stay\", \"readmission\"]:\n",
    "    eval_metric = \"prauc\"\n",
    "    task_type = \"binary\"\n",
    "    loss_fn = F.binary_cross_entropy_with_logits\n",
    "else:\n",
    "    eval_metric = \"prauc\"\n",
    "    task_type = \"l2r\"\n",
    "    loss_fn = lambda x, y: F.binary_cross_entropy_with_logits(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "33afa400",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2746317213, 1181241943, 958682846, 3163119785, 1812140441]\n"
     ]
    }
   ],
   "source": [
    "random.seed(42)\n",
    "seeds = [random.randint(0, 2**32 - 1) for _ in range(15)]\n",
    "print(seeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71af0347",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Random seed set to 2746317213\n",
      "Training with seed: 2746317213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|██████████| 1/1 [00:01<00:00,  1.83s/it]\n",
      "Running inference: 100%|██████████| 1/1 [00:02<00:00,  2.07s/it]\n",
      "Running inference: 100%|██████████| 1/1 [00:02<00:00,  2.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Average Loss: 0.6931\n",
      "Validation: {'precision': 0.5712560386456182, 'recall': 0.593289432422097, 'f1': 0.5820642928003377, 'auc': 0.6148730582106527, 'prauc': 0.6205900020904922}\n",
      "Test:       {'precision': 0.5843568196490486, 'recall': 0.5669488867965916, 'f1': 0.5755212428108661, 'auc': 0.621691740317212, 'prauc': 0.6234289136370958}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|██████████| 1/1 [00:00<00:00,  1.43it/s]\n",
      "Running inference: 100%|██████████| 1/1 [00:02<00:00,  2.34s/it]\n",
      "Running inference: 100%|██████████| 1/1 [00:02<00:00,  2.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 002, Average Loss: 0.6846\n",
      "Validation: {'precision': 0.5633187772911294, 'recall': 0.6876763875801578, 'f1': 0.6193165722857281, 'auc': 0.6227541023598322, 'prauc': 0.6264130328323974}\n",
      "Test:       {'precision': 0.5691250330410544, 'recall': 0.6751332706156314, 'f1': 0.6176133054189166, 'auc': 0.635294277530053, 'prauc': 0.6402119544969695}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|██████████| 1/1 [00:01<00:00,  1.01s/it]\n",
      "Running inference:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "final_metrics, final_long_seq_metrics = [], []\n",
    "\n",
    "for seed in seeds:\n",
    "    set_random_seed(seed)\n",
    "    print(f\"Training with seed: {seed}\")\n",
    "    \n",
    "    # Initialize model, optimizer, and loss function\n",
    "    model = SetGNN(args, tokenizer).to(device)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=args[\"lr\"])\n",
    "    \n",
    "    best_test_metric, best_test_long_seq_metric = train_with_early_stopping(\n",
    "        model, \n",
    "        train_dataloader, \n",
    "        val_dataloader, \n",
    "        test_dataloader,\n",
    "        optimizer, \n",
    "        loss_fn, \n",
    "        device, \n",
    "        args,\n",
    "        val_long_seq_idx,\n",
    "        test_long_seq_idx,\n",
    "        task_type=task_type,\n",
    "        eval_metric = \"f1\")\n",
    "    \n",
    "    final_metrics.append(best_test_metric)\n",
    "    final_long_seq_metrics.append(best_test_long_seq_metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f57c40-0abf-4a16-8806-cadd794d1c02",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def topk_avg_performance_formatted(performances, long_seq_performances, k=5):\n",
    "    metrics = [\"f1\", \"auc\", \"prauc\"]\n",
    "    scores = {m: np.array([p[m] for p in performances]) for m in metrics}\n",
    "\n",
    "    # 计算排名（值越大排名越靠前）\n",
    "    ranks = {m: (-scores[m]).argsort().argsort() + 1 for m in metrics}\n",
    "    avg_ranks = np.mean(np.stack([ranks[m] for m in metrics], axis=1), axis=1)\n",
    "\n",
    "    # 选 top-k\n",
    "    topk_idx = np.argsort(avg_ranks)[:k]\n",
    "    final_avg = {m: np.mean([performances[i][m] for i in topk_idx]) for m in performances[0].keys()}\n",
    "    final_std = {m: np.std([performances[i][m] for i in topk_idx], ddof=0) for m in performances[0].keys()}\n",
    "    final_long_seq_avg = {m: np.mean([long_seq_performances[i][m] for i in topk_idx]) for m in long_seq_performances[0].keys()}\n",
    "    final_long_seq_std = {m: np.std([long_seq_performances[i][m] for i in topk_idx], ddof=0) for m in long_seq_performances[0].keys()}\n",
    "\n",
    "    # 打印结果（转百分比，均保留两位小数）\n",
    "    print(\"Final Metrics:\")\n",
    "    for m in performances[0].keys():\n",
    "        mean_val = final_avg[m] * 100\n",
    "        std_val = final_std[m] * 100\n",
    "        print(f\"{m}: {mean_val:.2f} ± {std_val:.2f}\")\n",
    "    print(\"\\nFinal Long Sequence Metrics:\")\n",
    "    for m in long_seq_performances[0].keys():\n",
    "        mean_val = final_long_seq_avg[m] * 100\n",
    "        std_val = final_long_seq_std[m] * 100\n",
    "        print(f\"{m}: {mean_val:.2f} ± {std_val:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f127fc-b5f0-44ab-b9bb-3b321913ef4d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def print_per_class_performance(dfs, col_name=\"prauc\"):\n",
    "    \"\"\"\n",
    "    输入一个 DataFrame 列表，对每个疾病在所有表格的指定列计算 mean ± std 并打印。\n",
    "\n",
    "    参数:\n",
    "        dfs (list[pd.DataFrame]): 多个表格组成的列表\n",
    "        col_name (str): 要计算的指标列名 (默认: \"prauc\")\n",
    "    \"\"\"\n",
    "    # 拼接所有表格\n",
    "    all_values = pd.concat(dfs, axis=0)\n",
    "\n",
    "    # 按疾病分组，计算 mean 和 std\n",
    "    grouped = all_values.groupby(all_values.index)[col_name].agg([\"mean\", \"std\"])\n",
    "\n",
    "    # 打印\n",
    "    for disease, row in grouped.iterrows():\n",
    "        mean_val = row[\"mean\"] * 100\n",
    "        std_val = row[\"std\"] * 100\n",
    "        print(f\"{disease}: {mean_val:.2f} ± {std_val:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de561b29-f604-4efd-9b0a-7ac7848dbb93",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if task_type == \"binary\":\n",
    "    topk_avg_performance_formatted(final_metrics, final_long_seq_metrics)\n",
    "else:\n",
    "    final_metrics_global = [metrics[\"global\"] for metrics in final_metrics]\n",
    "    final_metrics_per_class = [metrics[\"per_class\"] for metrics in final_metrics]\n",
    "    final_long_seq_metrics_global = [metrics[\"global\"] for metrics in final_long_seq_metrics]\n",
    "    final_long_seq_metrics_per_class = [metrics[\"per_class\"] for metrics in final_long_seq_metrics]\n",
    "    topk_avg_performance_formatted(final_metrics_global, final_long_seq_metrics_global)\n",
    "    print(\"\\nPer-class performance, all patients:\")\n",
    "    print_per_class_performance(final_metrics_per_class, col_name=\"prauc\")\n",
    "    print(\"\\nPer-class performance, long seq:\")\n",
    "    print_per_class_performance(final_long_seq_metrics_per_class, col_name=\"prauc\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "heart-cuda",
   "language": "python",
   "name": "heart-cuda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
