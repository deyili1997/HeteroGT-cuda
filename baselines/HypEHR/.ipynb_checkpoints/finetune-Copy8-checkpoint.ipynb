{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "105bbf2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Disabling PyTorch because PyTorch >= 2.1 is required but found 1.13.1\n",
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import random\n",
    "from model import SetGNN \n",
    "import pickle\n",
    "from tokenizer import EHRTokenizer\n",
    "from dataset import FinetuneHGDataset, batcher_SetGNN_finetune\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "from train import PHENO_ORDER, train_with_early_stopping\n",
    "from set_seed import set_random_seed\n",
    "import pandas as pd\n",
    "from print_hg import summarize_hypergraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb757cdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89793d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    \"dataset\": \"MIMIC-IV\", \n",
    "    \"task\": \"next_diag_12m\",  # options: death, stay, readmission, next_diag_12m\n",
    "    \"special_tokens\":[\"[PAD]\", \"[CLS]\"],\n",
    "    \"predicted_token_type\": [\"diag\", \"med\"],\n",
    "    \"batch_size\": 256,\n",
    "    \"lr\": 1e-3,\n",
    "    \"epochs\": 500,\n",
    "    \"model_name\": \"HG\",\n",
    "    \"early_stop_patience\": 30,\n",
    "    # model hyperparameters\n",
    "    \"level\": \"visit\",  # \"visit\" or \"patient\"\n",
    "    \"hg_all_num_layers\": 3,\n",
    "    \"hg_use_type_embed\": True,\n",
    "    \"MLP_num_layers\": 2,\n",
    "    \"hg_aggregate\": \"mean\",\n",
    "    \"hg_dropout\": 0.0,\n",
    "    \"normtype\": \"all_one\",\n",
    "    \"add_self_loop\": True,\n",
    "    \"hg_normalization\": \"ln\",\n",
    "    \"hg_hidden_size\": 48,\n",
    "    \"PMA\": True,\n",
    "    \"hg_num_heads\": 4,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c32fba6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data_path = f\"/home/lideyi/HeteroGT-cuda/data_process/{args['dataset']}-processed/mimic.pkl\"\n",
    "\n",
    "if args[\"task\"] == \"next_diag_6m\":\n",
    "    finetune_data_path = f\"/home/lideyi/HeteroGT-cuda/data_process/{args['dataset']}-processed/mimic_nextdiag_6m.pkl\"\n",
    "elif args[\"task\"] == \"next_diag_12m\":\n",
    "    finetune_data_path = f\"/home/lideyi/HeteroGT-cuda/data_process/{args['dataset']}-processed/mimic_nextdiag_12m.pkl\"\n",
    "else:\n",
    "    finetune_data_path = f\"/home/lideyi/HeteroGT-cuda/data_process/{args['dataset']}-processed/mimic_downstream.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ab08e48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max admissions per patient: 8\n"
     ]
    }
   ],
   "source": [
    "ehr_full_data = pickle.load(open(full_data_path, 'rb'))\n",
    "diag_sentences = ehr_full_data[\"ICD9_CODE\"].values.tolist()\n",
    "med_sentences = ehr_full_data[\"NDC\"].values.tolist()\n",
    "lab_sentences = [[]]\n",
    "pro_sentences = [[]]\n",
    "age_gender_sentences = [\"[PAD]\"] + [str(c) + \"_\" + gender \\\n",
    "    for c in set(ehr_full_data[\"AGE\"].values.tolist()) for gender in [\"M\", \"F\"]] # PAD token special for age_gender vocabulary\n",
    "max_admissions = ehr_full_data.groupby(\"SUBJECT_ID\")[\"HADM_ID\"].nunique().max()\n",
    "args[\"max_adm_len\"] = max_admissions\n",
    "print(f\"Max admissions per patient: {max_admissions}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42864fb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age and gender vocabulary size: 41\n",
      "Global vocabulary size: 2125\n",
      "Label vocabulary size: 18\n"
     ]
    }
   ],
   "source": [
    "tokenizer = EHRTokenizer(age_gender_sentences, diag_sentences, med_sentences, lab_sentences, \n",
    "                         pro_sentences, special_tokens=args[\"special_tokens\"])\n",
    "args[\"age_gender_vocab_size\"] = tokenizer.token_number(\"age_gender\")\n",
    "args[\"global_vocab_size\"] = len(tokenizer.vocab.id2word)\n",
    "args[\"label_vocab_size\"] = len(PHENO_ORDER)\n",
    "print(f\"Age and gender vocabulary size: {args['age_gender_vocab_size']}\")\n",
    "print(f\"Global vocabulary size: {args['global_vocab_size']}\")\n",
    "print(f\"Label vocabulary size: {args['label_vocab_size']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f7ff21ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, val_data, test_data = pickle.load(open(finetune_data_path, 'rb'))\n",
    "train_data[\"EXP_FLAG\"] = 1\n",
    "val_data[\"EXP_FLAG\"] = 1\n",
    "test_data[\"EXP_FLAG\"] = 1\n",
    "\n",
    "# for transductiove learning, otherwise the graph is too sparse\n",
    "all_exp_ids = pd.concat([\n",
    "    train_data[\"SUBJECT_ID\"],\n",
    "    val_data[\"SUBJECT_ID\"],\n",
    "    test_data[\"SUBJECT_ID\"]\n",
    "]).unique()\n",
    "\n",
    "non_exp_data = ehr_full_data[~ehr_full_data[\"SUBJECT_ID\"].isin(all_exp_ids)].copy(deep = True)\n",
    "non_exp_data[\"EXP_FLAG\"] = 0\n",
    "\n",
    "# concat\n",
    "train_data_full = pd.concat([train_data, non_exp_data], axis = 0)\n",
    "val_data_full = pd.concat([val_data, non_exp_data], axis = 0)\n",
    "test_data_full = pd.concat([test_data, non_exp_data], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "598dd8df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60335 58531 58547\n"
     ]
    }
   ],
   "source": [
    "# output: input_ids (a patient has multiple visits), labels\n",
    "train_dataset = FinetuneHGDataset(train_data_full, tokenizer, token_type=args[\"predicted_token_type\"], task=args[\"task\"], level=args[\"level\"])\n",
    "val_dataset = FinetuneHGDataset(val_data_full, tokenizer, token_type=args[\"predicted_token_type\"], task=args[\"task\"], level=args[\"level\"])\n",
    "test_dataset = FinetuneHGDataset(test_data_full, tokenizer, token_type=args[\"predicted_token_type\"], task=args[\"task\"], level=args[\"level\"])\n",
    "print(len(train_dataset), len(val_dataset), len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "42afdd7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "857 876\n"
     ]
    }
   ],
   "source": [
    "long_adm_seq_crite = 3\n",
    "val_long_seq_idx, test_long_seq_idx = [], []\n",
    "for i in range(len(val_dataset)):\n",
    "    hadm_id = list(val_dataset.records.keys())[i]\n",
    "    exp_flag = val_dataset.exp_flags[hadm_id]\n",
    "    num_adms = len(val_dataset.records[hadm_id])\n",
    "    if num_adms >= long_adm_seq_crite and exp_flag == True:\n",
    "        val_long_seq_idx.append(i)\n",
    "for i in range(len(test_dataset)):\n",
    "    hadm_id = list(test_dataset.records.keys())[i]\n",
    "    exp_flag = test_dataset.exp_flags[hadm_id]\n",
    "    num_adms = len(test_dataset.records[hadm_id])\n",
    "    if num_adms >= long_adm_seq_crite and exp_flag == True:\n",
    "        test_long_seq_idx.append(i)\n",
    "print(len(val_long_seq_idx), len(test_long_seq_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d0769b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_full_graph = True\n",
    "train_batch_size = len(train_dataset) if use_full_graph else args[\"batch_size\"]\n",
    "val_batch_size = len(val_dataset) if use_full_graph else args[\"batch_size\"]\n",
    "test_batch_size = len(test_dataset) if use_full_graph else args[\"batch_size\"]\n",
    "train_dataloader = DataLoader(train_dataset, collate_fn=batcher_SetGNN_finetune(device = device), batch_size = train_batch_size, shuffle = True)\n",
    "val_dataloader = DataLoader(val_dataset, collate_fn=batcher_SetGNN_finetune(device = device), batch_size = val_batch_size, shuffle = False)\n",
    "test_dataloader = DataLoader(test_dataset, collate_fn=batcher_SetGNN_finetune(device = device), batch_size = test_batch_size, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3a3e5d45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(edge_index=[2, 1000264], n_x=[1], num_hyperedges=[1], totedges=71696, norm=[1000264])\n",
      "torch.Size([60335])\n",
      "torch.Size([60335])\n",
      "torch.Size([6850, 18])\n"
     ]
    }
   ],
   "source": [
    "# exmain HG properties\n",
    "batch = next(iter(train_dataloader))\n",
    "HG_sample, global_node_ids, last_visit_indices, exp_flags, labels = batch\n",
    "print(HG_sample)\n",
    "print(last_visit_indices.shape)\n",
    "print(exp_flags.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "92a62432",
   "metadata": {},
   "outputs": [],
   "source": [
    "if args[\"task\"] in [\"death\", \"stay\", \"readmission\"]:\n",
    "    eval_metric = \"prauc\"\n",
    "    task_type = \"binary\"\n",
    "    loss_fn = F.binary_cross_entropy_with_logits\n",
    "else:\n",
    "    eval_metric = \"prauc\"\n",
    "    task_type = \"l2r\"\n",
    "    loss_fn = lambda x, y: F.binary_cross_entropy_with_logits(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "33afa400",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2746317213, 1181241943, 958682846, 3163119785, 1812140441, 127978094, 939042955, 2340505846, 946785248, 2530876844]\n"
     ]
    }
   ],
   "source": [
    "random.seed(42)\n",
    "seeds = [random.randint(0, 2**32 - 1) for _ in range(10)]\n",
    "print(seeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "71af0347",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Random seed set to 2746317213\n",
      "Training with seed: 2746317213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|██████████| 1/1 [00:22<00:00, 22.29s/it]\n",
      "Running inference: 100%|██████████| 1/1 [00:18<00:00, 18.85s/it]\n",
      "Running inference: 100%|██████████| 1/1 [00:18<00:00, 18.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Average Loss: 0.6863\n",
      "Validation: {'precision': 0.10366406781673583, 'recall': 0.25914031279845684, 'f1': 0.08013712231521239, 'auc': 0.5135758866441147, 'prauc': 0.17692234681673347}\n",
      "Test:       {'precision': 0.10538291738754278, 'recall': 0.2559599746974518, 'f1': 0.08145564303255233, 'auc': 0.5101969502745288, 'prauc': 0.17453400461474822}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|██████████| 1/1 [00:20<00:00, 20.48s/it]\n",
      "Running inference: 100%|██████████| 1/1 [00:18<00:00, 18.73s/it]\n",
      "Running inference: 100%|██████████| 1/1 [00:19<00:00, 19.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 002, Average Loss: 0.6814\n",
      "Validation: {'precision': 0.11327106874166643, 'recall': 0.21769092849662106, 'f1': 0.06545164063178846, 'auc': 0.5176031042330407, 'prauc': 0.18450901223280936}\n",
      "Test:       {'precision': 0.11088718613537132, 'recall': 0.21364600454773985, 'f1': 0.06622512590128055, 'auc': 0.5117680349809688, 'prauc': 0.1811991959506321}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|██████████| 1/1 [00:20<00:00, 20.72s/it]\n",
      "Running inference: 100%|██████████| 1/1 [00:19<00:00, 19.05s/it]\n",
      "Running inference: 100%|██████████| 1/1 [00:19<00:00, 19.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 003, Average Loss: 0.6764\n",
      "Validation: {'precision': 0.11349610777347152, 'recall': 0.16492422562642553, 'f1': 0.04946731454432464, 'auc': 0.5199743074582769, 'prauc': 0.1896784193022142}\n",
      "Test:       {'precision': 0.09756450773079346, 'recall': 0.16634903999977474, 'f1': 0.05000483517843063, 'auc': 0.5122372407805297, 'prauc': 0.18626388281370765}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|██████████| 1/1 [00:19<00:00, 19.72s/it]\n",
      "Running inference: 100%|██████████| 1/1 [00:18<00:00, 18.81s/it]\n",
      "Running inference: 100%|██████████| 1/1 [00:19<00:00, 19.78s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 004, Average Loss: 0.6721\n",
      "Validation: {'precision': 0.11279357473671163, 'recall': 0.10785019978420102, 'f1': 0.03809578012562328, 'auc': 0.5204927639394796, 'prauc': 0.19270994197571056}\n",
      "Test:       {'precision': 0.08698537613604333, 'recall': 0.10299703158040963, 'f1': 0.036749342466333816, 'auc': 0.5121813552680774, 'prauc': 0.1890954875172981}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:   0%|          | 0/1 [00:16<?, ?it/s]\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_metrics, final_long_seq_metrics = [], []\n",
    "\n",
    "for seed in seeds:\n",
    "    set_random_seed(seed)\n",
    "    print(f\"Training with seed: {seed}\")\n",
    "    \n",
    "    # Initialize model, optimizer, and loss function\n",
    "    model = SetGNN(args, tokenizer).to(device)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=args[\"lr\"])\n",
    "    \n",
    "    best_test_metric, best_test_long_seq_metric = train_with_early_stopping(\n",
    "        model, \n",
    "        train_dataloader, \n",
    "        val_dataloader, \n",
    "        test_dataloader,\n",
    "        optimizer, \n",
    "        loss_fn, \n",
    "        device, \n",
    "        args,\n",
    "        val_long_seq_idx,\n",
    "        test_long_seq_idx,\n",
    "        task_type=task_type,\n",
    "        eval_metric = \"prauc\")\n",
    "    \n",
    "    final_metrics.append(best_test_metric)\n",
    "    final_long_seq_metrics.append(best_test_long_seq_metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9abd8e-1f4b-47bf-bed3-337489bcc79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def topk_avg_performance_formatted(performances, long_seq_performances, k=2):\n",
    "    metrics = [\"f1\", \"auc\", \"prauc\"]\n",
    "    scores = {m: np.array([p[m] for p in performances]) for m in metrics}\n",
    "\n",
    "    # 计算排名（值越大排名越靠前）\n",
    "    ranks = {m: (-scores[m]).argsort().argsort() + 1 for m in metrics}\n",
    "    avg_ranks = np.mean(np.stack([ranks[m] for m in metrics], axis=1), axis=1)\n",
    "\n",
    "    # 选 top-k\n",
    "    topk_idx = np.argsort(avg_ranks)[:k]\n",
    "    final_avg = {m: np.mean([performances[i][m] for i in topk_idx]) for m in performances[0].keys()}\n",
    "    final_std = {m: np.std([performances[i][m] for i in topk_idx], ddof=0) for m in performances[0].keys()}\n",
    "    final_long_seq_avg = {m: np.mean([long_seq_performances[i][m] for i in topk_idx]) for m in long_seq_performances[0].keys()}\n",
    "    final_long_seq_std = {m: np.std([long_seq_performances[i][m] for i in topk_idx], ddof=0) for m in long_seq_performances[0].keys()}\n",
    "\n",
    "    # 打印结果（转百分比，均保留两位小数）\n",
    "    print(\"Final Metrics:\")\n",
    "    for m in performances[0].keys():\n",
    "        mean_val = final_avg[m] * 100\n",
    "        std_val = final_std[m] * 100\n",
    "        print(f\"{m}: {mean_val:.2f} ± {std_val:.2f}\")\n",
    "    print(\"\\nFinal Long Sequence Metrics:\")\n",
    "    for m in long_seq_performances[0].keys():\n",
    "        mean_val = final_long_seq_avg[m] * 100\n",
    "        std_val = final_long_seq_std[m] * 100\n",
    "        print(f\"{m}: {mean_val:.2f} ± {std_val:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e4b92e-35fc-46b9-8f3d-4713b4c71cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_per_class_performance(dfs, col_name=\"prauc\"):\n",
    "    \"\"\"\n",
    "    输入一个 DataFrame 列表，对每个疾病在所有表格的指定列计算 mean ± std 并打印。\n",
    "\n",
    "    参数:\n",
    "        dfs (list[pd.DataFrame]): 多个表格组成的列表\n",
    "        col_name (str): 要计算的指标列名 (默认: \"prauc\")\n",
    "    \"\"\"\n",
    "    # 拼接所有表格\n",
    "    all_values = pd.concat(dfs, axis=0)\n",
    "\n",
    "    # 按疾病分组，计算 mean 和 std\n",
    "    grouped = all_values.groupby(all_values.index)[col_name].agg([\"mean\", \"std\"])\n",
    "\n",
    "    # 打印\n",
    "    for disease, row in grouped.iterrows():\n",
    "        mean_val = row[\"mean\"] * 100\n",
    "        std_val = row[\"std\"] * 100\n",
    "        print(f\"{disease}: {mean_val:.2f} ± {std_val:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a55c99e-6f60-468f-a7a7-1b67f170d599",
   "metadata": {},
   "outputs": [],
   "source": [
    "if task_type == \"binary\":\n",
    "    topk_avg_performance_formatted(final_metrics, final_long_seq_metrics)\n",
    "else:\n",
    "    final_metrics_global = [metrics[\"global\"] for metrics in final_metrics]\n",
    "    final_metrics_per_class = [metrics[\"per_class\"] for metrics in final_metrics]\n",
    "    final_long_seq_metrics_global = [metrics[\"global\"] for metrics in final_long_seq_metrics]\n",
    "    final_long_seq_metrics_per_class = [metrics[\"per_class\"] for metrics in final_long_seq_metrics]\n",
    "    topk_avg_performance_formatted(final_metrics_global, final_long_seq_metrics_global)\n",
    "    print(\"\\nPer-class performance, all patients:\")\n",
    "    print_per_class_performance(final_metrics_per_class, col_name=\"prauc\")\n",
    "    print(\"\\nPer-class performance, long seq:\")\n",
    "    print_per_class_performance(final_long_seq_metrics_per_class, col_name=\"prauc\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "heart-cuda",
   "language": "python",
   "name": "heart-cuda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
