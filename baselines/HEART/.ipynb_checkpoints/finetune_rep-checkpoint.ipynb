{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9bb1634",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Disabling PyTorch because PyTorch >= 2.1 is required but found 1.13.1\n",
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n"
     ]
    }
   ],
   "source": [
    "from set_seed_utils import set_random_seed\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pickle\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "from token_utils_rep import EHRTokenizer\n",
    "from dataset_utils_rep import HBERTFinetuneEHRDataset, batcher, UniqueIDSampler\n",
    "from HEART_rep import HBERT_Finetune\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import roc_auc_score, auc, precision_recall_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79dce127",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a26547b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate(model, dataloader, device, task_type=\"binary\"):\n",
    "    model.eval()\n",
    "    predicted_scores, gt_labels = [], []\n",
    "    # gt_labels is ground truth labels, predicted_scores is the output logits\n",
    "    for _, batch in enumerate(tqdm(dataloader, desc=\"Running inference\")):                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          \n",
    "        batch = [x.to(device) if isinstance(x, torch.Tensor) else x for x in batch]\n",
    "        labels = batch[-1]\n",
    "        output_logits = model(*batch[:-1])\n",
    "        predicted_scores.append(output_logits)\n",
    "        gt_labels.append(labels)\n",
    "    \n",
    "    if task_type == \"binary\":\n",
    "        # standard binary classification evaluation\n",
    "        predicted_scores = torch.cat(predicted_scores, dim=0).view(-1)\n",
    "        gt_labels = torch.cat(gt_labels, dim=0).view(-1).cpu().numpy()\n",
    "        scores = predicted_scores.cpu().numpy()      \n",
    "    #   The threshold should be 0 because:\n",
    "\t# \tYour model outputs logits, not probabilities. logit > 0 ≡ probability > 0.5\n",
    "        predicted_labels = (predicted_scores > 0).float().cpu().numpy()\n",
    "\n",
    "        precision = (predicted_labels * gt_labels).sum() / (predicted_labels.sum() + 1e-8)\n",
    "        recall = (predicted_labels * gt_labels).sum() / (gt_labels.sum() + 1e-8)\n",
    "        f1 = 2 * precision * recall / (precision + recall + 1e-8)\n",
    "        roc_auc = roc_auc_score(gt_labels, scores)\n",
    "        precision_curve, recall_curve, _ = precision_recall_curve(gt_labels, scores)\n",
    "        pr_auc = auc(recall_curve, precision_curve)\n",
    "\n",
    "        return {\"precision\":precision, \"recall\":recall, \"f1\":f1, \"auc\":roc_auc, \"prauc\":pr_auc}\n",
    "    else:\n",
    "        # multi-label classification evaluation\n",
    "        predicted_scores = torch.cat(predicted_scores, dim=0).cpu()  # [B, num of diagnosis code]\n",
    "        gt_labels = torch.cat(gt_labels, dim=0).cpu()\n",
    "\n",
    "        ave_f1, ave_auc, ave_prauc, ave_recall, ave_precision = [], [], [], [], []\n",
    "        # Iterates over each sample in the batch\n",
    "        for i in range(predicted_scores.size(0)):\n",
    "            # .clone() is used to safely copy tensors (not strictly necessary here unless you’re modifying them later).\n",
    "            scores, labels = predicted_scores[i].squeeze().clone(), gt_labels[i].squeeze().clone()\n",
    "            # Converts logits to predicted binary labels.\n",
    "            # Since no sigmoid is applied, logit > 0 implies probability > 0.5.\n",
    "            predicted_labels = (scores > 0).float().cpu().numpy()\n",
    "            labels = labels.float().cpu().numpy()\n",
    "            precision = (predicted_labels * labels).sum() / (predicted_labels.sum() + 1e-8)\n",
    "            recall = (predicted_labels * labels).sum() / (labels.sum() + 1e-8)\n",
    "            ave_f1.append(2 * precision * recall / (precision + recall + 1e-8))\n",
    "            ave_auc.append(roc_auc_score(labels, scores))\n",
    "            precision_curve, recall_curve, _ = precision_recall_curve(labels, scores)\n",
    "            ave_prauc.append(auc(recall_curve, precision_curve))\n",
    "            ave_recall.append(recall)\n",
    "            ave_precision.append(precision)\n",
    "\n",
    "        ave_f1, ave_auc, ave_prauc, ave_recall, ave_precision = np.mean(ave_f1), np.mean(ave_auc), np.mean(ave_prauc), np.mean(ave_recall), np.mean(ave_precision)\n",
    "        return {\"recall\":ave_recall, \"precision\":ave_precision, \"f1\":ave_f1, \"auc\":ave_auc, \"prauc\":ave_prauc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57efbc7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    \"seed\": 0,\n",
    "    \"dataset\": \"MIMIC-IV\", \n",
    "    \"task\": \"death\",  # options: death, stay, readmission, next_diag_6m, next_diag_12m\n",
    "    \"encoder\": \"hi_edge\",  # options: hi_edge, hi_node, hi_edge_node\n",
    "    \"batch_size\": 4,\n",
    "    \"eval_batch_size\": 4,\n",
    "    \"pretrain_mask_rate\": 0.7,\n",
    "    \"pretrain_anomaly_rate\": 0.05,\n",
    "    \"pretrain_anomaly_loss_weight\": 1,\n",
    "    \"pretrain_pos_weight\": 1,\n",
    "    \"lr\": 1e-4,\n",
    "    \"epochs\": 50,\n",
    "    \"num_hidden_layers\": 5,\n",
    "    \"num_attention_heads\": 6,\n",
    "    \"attention_probs_dropout_prob\": 0.2,\n",
    "    \"hidden_dropout_prob\": 0.2,\n",
    "    \"edge_hidden_size\": 32,\n",
    "    \"hidden_size\": 288,  # must be divisible by num_attention_heads\n",
    "    \"intermediate_size\": 288,\n",
    "    \"save_model\": True,\n",
    "    \"gat\": \"dotattn\",\n",
    "    \"gnn_n_heads\": 1,\n",
    "    \"gnn_temp\": 1,\n",
    "    \"diag_med_emb\": \"tree\",  # simple, tree\n",
    "    \"early_stop_patience\": 5,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1141f507",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain-HBERT-MIMIC-IV-hi_edge-0.7-0.05-1-288-32-5-6-0.2-0.2-288-dotattn-1-1-tree\n"
     ]
    }
   ],
   "source": [
    "exp_name = \"Pretrain-HBERT\" \\\n",
    "    + \"-\" + str(args[\"dataset\"]) \\\n",
    "    + \"-\" + str(args[\"encoder\"]) \\\n",
    "    + \"-\" + str(args[\"pretrain_mask_rate\"]) \\\n",
    "    + \"-\" + str(args[\"pretrain_anomaly_rate\"]) \\\n",
    "    + \"-\" + str(args[\"pretrain_anomaly_loss_weight\"]) \\\n",
    "    + \"-\" + str(args[\"hidden_size\"]) \\\n",
    "    + \"-\" + str(args[\"edge_hidden_size\"]) \\\n",
    "    + \"-\" + str(args[\"num_hidden_layers\"]) \\\n",
    "    + \"-\" + str(args[\"num_attention_heads\"]) \\\n",
    "    + \"-\" + str(args[\"attention_probs_dropout_prob\"]) \\\n",
    "    + \"-\" + str(args[\"hidden_dropout_prob\"]) \\\n",
    "    + \"-\" + str(args[\"intermediate_size\"]) \\\n",
    "    + \"-\" + str(args[\"gat\"]) \\\n",
    "    + \"-\" + str(args[\"gnn_n_heads\"]) \\\n",
    "    + \"-\" + str(args[\"gnn_temp\"]) \\\n",
    "    + \"-\" + str(args[\"diag_med_emb\"])\n",
    "print(exp_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9bdd4429",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_weight_path = \"./pretrained_models/\" + exp_name + f\"/pretrained_model.pt\"\n",
    "finetune_exp_name = f\"Finetune-{args['task']}-\" + exp_name\n",
    "save_path = \"./saved_model/\" + finetune_exp_name\n",
    "if args[\"save_model\"] and not os.path.exists(save_path):\n",
    "    os.makedirs(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "61606813",
   "metadata": {},
   "outputs": [],
   "source": [
    "args[\"predicted_token_type\"] = [\"diag\", \"med\", \"pro\", \"lab\"]\n",
    "args[\"special_tokens\"] = (\"[PAD]\", \"[CLS]\", \"[SEP]\", \"[MASK0]\", \"[MASK1]\", \"[MASK2]\", \"[MASK3]\")\n",
    "args[\"max_visit_size\"] = 15\n",
    "\n",
    "full_data_path = f\"/home/lideyi/HeteroGT-cuda/data_process/{args['dataset']}-processed/mimic.pkl\"\n",
    "\n",
    "if args[\"task\"] == \"next_diag_6m\":\n",
    "    finetune_data_path = f\"/home/lideyi/HeteroGT-cuda/data_process/{args['dataset']}-processed/mimic_nextdiag_6m.pkl\"\n",
    "elif args[\"task\"] == \"next_diag_12m\":\n",
    "    finetune_data_path = f\"/home/lideyi/HeteroGT-cuda/data_process/{args['dataset']}-processed/mimic_nextdiag_12m.pkl\"\n",
    "else:\n",
    "    finetune_data_path = f\"/home/lideyi/HeteroGT-cuda/data_process/{args['dataset']}-processed/mimic_downstream.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e814ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ehr_data = pickle.load(open(full_data_path, 'rb'))\n",
    "diag_sentences = ehr_data[\"ICD9_CODE\"].values.tolist()\n",
    "med_sentences = ehr_data[\"NDC\"].values.tolist()\n",
    "lab_sentences = ehr_data[\"LAB_TEST\"].values.tolist()\n",
    "pro_sentences = ehr_data[\"PRO_CODE\"].values.tolist()\n",
    "gender_set = [[\"M\"], [\"F\"]]\n",
    "age_gender_set = [[str(c) + \"_\" + gender] for c in set(ehr_data[\"AGE\"].values.tolist()) for gender in [\"M\", \"F\"]]\n",
    "age_set = [[c] for c in set(ehr_data[\"AGE\"].values.tolist())]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "24b8a841",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = EHRTokenizer(diag_sentences, med_sentences, lab_sentences, \n",
    "                         pro_sentences, gender_set, age_set, age_gender_set, special_tokens=args[\"special_tokens\"])\n",
    "tokenizer.build_tree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8e4fbbca",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, val_data, test_data = pickle.load(open(finetune_data_path, 'rb'))\n",
    "\n",
    "train_dataset = HBERTFinetuneEHRDataset(\n",
    "    train_data, tokenizer, \n",
    "    token_type=args[\"predicted_token_type\"], \n",
    "    task=args[\"task\"]\n",
    ")\n",
    "\n",
    "val_dataset = HBERTFinetuneEHRDataset(\n",
    "    val_data, tokenizer, \n",
    "    token_type=args[\"predicted_token_type\"], \n",
    "    task=args[\"task\"]\n",
    ")\n",
    "\n",
    "test_dataset = HBERTFinetuneEHRDataset(\n",
    "    test_data, tokenizer, \n",
    "    token_type=args[\"predicted_token_type\"], \n",
    "    task=args[\"task\"]\n",
    ")\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_sampler=UniqueIDSampler(train_dataset.get_ids(), batch_size=args[\"batch_size\"]),\n",
    "    collate_fn=batcher(pad_id=tokenizer.vocab.word2id[\"[PAD]\"], is_train=False), \n",
    ")\n",
    "\n",
    "val_dataloader = DataLoader(\n",
    "    val_dataset, \n",
    "    batch_sampler=UniqueIDSampler(val_dataset.get_ids(), batch_size=args[\"batch_size\"]),\n",
    "    collate_fn=batcher(pad_id=tokenizer.vocab.word2id[\"[PAD]\"], is_train=False), \n",
    ")\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset, \n",
    "    batch_sampler=UniqueIDSampler(test_dataset.get_ids(), batch_size=args[\"eval_batch_size\"]),\n",
    "    collate_fn=batcher(pad_id=tokenizer.vocab.word2id[\"[PAD]\"], is_train=False),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "31b61a20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([14, 74])\n",
      "input_types shape: torch.Size([14, 74])\n",
      "visit_positions shape: torch.Size([14])\n",
      "labeled_batch_idx shape: 8\n",
      "labels shape: torch.Size([8, 1])\n"
     ]
    }
   ],
   "source": [
    "# examine a batch\n",
    "batch = next(iter(train_dataloader))  # 取第一个 batch\n",
    "input_ids, input_types, edge_index, visit_positions, labeled_batch_idx, labels = batch\n",
    "\n",
    "# 打印每个张量的形状\n",
    "print(\"input_ids shape:\", input_ids.shape)\n",
    "print(\"input_types shape:\", input_types.shape)\n",
    "print(\"visit_positions shape:\", visit_positions.shape)\n",
    "print(\"labeled_batch_idx shape:\", len(labeled_batch_idx)) # it is a list\n",
    "print(\"labels shape:\", labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e9bb1712",
   "metadata": {},
   "outputs": [],
   "source": [
    "args[\"vocab_size\"] = len(args[\"special_tokens\"]) + \\\n",
    "                     len(tokenizer.diag_voc.id2word) + \\\n",
    "                     len(tokenizer.pro_voc.id2word) + \\\n",
    "                     len(tokenizer.med_voc.id2word) + \\\n",
    "                     len(tokenizer.lab_voc.id2word) + \\\n",
    "                     len(tokenizer.age_voc.id2word) + \\\n",
    "                     len(tokenizer.gender_voc.id2word) + \\\n",
    "                     len(tokenizer.age_gender_voc.id2word)\n",
    "args[\"label_vocab_size\"] = len(tokenizer.diag_voc.id2word)  # only for diagnosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d5df929a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if args[\"task\"] in [\"death\", \"stay\", \"readmission\"]:\n",
    "    eval_metric = \"f1\"\n",
    "    task_type = \"binary\"\n",
    "    loss_fn = F.binary_cross_entropy_with_logits\n",
    "else:\n",
    "    eval_metric = \"prauc\"\n",
    "    task_type = \"l2r\"\n",
    "    loss_fn = lambda x, y: F.binary_cross_entropy_with_logits(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "338d945c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_with_early_stopping(model, \n",
    "                              train_dataloader, \n",
    "                              val_dataloader, \n",
    "                              test_dataloader,\n",
    "                              optimizer, \n",
    "                              loss_fn, \n",
    "                              device, \n",
    "                              args,\n",
    "                              task_type=\"binary\", \n",
    "                              eval_metric=\"f1\"):\n",
    "    best_score = 0.\n",
    "    best_val_metric = None\n",
    "    best_test_metric = None\n",
    "    epochs_no_improve = 0\n",
    "\n",
    "    for epoch in range(1, 1 + args[\"epochs\"]):\n",
    "        model.train()\n",
    "        ave_loss = 0.\n",
    "\n",
    "        for step, batch in enumerate(tqdm(train_dataloader, desc=\"Training Batches\")):\n",
    "            batch = [x.to(device) if isinstance(x, torch.Tensor) else x for x in batch]\n",
    "\n",
    "            labels = batch[-1].float()\n",
    "            output_logits = model(*batch[:-1])\n",
    "            \n",
    "            loss = loss_fn(output_logits.view(-1), labels.view(-1))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            ave_loss += loss.item()\n",
    "            \n",
    "\n",
    "        ave_loss /= (step + 1)\n",
    "\n",
    "        # Evaluation\n",
    "        val_metric = evaluate(model, val_dataloader, device, task_type=task_type)\n",
    "        test_metric = evaluate(model, test_dataloader, device, task_type=task_type)\n",
    "\n",
    "        # Logging\n",
    "        print(f\"Epoch: {epoch:03d}, Average Loss: {ave_loss:.4f}\")\n",
    "        print(f\"Validation: {val_metric}\")\n",
    "        print(f\"Test:       {test_metric}\")\n",
    "\n",
    "        # Check for improvement\n",
    "        current_score = val_metric[eval_metric]\n",
    "        if current_score > best_score:\n",
    "            best_score = current_score\n",
    "            best_val_metric = val_metric\n",
    "            best_test_metric = test_metric\n",
    "            epochs_no_improve = 0\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "\n",
    "        # Early stopping check\n",
    "        if epochs_no_improve >= args[\"early_stop_patience\"]:\n",
    "            print(f\"\\nEarly stopping triggered after {epoch} epochs (no improvement for {args['early_stop_patience']} epochs).\")\n",
    "            break\n",
    "\n",
    "    print(\"\\nBest validation performance:\")\n",
    "    print(best_val_metric)\n",
    "    print(\"Corresponding test performance:\")\n",
    "    print(best_test_metric)\n",
    "    return best_test_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9a7f4395",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2746317213, 1181241943, 958682846, 3163119785, 1812140441]\n"
     ]
    }
   ],
   "source": [
    "random.seed(42)\n",
    "seeds = [random.randint(0, 2**32 - 1) for _ in range(5)]\n",
    "print(seeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c9068358",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Random seed set to 2746317213\n",
      "Training with seed: 2746317213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|██████████| 953/953 [00:59<00:00, 16.08it/s]\n",
      "Running inference: 100%|██████████| 1926/1926 [00:39<00:00, 48.67it/s]\n",
      "Running inference:  20%|█▉        | 384/1953 [00:07<00:31, 50.16it/s]\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 1.27 GiB (GPU 0; 22.05 GiB total capacity; 3.51 GiB already allocated; 937.00 MiB free; 5.26 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m model \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     12\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdamW(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39margs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m---> 14\u001b[0m best_test_metric \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_with_early_stopping\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtask_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtask_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m final_metrics\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m     26\u001b[0m     final_metrics[key]\u001b[38;5;241m.\u001b[39mappend(best_test_metric[key])\n",
      "Cell \u001b[0;32mIn[14], line 38\u001b[0m, in \u001b[0;36mtrain_with_early_stopping\u001b[0;34m(model, train_dataloader, val_dataloader, test_dataloader, optimizer, loss_fn, device, args, task_type, eval_metric)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# Evaluation\u001b[39;00m\n\u001b[1;32m     37\u001b[0m val_metric \u001b[38;5;241m=\u001b[39m evaluate(model, val_dataloader, device, task_type\u001b[38;5;241m=\u001b[39mtask_type)\n\u001b[0;32m---> 38\u001b[0m test_metric \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtask_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m# Logging\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m03d\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Average Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mave_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/conda/envs/heart-cuda/lib/python3.10/site-packages/torch/autograd/grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclone():\n\u001b[0;32m---> 27\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[3], line 9\u001b[0m, in \u001b[0;36mevaluate\u001b[0;34m(model, dataloader, device, task_type)\u001b[0m\n\u001b[1;32m      7\u001b[0m batch \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mto(device) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m batch]\n\u001b[1;32m      8\u001b[0m labels \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m----> 9\u001b[0m output_logits \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m predicted_scores\u001b[38;5;241m.\u001b[39mappend(output_logits)\n\u001b[1;32m     11\u001b[0m gt_labels\u001b[38;5;241m.\u001b[39mappend(labels)\n",
      "File \u001b[0;32m~/conda/envs/heart-cuda/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/HeteroGT-cuda/baselines/HEART/HEART_rep.py:336\u001b[0m, in \u001b[0;36mHBERT_Finetune.forward\u001b[0;34m(self, input_ids, token_types, edge_index, visit_positions, labeled_ids)\u001b[0m\n\u001b[1;32m    334\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransformer(x, edge_index, \u001b[38;5;241m~\u001b[39mpad_mask, visit_positions) \u001b[38;5;66;03m# [B, L, D]\u001b[39;00m\n\u001b[1;32m    335\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhi_edge\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 336\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken_types\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m~\u001b[39;49m\u001b[43mpad_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvisit_positions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    339\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtask \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdeath\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstay\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreadmission\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    340\u001b[0m     \u001b[38;5;66;03m# labeled_ids indicates each patient's last visit index\u001b[39;00m\n\u001b[1;32m    341\u001b[0m     \u001b[38;5;66;03m# use CLS to make prediction\u001b[39;00m\n\u001b[1;32m    342\u001b[0m     prediction \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdownstream_cls(x[labeled_ids][:, \u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[0;32m~/conda/envs/heart-cuda/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/HeteroGT-cuda/baselines/HEART/HEART_rep.py:145\u001b[0m, in \u001b[0;36mHiEdgeTransformer.forward\u001b[0;34m(self, x, x_types, edge_index, mask, visit_positions)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, x_types, edge_index, mask, visit_positions):\n\u001b[0;32m--> 145\u001b[0m     edge_embs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_types\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# [B, L, L, D]\u001b[39;00m\n\u001b[1;32m    146\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransformer_blocks)):\n\u001b[1;32m    147\u001b[0m         \u001b[38;5;66;03m# note that here 1 is pad and 0 is valid token\u001b[39;00m\n\u001b[1;32m    148\u001b[0m         x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransformer_blocks[i](x, edge_embs, mask)  \u001b[38;5;66;03m# [B, L, D]\u001b[39;00m\n",
      "File \u001b[0;32m~/conda/envs/heart-cuda/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/HeteroGT-cuda/baselines/HEART/transformer_rel.py:42\u001b[0m, in \u001b[0;36mEdgeModule.forward\u001b[0;34m(self, token_embs, token_types)\u001b[0m\n\u001b[1;32m     39\u001b[0m left_embs \u001b[38;5;241m=\u001b[39m einsum(token_embs, left_trans, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mb l d, b l m d -> b l m\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# [batch_size, seq_len, hidden_size]\u001b[39;00m\n\u001b[1;32m     40\u001b[0m right_embs \u001b[38;5;241m=\u001b[39m einsum(token_embs, right_trans, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mb l d, b l m d -> b l m\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# [batch_size, seq_len, hidden_size]\u001b[39;00m\n\u001b[0;32m---> 42\u001b[0m edge_embs \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mleft_embs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrepeat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseq_len\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mright_embs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrepeat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseq_len\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# [B, L, L, 2D]\u001b[39;00m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput(edge_embs)\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 1.27 GiB (GPU 0; 22.05 GiB total capacity; 3.51 GiB already allocated; 937.00 MiB free; 5.26 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "final_metrics = {\"recall\":[], \"precision\":[],\"f1\":[],\"auc\":[],\"prauc\":[]}\n",
    "\n",
    "for seed in seeds:\n",
    "    args[\"seed\"] = seed\n",
    "    set_random_seed(args[\"seed\"])\n",
    "    print(f\"Training with seed: {args['seed']}\")\n",
    "    \n",
    "    # Initialize model, optimizer, and loss function\n",
    "    model = HBERT_Finetune(args, tokenizer)\n",
    "    model.load_weight(torch.load(pretrained_weight_path, weights_only=True))\n",
    "    model = model.to(device)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=args[\"lr\"])\n",
    "    \n",
    "    best_test_metric = train_with_early_stopping(\n",
    "        model, \n",
    "        train_dataloader, \n",
    "        val_dataloader, \n",
    "        test_dataloader,\n",
    "        optimizer, \n",
    "        loss_fn, \n",
    "        device, \n",
    "        args,\n",
    "        task_type=task_type)\n",
    "    \n",
    "    for key in final_metrics.keys():\n",
    "        final_metrics[key].append(best_test_metric[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8f55db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the mean and std of the final metrics\n",
    "print(\"\\nFinal Metrics:\")\n",
    "for key in final_metrics.keys():\n",
    "    mean_value = np.mean(final_metrics[key])\n",
    "    std_value = np.std(final_metrics[key])\n",
    "    print(f\"{key}: {mean_value:.4f} ± {std_value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4184e90",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Assuming final_metrics and args are defined\n",
    "# Create the results directory if it doesn't exist\n",
    "os.makedirs(f\"./results/{args['dataset']}\", exist_ok=True)\n",
    "\n",
    "# Define the file name\n",
    "file_name = f\"{args['dataset']}-{args['task']}.txt\"\n",
    "file_path = os.path.join(f\"./results/{args['dataset']}\", file_name)\n",
    "\n",
    "# Save the metrics to a text file\n",
    "with open(file_path, 'w') as f:\n",
    "    f.write(\"Final Metrics:\\n\")\n",
    "    for key in final_metrics.keys():\n",
    "        mean_value = np.mean(final_metrics[key])\n",
    "        std_value = np.std(final_metrics[key])\n",
    "        f.write(f\"{key}: {mean_value:.4f} ± {std_value:.4f}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "heart-cuda",
   "language": "python",
   "name": "heart-cuda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
