{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f52d2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from pyhealth.models import RETAINLayer, StageNetLayer\n",
    "from set_seed_utils import set_random_seed\n",
    "from sklearn.metrics import roc_auc_score, auc, precision_recall_curve, precision_recall_fscore_support\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "import pickle\n",
    "from torch.utils.data import DataLoader\n",
    "from token_utils_rep import EHRTokenizer\n",
    "from dataset_utils_rep import HBERTFinetuneEHRDataset, batcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5877398a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16847aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    \"dataset\": \"MIMIC-IV\", \n",
    "    \"task\": \"stay\",  # options: death, stay, readmission, next_diag_12m\n",
    "    \"batch_size\": 64,\n",
    "    \"hidden_size\": 256,\n",
    "    \"lr\": 1e-3,\n",
    "    \"epochs\": 500,\n",
    "    \"early_stop_patience\": 5,\n",
    "    \"dropout\": 0.0,\n",
    "    \"backbone\": \"stagenet\",  # options: retain, stagenet\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4fda902c",
   "metadata": {},
   "outputs": [],
   "source": [
    "PHENO_ORDER = [\n",
    "    \"Acute and unspecified renal failure\",\n",
    "    \"Acute cerebrovascular disease\",\n",
    "    \"Acute myocardial infarction\",\n",
    "    \"Cardiac dysrhythmias\",\n",
    "    \"Chronic kidney disease\",\n",
    "    \"Chronic obstructive pulmonary disease\",\n",
    "    \"Conduction disorders\",\n",
    "    \"Congestive heart failure; nonhypertensive\",\n",
    "    \"Coronary atherosclerosis and related\",\n",
    "    \"Disorders of lipid metabolism\",\n",
    "    \"Essential hypertension\",\n",
    "    \"Fluid and electrolyte disorders\",\n",
    "    \"Gastrointestinal hemorrhage\",\n",
    "    \"Hypertension with complications\",\n",
    "    \"Other liver diseases\",\n",
    "    \"Other lower respiratory disease\",\n",
    "    \"Pneumonia\",\n",
    "    \"Septicemia (except in labor)\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6eea04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate(model, dataloader, device, long_seq_idx=None, task_type=\"binary\"):\n",
    "    model.eval()\n",
    "    predicted_scores, gt_labels = [], []\n",
    "\n",
    "    # 推理：收集 logits 与 labels\n",
    "    for _, batch in enumerate(tqdm(dataloader, desc=\"Running inference\")):\n",
    "        batch = [x.to(device) if isinstance(x, torch.Tensor) else x for x in batch]\n",
    "        labels = batch[-1]\n",
    "        output_logits = model(*batch[:-1])\n",
    "        predicted_scores.append(output_logits)\n",
    "        gt_labels.append(labels)\n",
    "\n",
    "    if task_type == \"binary\":\n",
    "        # —— 标准二分类评估 —— #\n",
    "        logits_all = torch.cat(predicted_scores, dim=0).view(-1)          # logits [N]\n",
    "        labels_all = torch.cat(gt_labels, dim=0).view(-1).cpu().numpy()    # y_true [N]\n",
    "        scores_all = logits_all.cpu().numpy()                              # 连续分数（logits）\n",
    "        ypred_all  = (logits_all > 0).float().cpu().numpy()                # logits > 0\n",
    "\n",
    "        tp = (ypred_all * labels_all).sum()\n",
    "        precision = tp / (ypred_all.sum() + 1e-8)\n",
    "        recall    = tp / (labels_all.sum() + 1e-8)\n",
    "        f1        = 2 * precision * recall / (precision + recall + 1e-8)\n",
    "        roc_auc   = roc_auc_score(labels_all, scores_all)\n",
    "        prec_curve, rec_curve, _ = precision_recall_curve(labels_all, scores_all)\n",
    "        pr_auc    = auc(rec_curve, prec_curve)\n",
    "\n",
    "        all_performance = {\"precision\": float(precision),\n",
    "                           \"recall\": float(recall),\n",
    "                           \"f1\": float(f1),\n",
    "                           \"auc\": float(roc_auc),\n",
    "                           \"prauc\": float(pr_auc)}\n",
    "\n",
    "        subset_performance = None\n",
    "        if long_seq_idx is not None:\n",
    "            idx = torch.as_tensor(long_seq_idx, device=logits_all.device, dtype=torch.long)\n",
    "            logits_sub = logits_all.index_select(0, idx).view(-1)\n",
    "            labels_sub = torch.as_tensor(labels_all, device=logits_all.device)[idx].cpu().numpy()\n",
    "            scores_sub = logits_sub.cpu().numpy()\n",
    "            ypred_sub  = (logits_sub > 0).float().cpu().numpy()\n",
    "\n",
    "            tp = (ypred_sub * labels_sub).sum()\n",
    "            precision = tp / (ypred_sub.sum() + 1e-8)\n",
    "            recall    = tp / (labels_sub.sum() + 1e-8)\n",
    "            f1        = 2 * precision * recall / (precision + recall + 1e-8)\n",
    "            roc_auc   = roc_auc_score(labels_sub, scores_sub)\n",
    "            prec_curve, rec_curve, _ = precision_recall_curve(labels_sub, scores_sub)\n",
    "            pr_auc    = auc(rec_curve, prec_curve)\n",
    "\n",
    "            subset_performance = {\"precision\": float(precision),\n",
    "                                  \"recall\": float(recall),\n",
    "                                  \"f1\": float(f1),\n",
    "                                  \"auc\": float(roc_auc),\n",
    "                                  \"prauc\": float(pr_auc)}\n",
    "\n",
    "        return all_performance, subset_performance\n",
    "\n",
    "    else:\n",
    "        # —— Multi-label evaluation（按类聚合） —— #\n",
    "        logits_all = torch.cat(predicted_scores, dim=0)    # [B, C]\n",
    "        labels_all_t = torch.cat(gt_labels, dim=0)         # [B, C]\n",
    "\n",
    "        def _compute_metrics(logits_sub, labels_sub):\n",
    "            # 连续分数（概率）：sigmoid(logits)，CPU + fp16 先升为 fp32\n",
    "            if logits_sub.device.type == \"cpu\" and logits_sub.dtype == torch.float16:\n",
    "                prob_t = torch.sigmoid(logits_sub.float())\n",
    "            else:\n",
    "                prob_t = torch.sigmoid(logits_sub)\n",
    "            # 二值化：logits > 0\n",
    "            ypred_t = (logits_sub > 0).to(torch.int32)\n",
    "\n",
    "            y_true = labels_sub.cpu().numpy().astype(np.int32)       # [N, C]\n",
    "            y_pred = ypred_t.cpu().numpy().astype(np.int32)          # [N, C]\n",
    "            scores = prob_t.cpu().numpy()                             # [N, C]\n",
    "\n",
    "            # per-class P/R/F1\n",
    "            p_cls, r_cls, f1_cls, _ = precision_recall_fscore_support(\n",
    "                y_true, y_pred, average=None, zero_division=0\n",
    "            )\n",
    "\n",
    "            # per-class AUC / PR-AUC\n",
    "            C = y_true.shape[1]\n",
    "            aucs, praucs = [], []\n",
    "            for c in range(C):\n",
    "                yt, ys = y_true[:, c], scores[:, c]\n",
    "                if yt.max() == yt.min():\n",
    "                    aucs.append(np.nan)\n",
    "                    praucs.append(np.nan)\n",
    "                else:\n",
    "                    aucs.append(roc_auc_score(yt, ys))\n",
    "                    prec_curve, rec_curve, _ = precision_recall_curve(yt, ys)\n",
    "                    praucs.append(auc(rec_curve, prec_curve))\n",
    "\n",
    "            # 宏平均（忽略 NaN）\n",
    "            summary = {\n",
    "                \"precision\": float(np.mean(p_cls)),\n",
    "                \"recall\":    float(np.mean(r_cls)),\n",
    "                \"f1\":        float(np.mean(f1_cls)),\n",
    "                \"auc\":       float(np.nanmean(aucs)) if np.any(~np.isnan(aucs)) else float(\"nan\"),\n",
    "                \"prauc\":     float(np.nanmean(praucs)) if np.any(~np.isnan(praucs)) else float(\"nan\"),\n",
    "            }\n",
    "\n",
    "            per_class_df = pd.DataFrame({\n",
    "                \"precision\": p_cls,\n",
    "                \"recall\":    r_cls,\n",
    "                \"f1\":        f1_cls,\n",
    "                \"auc\":       aucs,\n",
    "                \"prauc\":     praucs,\n",
    "            }, index=PHENO_ORDER)   # 确保 PHENO_ORDER 已定义且长度=C\n",
    "\n",
    "            return {\"global\": summary, \"per_class\": per_class_df}\n",
    "\n",
    "        # 全量\n",
    "        all_performance = _compute_metrics(logits_all, labels_all_t)\n",
    "\n",
    "        # 子集\n",
    "        subset_performance = None\n",
    "        if long_seq_idx is not None:\n",
    "            idx = torch.as_tensor(long_seq_idx, device=logits_all.device, dtype=torch.long)\n",
    "            subset_performance = _compute_metrics(\n",
    "                logits_all.index_select(0, idx),\n",
    "                labels_all_t.index_select(0, idx)\n",
    "            )\n",
    "\n",
    "        return all_performance, subset_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a69ecc85",
   "metadata": {},
   "outputs": [],
   "source": [
    "args[\"predicted_token_type\"] = [\"diag\", \"med\", \"pro\", \"lab\"]\n",
    "args[\"special_tokens\"] = (\"[PAD]\", \"[CLS]\", \"[SEP]\", \"[MASK0]\", \"[MASK1]\", \"[MASK2]\", \"[MASK3]\")\n",
    "args[\"max_visit_size\"] = 15\n",
    "\n",
    "full_data_path = f\"/home/lideyi/HeteroGT-cuda/data_process/{args['dataset']}-processed/mimic.pkl\"\n",
    "\n",
    "if args[\"task\"] == \"next_diag_6m\":\n",
    "    finetune_data_path = f\"/home/lideyi/HeteroGT-cuda/data_process/{args['dataset']}-processed/mimic_nextdiag_6m.pkl\"\n",
    "elif args[\"task\"] == \"next_diag_12m\":\n",
    "    finetune_data_path = f\"/home/lideyi/HeteroGT-cuda/data_process/{args['dataset']}-processed/mimic_nextdiag_12m.pkl\"\n",
    "else:\n",
    "    finetune_data_path = f\"/home/lideyi/HeteroGT-cuda/data_process/{args['dataset']}-processed/mimic_downstream.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea0c0efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ehr_data = pickle.load(open(full_data_path, 'rb'))\n",
    "diag_sentences = ehr_data[\"ICD9_CODE\"].values.tolist()\n",
    "med_sentences = ehr_data[\"NDC\"].values.tolist()\n",
    "lab_sentences = ehr_data[\"LAB_TEST\"].values.tolist()\n",
    "pro_sentences = ehr_data[\"PRO_CODE\"].values.tolist()\n",
    "gender_set = [[\"M\"], [\"F\"]]\n",
    "age_gender_set = [[str(c) + \"_\" + gender] for c in set(ehr_data[\"AGE\"].values.tolist()) for gender in [\"M\", \"F\"]]\n",
    "age_set = [[c] for c in set(ehr_data[\"AGE\"].values.tolist())]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a4607420",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = EHRTokenizer(diag_sentences, med_sentences, lab_sentences, \n",
    "                         pro_sentences, gender_set, age_set, age_gender_set, special_tokens=args[\"special_tokens\"])\n",
    "tokenizer.build_tree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "34290960",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3131 6310 6304\n"
     ]
    }
   ],
   "source": [
    "train_data, val_data, test_data = pickle.load(open(finetune_data_path, 'rb'))\n",
    "\n",
    "train_dataset = HBERTFinetuneEHRDataset(\n",
    "    train_data, tokenizer, \n",
    "    token_type=args[\"predicted_token_type\"], \n",
    "    task=args[\"task\"]\n",
    ")\n",
    "\n",
    "val_dataset = HBERTFinetuneEHRDataset(\n",
    "    val_data, tokenizer, \n",
    "    token_type=args[\"predicted_token_type\"], \n",
    "    task=args[\"task\"]\n",
    ")\n",
    "\n",
    "test_dataset = HBERTFinetuneEHRDataset(\n",
    "    test_data, tokenizer, \n",
    "    token_type=args[\"predicted_token_type\"], \n",
    "    task=args[\"task\"]\n",
    ")\n",
    "\n",
    "print(len(train_dataset), len(val_dataset), len(test_dataset))\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset, \n",
    "    collate_fn=batcher(pad_id=tokenizer.vocab.word2id[\"[PAD]\"], is_train=False), \n",
    "    batch_size =  args[\"batch_size\"],\n",
    "    shuffle = True\n",
    ")\n",
    "\n",
    "val_dataloader = DataLoader(\n",
    "    val_dataset, \n",
    "    collate_fn=batcher(pad_id=tokenizer.vocab.word2id[\"[PAD]\"], is_train=False), \n",
    "    batch_size =  args[\"batch_size\"],\n",
    "    shuffle = False\n",
    ")\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset, \n",
    "    collate_fn=batcher(pad_id=tokenizer.vocab.word2id[\"[PAD]\"], is_train=False),\n",
    "    batch_size = args[\"batch_size\"],\n",
    "    shuffle = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "db4d8c1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "835 854\n"
     ]
    }
   ],
   "source": [
    "long_adm_seq_crite = 3\n",
    "val_long_seq_idx, test_long_seq_idx = [], []\n",
    "for i in range(len(val_dataset)):\n",
    "    hadm_id = list(val_dataset.records.keys())[i]\n",
    "    num_adms = len(val_dataset.records[hadm_id])\n",
    "    if num_adms >= long_adm_seq_crite:\n",
    "        val_long_seq_idx.append(i)\n",
    "for i in range(len(test_dataset)):\n",
    "    hadm_id = list(test_dataset.records.keys())[i]\n",
    "    num_adms = len(test_dataset.records[hadm_id])\n",
    "    if num_adms >= long_adm_seq_crite:\n",
    "        test_long_seq_idx.append(i)\n",
    "print(len(val_long_seq_idx), len(test_long_seq_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b866c53e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([108, 181])\n",
      "input_types shape: torch.Size([108, 181])\n",
      "labeled_batch_idx shape: 64\n",
      "labels shape: torch.Size([64, 1])\n"
     ]
    }
   ],
   "source": [
    "# examine a batch\n",
    "batch = next(iter(train_dataloader))  # 取第一个 batch\n",
    "input_ids, input_types, labeled_batch_idx, labels = batch\n",
    "\n",
    "# 打印每个张量的形状\n",
    "print(\"input_ids shape:\", input_ids.shape)\n",
    "print(\"input_types shape:\", input_types.shape)\n",
    "print(\"labeled_batch_idx shape:\", len(labeled_batch_idx)) # it is a list\n",
    "print(\"labels shape:\", labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3c711a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "args[\"vocab_size\"] = len(tokenizer.vocab.word2id)\n",
    "args[\"label_vocab_size\"] = 18  # only for diagnosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cf769c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if args[\"task\"] in [\"death\", \"stay\", \"readmission\"]:\n",
    "    eval_metric = \"f1\"\n",
    "    task_type = \"binary\"\n",
    "    loss_fn = F.binary_cross_entropy_with_logits\n",
    "else:\n",
    "    eval_metric = \"prauc\"\n",
    "    task_type = \"l2r\"\n",
    "    loss_fn = lambda x, y: F.binary_cross_entropy_with_logits(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "452cb47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_with_early_stopping(model, \n",
    "                              train_dataloader, \n",
    "                              val_dataloader, \n",
    "                              test_dataloader,\n",
    "                              optimizer, \n",
    "                              loss_fn, \n",
    "                              device, \n",
    "                              args,\n",
    "                              val_long_seq_idx = None,\n",
    "                              test_long_seq_idx = None,\n",
    "                              task_type=\"binary\", \n",
    "                              eval_metric=\"f1\"):\n",
    "    best_score = 0.\n",
    "    best_val_metric = None\n",
    "    best_test_metric = None\n",
    "    best_test_long_seq_metric = None\n",
    "    epochs_no_improve = 0\n",
    "\n",
    "    for epoch in range(1, 1 + args[\"epochs\"]):\n",
    "        model.train()\n",
    "        ave_loss = 0.\n",
    "\n",
    "        for step, batch in enumerate(tqdm(train_dataloader, desc=\"Training Batches\")):\n",
    "            batch = [x.to(device) if isinstance(x, torch.Tensor) else x for x in batch]\n",
    "\n",
    "            labels = batch[-1].float()\n",
    "            output_logits = model(*batch[:-1])\n",
    "            \n",
    "            loss = loss_fn(output_logits.view(-1), labels.view(-1))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            ave_loss += loss.item()\n",
    "            \n",
    "\n",
    "        ave_loss /= (step + 1)\n",
    "\n",
    "        # Evaluation\n",
    "        val_metric, val_long_seq_metric = evaluate(model, val_dataloader, device, task_type=task_type, long_seq_idx=val_long_seq_idx)\n",
    "        test_metric, test_long_seq_metric = evaluate(model, test_dataloader, device, task_type=task_type, long_seq_idx=test_long_seq_idx)\n",
    "\n",
    "        if task_type != \"binary\":\n",
    "            val_per_class_df = val_metric[\"per_class\"]\n",
    "            val_metric = val_metric[\"global\"]\n",
    "            test_per_class_df = test_metric[\"per_class\"]\n",
    "            test_metric = test_metric[\"global\"]\n",
    "            \n",
    "            if val_long_seq_idx != None:\n",
    "                val_long_seq_per_class_df = val_long_seq_metric[\"per_class\"]\n",
    "                val_long_seq_metric = val_long_seq_metric[\"global\"]\n",
    "            if test_long_seq_idx != None:\n",
    "                test_long_seq_per_class_df = test_long_seq_metric[\"per_class\"]\n",
    "                test_long_seq_metric = test_long_seq_metric[\"global\"]\n",
    "\n",
    "        # Logging\n",
    "        print(f\"Epoch: {epoch:03d}, Average Loss: {ave_loss:.4f}\")\n",
    "        print(f\"Validation: {val_metric}\")\n",
    "        print(f\"Test:       {test_metric}\")\n",
    "\n",
    "        # Check for improvement\n",
    "        current_score = val_metric[eval_metric]\n",
    "        if current_score > best_score:\n",
    "            best_score = current_score\n",
    "            best_val_metric = val_metric if task_type == \"binary\" else {\"global\": val_metric, \"per_class\": val_per_class_df}\n",
    "            best_test_metric = test_metric if task_type == \"binary\" else {\"global\": test_metric, \"per_class\": test_per_class_df}\n",
    "            best_test_long_seq_metric = test_long_seq_metric if task_type == \"binary\" else {\"global\": test_long_seq_metric, \"per_class\": test_long_seq_per_class_df}\n",
    "            epochs_no_improve = 0\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "\n",
    "        # Early stopping check\n",
    "        if epochs_no_improve >= args[\"early_stop_patience\"]:\n",
    "            print(f\"\\nEarly stopping triggered after {epoch} epochs (no improvement for {args['early_stop_patience']} epochs).\")\n",
    "            break\n",
    "\n",
    "    print(\"\\nBest validation performance:\")\n",
    "    print(best_val_metric)\n",
    "    print(\"Corresponding test performance:\")\n",
    "    print(best_test_metric)\n",
    "    if best_test_long_seq_metric is not None:\n",
    "        print(\"Corresponding test-long performance:\")\n",
    "        print(best_test_long_seq_metric)\n",
    "    return best_test_metric, best_test_long_seq_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6a27569c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinaryPredictionHead(nn.Module):\n",
    "    def __init__(self, in_dim: int):\n",
    "        super().__init__()\n",
    "        self.cls = nn.Sequential(\n",
    "            nn.Linear(in_dim, in_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_dim, 1),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.cls(x)  # [N,1]\n",
    "\n",
    "class PyHealthModel(nn.Module):\n",
    "    def __init__(self, args):\n",
    "        \"\"\"\n",
    "        必要参数：\n",
    "          args[\"vocab_size\"]:  int\n",
    "          args[\"hidden_size\"]: int  (embedding 维度 & RETAIN feature_size)\n",
    "          args[\"backbone\"]:    str  (\"retain\" 或 \"stagenet\")\n",
    "        可选参数：\n",
    "          args[\"dropout\"]:     float (默认 0.5)\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.vocab_size  = int(args[\"vocab_size\"])\n",
    "        self.hidden_size = int(args[\"hidden_size\"])\n",
    "        self.dropout     = float(args.get(\"dropout\", 0.5))\n",
    "        self.backbone    = str(args.get(\"backbone\", \"retain\")).lower()\n",
    "\n",
    "        # Embeddings（pad=0）\n",
    "        self.input_emb = nn.Embedding(self.vocab_size, self.hidden_size, padding_idx=0)\n",
    "        self.type_emb  = nn.Embedding(5,              self.hidden_size, padding_idx=0)\n",
    "\n",
    "        # Backbone\n",
    "        if self.backbone == \"retain\":\n",
    "            self.backbone_mod = RETAINLayer(feature_size=self.hidden_size, dropout=self.dropout)\n",
    "            backbone_out_dim = self.hidden_size\n",
    "        elif self.backbone == \"stagenet\":\n",
    "            # 你自己的 StageNetLayer，构造参数按你的实现来\n",
    "            self.backbone_mod = StageNetLayer(self.hidden_size)  # 示例\n",
    "            # StageNet 输出维可能与 hidden_size 不同；提供可配置项\n",
    "            backbone_out_dim = 384\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown backbone: {self.backbone}\")\n",
    "\n",
    "        # 分类头：输入维度与 backbone 输出对齐\n",
    "        self.pred_head = BinaryPredictionHead(backbone_out_dim)\n",
    "\n",
    "    def forward(self, input_ids, input_types, labeled_batch_idx):\n",
    "        \"\"\"\n",
    "        input_ids:        LongTensor [B, T], pad=0\n",
    "        input_types:      LongTensor [B, T], pad=0\n",
    "        labeled_batch_idx: list[int] 或 LongTensor [P]，表示要从 batch 里取出的行（病人）\n",
    "        return:\n",
    "          logits:         Tensor [P, 1]\n",
    "        \"\"\"\n",
    "        # 1) embeddings 相加\n",
    "        x = self.input_emb(input_ids) + self.type_emb(input_types)   # [B,T,H]\n",
    "\n",
    "        # 2) mask（以 input_ids!=0 作为有效位）\n",
    "        mask = (input_ids != 0)  # [B,T]，RETAIN 接受 bool/float mask\n",
    "\n",
    "        # 3) backbone 前向：得到每个病人的表示 c: [B, H*]\n",
    "        if self.backbone == \"retain\":\n",
    "            c = self.backbone_mod(x, mask=mask)                      # [B,H]\n",
    "        else:  # stagenet\n",
    "            out = self.backbone_mod(x, mask=mask)                    # 取决于你的实现\n",
    "            c = out[0] if isinstance(out, (tuple, list)) else out    # [B,H*]\n",
    "\n",
    "        # 4) 用 labeled_batch_idx 选择需要的样本行：c_sel [P,H*]\n",
    "        idx = torch.as_tensor(labeled_batch_idx, device=c.device, dtype=torch.long)\n",
    "        # 健壮性检查（调试期可保留）\n",
    "        assert idx.ndim == 1 and (idx.numel() == 0 or (0 <= idx.min() and idx.max() < c.size(0))), \\\n",
    "            f\"Index out of range: max={int(idx.max()) if idx.numel()>0 else 'NA'}, B={c.size(0)}\"\n",
    "\n",
    "        c_sel = c.index_select(0, idx)                                # [P,H*]\n",
    "\n",
    "        # 5) 分类\n",
    "        logits = self.pred_head(c_sel)                                # [P,1]\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d5b6b360",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2746317213, 1181241943, 958682846, 3163119785, 1812140441]\n"
     ]
    }
   ],
   "source": [
    "random.seed(42)\n",
    "seeds = [random.randint(0, 2**32 - 1) for _ in range(5)]\n",
    "print(seeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d519eaf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Random seed set to 2746317213\n",
      "Training with seed: 2746317213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|██████████| 49/49 [00:02<00:00, 18.67it/s]\n",
      "Running inference: 100%|██████████| 99/99 [00:01<00:00, 86.05it/s]\n",
      "Running inference: 100%|██████████| 99/99 [00:01<00:00, 86.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Average Loss: 0.5580\n",
      "Validation: {'precision': 0.5218726016844062, 'recall': 0.4007071302274561, 'f1': 0.4533333284165534, 'auc': 0.7542153998186825, 'prauc': 0.4894334919253639}\n",
      "Test:       {'precision': 0.5596899224762815, 'recall': 0.39977851605537224, 'f1': 0.4664082638697261, 'auc': 0.7519057934940446, 'prauc': 0.5140761434481639}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|██████████| 49/49 [00:02<00:00, 20.02it/s]\n",
      "Running inference: 100%|██████████| 99/99 [00:01<00:00, 86.64it/s]\n",
      "Running inference: 100%|██████████| 99/99 [00:01<00:00, 86.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 002, Average Loss: 0.4347\n",
      "Validation: {'precision': 0.7422680412323308, 'recall': 0.6788450206206315, 'f1': 0.7091412692438207, 'auc': 0.8970108431489445, 'prauc': 0.7785631010299476}\n",
      "Test:       {'precision': 0.7546239210804278, 'recall': 0.6777408637836227, 'f1': 0.7141190148468786, 'auc': 0.8959551113402436, 'prauc': 0.7803854114149931}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|██████████| 49/49 [00:02<00:00, 20.35it/s]\n",
      "Running inference: 100%|██████████| 99/99 [00:01<00:00, 86.92it/s]\n",
      "Running inference: 100%|██████████| 99/99 [00:01<00:00, 86.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 003, Average Loss: 0.3089\n",
      "Validation: {'precision': 0.6986807387825927, 'recall': 0.7802003535605174, 'f1': 0.7371937589309098, 'auc': 0.9084106930006548, 'prauc': 0.8119934761102677}\n",
      "Test:       {'precision': 0.7193877550983705, 'recall': 0.7807308970056438, 'f1': 0.7488050932518617, 'auc': 0.908229915892236, 'prauc': 0.8125461440722943}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|██████████| 49/49 [00:02<00:00, 19.73it/s]\n",
      "Running inference: 100%|██████████| 99/99 [00:01<00:00, 86.64it/s]\n",
      "Running inference: 100%|██████████| 99/99 [00:01<00:00, 86.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 004, Average Loss: 0.2426\n",
      "Validation: {'precision': 0.7788713910710048, 'recall': 0.6994696523235152, 'f1': 0.7370381819083263, 'auc': 0.9203134642547048, 'prauc': 0.8290467064318091}\n",
      "Test:       {'precision': 0.7884972170637694, 'recall': 0.7059800664412736, 'f1': 0.7449605559223719, 'auc': 0.9201372629252721, 'prauc': 0.8342794617660265}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|██████████| 49/49 [00:02<00:00, 20.18it/s]\n",
      "Running inference: 100%|██████████| 99/99 [00:01<00:00, 88.41it/s]\n",
      "Running inference: 100%|██████████| 99/99 [00:01<00:00, 78.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 005, Average Loss: 0.1567\n",
      "Validation: {'precision': 0.7502910360841077, 'recall': 0.7595757218576337, 'f1': 0.754904826620951, 'auc': 0.9214161357164764, 'prauc': 0.8302798509903037}\n",
      "Test:       {'precision': 0.7601809954708135, 'recall': 0.7441860465075073, 'f1': 0.7520984840842133, 'auc': 0.9188186013028061, 'prauc': 0.83324789472297}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|██████████| 49/49 [00:02<00:00, 19.59it/s]\n",
      "Running inference: 100%|██████████| 99/99 [00:01<00:00, 86.99it/s]\n",
      "Running inference: 100%|██████████| 99/99 [00:01<00:00, 86.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 006, Average Loss: 0.0864\n",
      "Validation: {'precision': 0.7858208955165238, 'recall': 0.6205067766610459, 'f1': 0.6934474761313659, 'auc': 0.9080017899249911, 'prauc': 0.8030342122963164}\n",
      "Test:       {'precision': 0.7970085470028704, 'recall': 0.6196013289002237, 'f1': 0.6971962567563165, 'auc': 0.9076765753402398, 'prauc': 0.8080506877212805}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|██████████| 49/49 [00:02<00:00, 19.99it/s]\n",
      "Running inference: 100%|██████████| 99/99 [00:01<00:00, 87.30it/s]\n",
      "Running inference: 100%|██████████| 99/99 [00:01<00:00, 86.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 007, Average Loss: 0.1036\n",
      "Validation: {'precision': 0.8118657298921791, 'recall': 0.6128461991714034, 'f1': 0.6984553342466718, 'auc': 0.9155900652775886, 'prauc': 0.8196765890868501}\n",
      "Test:       {'precision': 0.8194650817175375, 'recall': 0.6107419712037058, 'f1': 0.6998730915487509, 'auc': 0.9150301573678372, 'prauc': 0.823121296041284}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|██████████| 49/49 [00:02<00:00, 20.69it/s]\n",
      "Running inference: 100%|██████████| 99/99 [00:01<00:00, 87.01it/s]\n",
      "Running inference: 100%|██████████| 99/99 [00:01<00:00, 86.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 008, Average Loss: 0.0256\n",
      "Validation: {'precision': 0.7338530066774285, 'recall': 0.7766647024114517, 'f1': 0.7546521564654843, 'auc': 0.9173149694421279, 'prauc': 0.8203274206147194}\n",
      "Test:       {'precision': 0.7470651013834202, 'recall': 0.7751937984453201, 'f1': 0.7608695602149634, 'auc': 0.9164129547917692, 'prauc': 0.8264360812589235}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|██████████| 49/49 [00:02<00:00, 20.36it/s]\n",
      "Running inference: 100%|██████████| 99/99 [00:01<00:00, 86.92it/s]\n",
      "Running inference: 100%|██████████| 99/99 [00:01<00:00, 86.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 009, Average Loss: 0.0065\n",
      "Validation: {'precision': 0.7752200406176357, 'recall': 0.6747200942800547, 'f1': 0.7214870775651591, 'auc': 0.9161201957880556, 'prauc': 0.8167626953221553}\n",
      "Test:       {'precision': 0.782915863835691, 'recall': 0.6749723145034608, 'f1': 0.7249479581512586, 'auc': 0.9134939756663107, 'prauc': 0.8192812735974226}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|██████████| 49/49 [00:02<00:00, 20.19it/s]\n",
      "Running inference: 100%|██████████| 99/99 [00:01<00:00, 87.42it/s]\n",
      "Running inference: 100%|██████████| 99/99 [00:01<00:00, 86.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 010, Average Loss: 0.0011\n",
      "Validation: {'precision': 0.7821038251312699, 'recall': 0.6747200942800547, 'f1': 0.7244542816407417, 'auc': 0.9166274604283122, 'prauc': 0.8178791040391007}\n",
      "Test:       {'precision': 0.7861715748989362, 'recall': 0.6799557032077522, 'f1': 0.7292161470409148, 'auc': 0.9146635615583055, 'prauc': 0.8212231410695758}\n",
      "\n",
      "Early stopping triggered after 10 epochs (no improvement for 5 epochs).\n",
      "\n",
      "Best validation performance:\n",
      "{'precision': 0.7502910360841077, 'recall': 0.7595757218576337, 'f1': 0.754904826620951, 'auc': 0.9214161357164764, 'prauc': 0.8302798509903037}\n",
      "Corresponding test performance:\n",
      "{'precision': 0.7601809954708135, 'recall': 0.7441860465075073, 'f1': 0.7520984840842133, 'auc': 0.9188186013028061, 'prauc': 0.83324789472297}\n",
      "Corresponding test-long performance:\n",
      "{'precision': 0.4912280701323484, 'recall': 0.4210526315472892, 'f1': 0.45344129053942855, 'auc': 0.8073686296184288, 'prauc': 0.46258505102665326}\n",
      "[INFO] Random seed set to 1181241943\n",
      "Training with seed: 1181241943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|██████████| 49/49 [00:02<00:00, 20.07it/s]\n",
      "Running inference: 100%|██████████| 99/99 [00:01<00:00, 87.09it/s]\n",
      "Running inference: 100%|██████████| 99/99 [00:01<00:00, 86.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Average Loss: 0.5442\n",
      "Validation: {'precision': 0.6409861325016797, 'recall': 0.24513847966856137, 'f1': 0.354646202303371, 'auc': 0.7605746665830381, 'prauc': 0.5381616696045545}\n",
      "Test:       {'precision': 0.6585365853558149, 'recall': 0.2392026578059845, 'f1': 0.35093419592559133, 'auc': 0.7653053134972747, 'prauc': 0.5560130742097439}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|██████████| 49/49 [00:02<00:00, 20.52it/s]\n",
      "Running inference: 100%|██████████| 99/99 [00:01<00:00, 86.14it/s]\n",
      "Running inference: 100%|██████████| 99/99 [00:01<00:00, 85.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 002, Average Loss: 0.4355\n",
      "Validation: {'precision': 0.7766159695743668, 'recall': 0.4814378314644583, 'f1': 0.5943979581665321, 'auc': 0.8650361810879836, 'prauc': 0.7320246973849289}\n",
      "Test:       {'precision': 0.8063926940565627, 'recall': 0.48892580287658405, 'f1': 0.6087555968128621, 'auc': 0.8707794087885496, 'prauc': 0.748307966231117}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|██████████| 49/49 [00:02<00:00, 19.54it/s]\n",
      "Running inference: 100%|██████████| 99/99 [00:01<00:00, 86.06it/s]\n",
      "Running inference: 100%|██████████| 99/99 [00:01<00:00, 85.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 003, Average Loss: 0.3348\n",
      "Validation: {'precision': 0.8954545454409779, 'recall': 0.3482616381829802, 'f1': 0.5014849344447155, 'auc': 0.8888833675831707, 'prauc': 0.77831921612235}\n",
      "Test:       {'precision': 0.8923303834676647, 'recall': 0.3349944628995848, 'f1': 0.48711754836208426, 'auc': 0.8923963745176273, 'prauc': 0.7906291161237271}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|██████████| 49/49 [00:02<00:00, 20.24it/s]\n",
      "Running inference: 100%|██████████| 99/99 [00:01<00:00, 85.84it/s]\n",
      "Running inference: 100%|██████████| 99/99 [00:01<00:00, 84.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 004, Average Loss: 0.2566\n",
      "Validation: {'precision': 0.7000569151923731, 'recall': 0.7248084855584868, 'f1': 0.7122177135845302, 'auc': 0.8932935424610907, 'prauc': 0.7790015562982634}\n",
      "Test:       {'precision': 0.734878462403986, 'recall': 0.7198228128420829, 'f1': 0.7272727222691941, 'auc': 0.8962985640966552, 'prauc': 0.790950370822117}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|██████████| 49/49 [00:02<00:00, 19.58it/s]\n",
      "Running inference: 100%|██████████| 99/99 [00:01<00:00, 87.08it/s]\n",
      "Running inference: 100%|██████████| 99/99 [00:01<00:00, 86.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 005, Average Loss: 0.1728\n",
      "Validation: {'precision': 0.7347600518759095, 'recall': 0.6676487919819232, 'f1': 0.6995986365631662, 'auc': 0.8850476497909305, 'prauc': 0.7675733260507086}\n",
      "Test:       {'precision': 0.7564668769668362, 'recall': 0.6638981173828135, 'f1': 0.7071660227375031, 'auc': 0.886437776947254, 'prauc': 0.7800392412269939}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|██████████| 49/49 [00:02<00:00, 19.67it/s]\n",
      "Running inference: 100%|██████████| 99/99 [00:01<00:00, 86.86it/s]\n",
      "Running inference: 100%|██████████| 99/99 [00:01<00:00, 86.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 006, Average Loss: 0.0943\n",
      "Validation: {'precision': 0.7217694994137267, 'recall': 0.7307012374735964, 'f1': 0.7262079012916902, 'auc': 0.9020096545069206, 'prauc': 0.7872461346936648}\n",
      "Test:       {'precision': 0.7357859531731562, 'recall': 0.7308970099627304, 'f1': 0.733333328329315, 'auc': 0.9002236505261105, 'prauc': 0.7976806884270481}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|██████████| 49/49 [00:02<00:00, 20.00it/s]\n",
      "Running inference: 100%|██████████| 99/99 [00:01<00:00, 87.05it/s]\n",
      "Running inference: 100%|██████████| 99/99 [00:01<00:00, 86.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 007, Average Loss: 0.0673\n",
      "Validation: {'precision': 0.7309711286041275, 'recall': 0.6564525633432148, 'f1': 0.6917106438769406, 'auc': 0.8885302240178246, 'prauc': 0.7562219699059796}\n",
      "Test:       {'precision': 0.7560975609707568, 'recall': 0.6522702104061336, 'f1': 0.7003567132156385, 'auc': 0.8874601336289736, 'prauc': 0.766594203118491}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|██████████| 49/49 [00:02<00:00, 20.29it/s]\n",
      "Running inference: 100%|██████████| 99/99 [00:01<00:00, 87.16it/s]\n",
      "Running inference: 100%|██████████| 99/99 [00:01<00:00, 86.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 008, Average Loss: 0.0349\n",
      "Validation: {'precision': 0.7314939434674866, 'recall': 0.6405421331724188, 'f1': 0.6830034508769324, 'auc': 0.8838151921608132, 'prauc': 0.7541993062902524}\n",
      "Test:       {'precision': 0.7605540897047457, 'recall': 0.6384274640053244, 'f1': 0.6941601395251948, 'auc': 0.8825253084058031, 'prauc': 0.7722907928043419}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|██████████| 49/49 [00:02<00:00, 20.15it/s]\n",
      "Running inference: 100%|██████████| 99/99 [00:01<00:00, 86.73it/s]\n",
      "Running inference: 100%|██████████| 99/99 [00:01<00:00, 87.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 009, Average Loss: 0.0294\n",
      "Validation: {'precision': 0.6754675467509601, 'recall': 0.7236299351754648, 'f1': 0.6987197674059324, 'auc': 0.8827866750993613, 'prauc': 0.7461022795946466}\n",
      "Test:       {'precision': 0.7039438141507081, 'recall': 0.7214839424101801, 'f1': 0.7126059561672182, 'auc': 0.8801902605169174, 'prauc': 0.7592676042993595}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|██████████| 49/49 [00:02<00:00, 20.04it/s]\n",
      "Running inference: 100%|██████████| 99/99 [00:01<00:00, 86.85it/s]\n",
      "Running inference: 100%|██████████| 99/99 [00:01<00:00, 86.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 010, Average Loss: 0.0249\n",
      "Validation: {'precision': 0.7280513918577585, 'recall': 0.6010606953411841, 'f1': 0.6584893430078237, 'auc': 0.8706150701924731, 'prauc': 0.7348518565163266}\n",
      "Test:       {'precision': 0.7611832611777692, 'recall': 0.5841638981141519, 'f1': 0.6610275640047291, 'auc': 0.8683184897729863, 'prauc': 0.7501806895960688}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|██████████| 49/49 [00:02<00:00, 20.01it/s]\n",
      "Running inference: 100%|██████████| 99/99 [00:01<00:00, 87.02it/s]\n",
      "Running inference: 100%|██████████| 99/99 [00:01<00:00, 86.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 011, Average Loss: 0.0175\n",
      "Validation: {'precision': 0.6015070921959154, 'recall': 0.7996464348803792, 'f1': 0.6865671592756172, 'auc': 0.8771679942710137, 'prauc': 0.7255356789466338}\n",
      "Test:       {'precision': 0.6312973695914789, 'recall': 0.784053156141838, 'f1': 0.699431953563061, 'auc': 0.875300305734504, 'prauc': 0.7390635215776198}\n",
      "\n",
      "Early stopping triggered after 11 epochs (no improvement for 5 epochs).\n",
      "\n",
      "Best validation performance:\n",
      "{'precision': 0.7217694994137267, 'recall': 0.7307012374735964, 'f1': 0.7262079012916902, 'auc': 0.9020096545069206, 'prauc': 0.7872461346936648}\n",
      "Corresponding test performance:\n",
      "{'precision': 0.7357859531731562, 'recall': 0.7308970099627304, 'f1': 0.733333328329315, 'auc': 0.9002236505261105, 'prauc': 0.7976806884270481}\n",
      "Corresponding test-long performance:\n",
      "{'precision': 0.4999999999519231, 'recall': 0.3909774435796257, 'f1': 0.4388185604386762, 'auc': 0.7890565526159364, 'prauc': 0.42380631634826316}\n",
      "[INFO] Random seed set to 958682846\n",
      "Training with seed: 958682846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|██████████| 49/49 [00:02<00:00, 19.85it/s]\n",
      "Running inference: 100%|██████████| 99/99 [00:01<00:00, 86.98it/s]\n",
      "Running inference: 100%|██████████| 99/99 [00:01<00:00, 86.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Average Loss: 0.5338\n",
      "Validation: {'precision': 0.6225018504765174, 'recall': 0.49558043606072144, 'f1': 0.5518372654020172, 'auc': 0.7923959101516926, 'prauc': 0.6059524153686152}\n",
      "Test:       {'precision': 0.660619803471953, 'recall': 0.4839424141722927, 'f1': 0.5586449295994288, 'auc': 0.797456676943167, 'prauc': 0.6229719632956054}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|██████████| 49/49 [00:02<00:00, 19.50it/s]\n",
      "Running inference: 100%|██████████| 99/99 [00:01<00:00, 86.91it/s]\n",
      "Running inference: 100%|██████████| 99/99 [00:01<00:00, 86.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 002, Average Loss: 0.3901\n",
      "Validation: {'precision': 0.8408437200302892, 'recall': 0.5167943429551162, 'f1': 0.6401459806816426, 'auc': 0.9026608847098992, 'prauc': 0.7917704672241376}\n",
      "Test:       {'precision': 0.8397839783902811, 'recall': 0.5166112956782026, 'f1': 0.6396983154714276, 'auc': 0.9022854749766969, 'prauc': 0.7998186951395676}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|██████████| 49/49 [00:02<00:00, 19.91it/s]\n",
      "Running inference: 100%|██████████| 99/99 [00:01<00:00, 88.71it/s]\n",
      "Running inference: 100%|██████████| 99/99 [00:01<00:00, 88.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 003, Average Loss: 0.3121\n",
      "Validation: {'precision': 0.8351836037503401, 'recall': 0.5763111372977237, 'f1': 0.6820083633642644, 'auc': 0.9115286268559518, 'prauc': 0.8124002839754645}\n",
      "Test:       {'precision': 0.8452188006414488, 'recall': 0.5775193798417635, 'f1': 0.6861842056988186, 'auc': 0.9152689739798222, 'prauc': 0.8233285623445579}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|██████████| 49/49 [00:02<00:00, 19.89it/s]\n",
      "Running inference: 100%|██████████| 99/99 [00:01<00:00, 87.01it/s]\n",
      "Running inference: 100%|██████████| 99/99 [00:01<00:00, 86.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 004, Average Loss: 0.2255\n",
      "Validation: {'precision': 0.6280594405566956, 'recall': 0.8467884502012565, 'f1': 0.7212045120448736, 'auc': 0.9099452611505927, 'prauc': 0.815298063444491}\n",
      "Test:       {'precision': 0.6599398883612713, 'recall': 0.851052048721755, 'f1': 0.743409910433103, 'auc': 0.9154617506882596, 'prauc': 0.8316057588678137}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|██████████| 49/49 [00:02<00:00, 19.70it/s]\n",
      "Running inference: 100%|██████████| 99/99 [00:01<00:00, 86.18it/s]\n",
      "Running inference: 100%|██████████| 99/99 [00:01<00:00, 86.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 005, Average Loss: 0.1689\n",
      "Validation: {'precision': 0.7977126518885082, 'recall': 0.6576311137262367, 'f1': 0.7209302275998059, 'auc': 0.9157809122613565, 'prauc': 0.8213112138219134}\n",
      "Test:       {'precision': 0.8217543859591456, 'recall': 0.648394241413907, 'f1': 0.7248529817564657, 'auc': 0.9187849946352433, 'prauc': 0.8344867185708742}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|██████████| 49/49 [00:02<00:00, 20.19it/s]\n",
      "Running inference: 100%|██████████| 99/99 [00:01<00:00, 86.14it/s]\n",
      "Running inference: 100%|██████████| 99/99 [00:01<00:00, 86.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 006, Average Loss: 0.0949\n",
      "Validation: {'precision': 0.5584849610079522, 'recall': 0.8862698880324911, 'f1': 0.685193617122131, 'auc': 0.90592521123146, 'prauc': 0.800894022260978}\n",
      "Test:       {'precision': 0.5921972764056231, 'recall': 0.8909191583560858, 'f1': 0.7114746801433156, 'auc': 0.9081516234359358, 'prauc': 0.811741793734717}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|██████████| 49/49 [00:02<00:00, 19.39it/s]\n",
      "Running inference: 100%|██████████| 99/99 [00:01<00:00, 87.79it/s]\n",
      "Running inference: 100%|██████████| 99/99 [00:01<00:00, 86.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 007, Average Loss: 0.0730\n",
      "Validation: {'precision': 0.6725798276701846, 'recall': 0.7819681791350503, 'f1': 0.723160757967117, 'auc': 0.904372375933812, 'prauc': 0.7970821883052448}\n",
      "Test:       {'precision': 0.6950803701865803, 'recall': 0.7901439645581941, 'f1': 0.7395698317619219, 'auc': 0.9075521198790455, 'prauc': 0.8109334907896517}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|██████████| 49/49 [00:02<00:00, 20.02it/s]\n",
      "Running inference: 100%|██████████| 99/99 [00:01<00:00, 86.97it/s]\n",
      "Running inference: 100%|██████████| 99/99 [00:01<00:00, 86.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 008, Average Loss: 0.0676\n",
      "Validation: {'precision': 0.6803069053673642, 'recall': 0.7837360047095833, 'f1': 0.7283680125456097, 'auc': 0.9039171024062687, 'prauc': 0.7969076092371981}\n",
      "Test:       {'precision': 0.7068709836840985, 'recall': 0.7918050941262913, 'f1': 0.7469313086710765, 'auc': 0.9090082857054224, 'prauc': 0.8150557876513984}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|██████████| 49/49 [00:02<00:00, 20.37it/s]\n",
      "Running inference: 100%|██████████| 99/99 [00:01<00:00, 86.74it/s]\n",
      "Running inference: 100%|██████████| 99/99 [00:01<00:00, 86.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 009, Average Loss: 0.0263\n",
      "Validation: {'precision': 0.8116063919191623, 'recall': 0.5686505598080811, 'f1': 0.6687456638959535, 'auc': 0.9033131368512113, 'prauc': 0.7970485217734287}\n",
      "Test:       {'precision': 0.8336025848074831, 'recall': 0.5714285714254074, 'f1': 0.6780551857084013, 'auc': 0.9026523785395946, 'prauc': 0.806572644180775}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|██████████| 49/49 [00:02<00:00, 19.87it/s]\n",
      "Running inference: 100%|██████████| 99/99 [00:01<00:00, 86.34it/s]\n",
      "Running inference: 100%|██████████| 99/99 [00:01<00:00, 86.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 010, Average Loss: 0.0104\n",
      "Validation: {'precision': 0.7348951911175408, 'recall': 0.7024160282810701, 'f1': 0.7182886361552, 'auc': 0.9068748474278004, 'prauc': 0.8007842018448821}\n",
      "Test:       {'precision': 0.7645645645599727, 'recall': 0.7048726467292089, 'f1': 0.7335061891843759, 'auc': 0.908362003636906, 'prauc': 0.815367232884462}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|██████████| 49/49 [00:02<00:00, 19.52it/s]\n",
      "Running inference: 100%|██████████| 99/99 [00:01<00:00, 87.29it/s]\n",
      "Running inference: 100%|██████████| 99/99 [00:01<00:00, 86.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 011, Average Loss: 0.0049\n",
      "Validation: {'precision': 0.7016574585596594, 'recall': 0.7483794932189254, 'f1': 0.7242657492069348, 'auc': 0.9037747974933386, 'prauc': 0.7875568667891546}\n",
      "Test:       {'precision': 0.7164179104439424, 'recall': 0.7441860465075073, 'f1': 0.7300380178115301, 'auc': 0.9051358866522197, 'prauc': 0.8027437244483067}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|██████████| 49/49 [00:02<00:00, 19.91it/s]\n",
      "Running inference: 100%|██████████| 99/99 [00:01<00:00, 87.05it/s]\n",
      "Running inference: 100%|██████████| 99/99 [00:01<00:00, 86.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 012, Average Loss: 0.0048\n",
      "Validation: {'precision': 0.8589083419067054, 'recall': 0.4914555097201447, 'f1': 0.6251874016623951, 'auc': 0.904419768324025, 'prauc': 0.8019710714988759}\n",
      "Test:       {'precision': 0.8670634920548902, 'recall': 0.4839424141722927, 'f1': 0.6211798106073452, 'auc': 0.9055285799471846, 'prauc': 0.817064747849431}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|██████████| 49/49 [00:02<00:00, 19.49it/s]\n",
      "Running inference: 100%|██████████| 99/99 [00:01<00:00, 80.63it/s]\n",
      "Running inference: 100%|██████████| 99/99 [00:01<00:00, 86.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 013, Average Loss: 0.0061\n",
      "Validation: {'precision': 0.7924528301826985, 'recall': 0.6187389510865131, 'f1': 0.6949040321327146, 'auc': 0.9080398571279112, 'prauc': 0.8038341376182547}\n",
      "Test:       {'precision': 0.8098336948603773, 'recall': 0.6201550387562561, 'f1': 0.7024145450992452, 'auc': 0.9077190453047423, 'prauc': 0.8149246991737772}\n",
      "\n",
      "Early stopping triggered after 13 epochs (no improvement for 5 epochs).\n",
      "\n",
      "Best validation performance:\n",
      "{'precision': 0.6803069053673642, 'recall': 0.7837360047095833, 'f1': 0.7283680125456097, 'auc': 0.9039171024062687, 'prauc': 0.7969076092371981}\n",
      "Corresponding test performance:\n",
      "{'precision': 0.7068709836840985, 'recall': 0.7918050941262913, 'f1': 0.7469313086710765, 'auc': 0.9090082857054224, 'prauc': 0.8150557876513984}\n",
      "Corresponding test-long performance:\n",
      "{'precision': 0.537735849005874, 'recall': 0.42857142853920516, 'f1': 0.4769874427226415, 'auc': 0.8131667587832271, 'prauc': 0.4838872451615434}\n",
      "[INFO] Random seed set to 3163119785\n",
      "Training with seed: 3163119785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  33%|███▎      | 16/49 [00:00<00:01, 19.45it/s]"
     ]
    }
   ],
   "source": [
    "final_metrics, final_long_seq_metrics = [], []\n",
    "\n",
    "for seed in seeds:\n",
    "    args[\"seed\"] = seed\n",
    "    set_random_seed(args[\"seed\"])\n",
    "    print(f\"Training with seed: {args['seed']}\")\n",
    "    \n",
    "    # Initialize model, optimizer, and loss function\n",
    "    model = PyHealthModel(args)\n",
    "    model = model.to(device)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=args[\"lr\"])\n",
    "    \n",
    "    best_test_metric, best_test_long_seq_metric = train_with_early_stopping(\n",
    "        model, \n",
    "        train_dataloader, \n",
    "        val_dataloader, \n",
    "        test_dataloader,\n",
    "        optimizer, \n",
    "        loss_fn, \n",
    "        device, \n",
    "        args,\n",
    "        val_long_seq_idx,\n",
    "        test_long_seq_idx,\n",
    "        task_type=task_type)\n",
    "    \n",
    "    final_metrics.append(best_test_metric)\n",
    "    final_long_seq_metrics.append(best_test_long_seq_metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83685ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def topk_avg_performance_formatted(performances, long_seq_performances, k=5):\n",
    "    metrics = [\"f1\", \"auc\", \"prauc\"]\n",
    "    scores = {m: np.array([p[m] for p in performances]) for m in metrics}\n",
    "\n",
    "    # 计算排名（值越大排名越靠前）\n",
    "    ranks = {m: (-scores[m]).argsort().argsort() + 1 for m in metrics}\n",
    "    avg_ranks = np.mean(np.stack([ranks[m] for m in metrics], axis=1), axis=1)\n",
    "\n",
    "    # 选 top-k\n",
    "    topk_idx = np.argsort(avg_ranks)[:k]\n",
    "    final_avg = {m: np.mean([performances[i][m] for i in topk_idx]) for m in performances[0].keys()}\n",
    "    final_std = {m: np.std([performances[i][m] for i in topk_idx], ddof=0) for m in performances[0].keys()}\n",
    "    final_long_seq_avg = {m: np.mean([long_seq_performances[i][m] for i in topk_idx]) for m in long_seq_performances[0].keys()}\n",
    "    final_long_seq_std = {m: np.std([long_seq_performances[i][m] for i in topk_idx], ddof=0) for m in long_seq_performances[0].keys()}\n",
    "\n",
    "    # 打印结果（转百分比，均保留两位小数）\n",
    "    print(\"Final Metrics:\")\n",
    "    for m in performances[0].keys():\n",
    "        mean_val = final_avg[m] * 100\n",
    "        std_val = final_std[m] * 100\n",
    "        print(f\"{m}: {mean_val:.2f} ± {std_val:.2f}\")\n",
    "    print(\"\\nFinal Long Sequence Metrics:\")\n",
    "    for m in long_seq_performances[0].keys():\n",
    "        mean_val = final_long_seq_avg[m] * 100\n",
    "        std_val = final_long_seq_std[m] * 100\n",
    "        print(f\"{m}: {mean_val:.2f} ± {std_val:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11017800",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_per_class_performance(dfs, col_name=\"prauc\"):\n",
    "    \"\"\"\n",
    "    输入一个 DataFrame 列表，对每个疾病在所有表格的指定列计算 mean ± std 并打印。\n",
    "\n",
    "    参数:\n",
    "        dfs (list[pd.DataFrame]): 多个表格组成的列表\n",
    "        col_name (str): 要计算的指标列名 (默认: \"prauc\")\n",
    "    \"\"\"\n",
    "    # 拼接所有表格\n",
    "    all_values = pd.concat(dfs, axis=0)\n",
    "\n",
    "    # 按疾病分组，计算 mean 和 std\n",
    "    grouped = all_values.groupby(all_values.index)[col_name].agg([\"mean\", \"std\"])\n",
    "\n",
    "    # 打印\n",
    "    for disease, row in grouped.iterrows():\n",
    "        mean_val = row[\"mean\"] * 100\n",
    "        std_val = row[\"std\"] * 100\n",
    "        print(f\"{disease}: {mean_val:.2f} ± {std_val:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141f2782",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Metrics:\n",
      "precision: 76.64 ± 2.32\n",
      "recall: 72.54 ± 3.27\n",
      "f1: 74.44 ± 1.16\n",
      "auc: 91.42 ± 0.53\n",
      "prauc: 82.06 ± 1.32\n",
      "\n",
      "Final Long Sequence Metrics:\n",
      "precision: 54.75 ± 5.83\n",
      "recall: 22.56 ± 3.83\n",
      "f1: 31.74 ± 4.10\n",
      "auc: 80.41 ± 1.02\n",
      "prauc: 40.71 ± 1.48\n"
     ]
    }
   ],
   "source": [
    "if task_type == \"binary\":\n",
    "    topk_avg_performance_formatted(final_metrics, final_long_seq_metrics)\n",
    "else:\n",
    "    final_metrics_global = [metrics[\"global\"] for metrics in final_metrics]\n",
    "    final_metrics_per_class = [metrics[\"per_class\"] for metrics in final_metrics]\n",
    "    final_long_seq_metrics_global = [metrics[\"global\"] for metrics in final_long_seq_metrics]\n",
    "    final_long_seq_metrics_per_class = [metrics[\"per_class\"] for metrics in final_long_seq_metrics]\n",
    "    topk_avg_performance_formatted(final_metrics_global, final_long_seq_metrics_global)\n",
    "    print(\"\\nPer-class performance, all patients:\")\n",
    "    print_per_class_performance(final_metrics_per_class, col_name=\"prauc\")\n",
    "    print(\"\\nPer-class performance, long seq:\")\n",
    "    print_per_class_performance(final_long_seq_metrics_per_class, col_name=\"prauc\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyhealth",
   "language": "python",
   "name": "pyhealth"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
