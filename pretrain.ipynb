{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "237db178",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Disabling PyTorch because PyTorch >= 2.1 is required but found 1.13.1\n",
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pickle\n",
    "from argparse import Namespace\n",
    "from torch.utils.data import DataLoader\n",
    "from heterogt.utils.tokenizer import EHRTokenizer\n",
    "from heterogt.utils.dataset import PreTrainEHRDataset, batcher, expand_level3\n",
    "from heterogt.utils.seed import set_random_seed\n",
    "from heterogt.model.model import HeteroGTPreTrain\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c3c4dd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Random seed set to 123\n"
     ]
    }
   ],
   "source": [
    "set_random_seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af749748",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b71b0e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Namespace(\n",
    "    dataset = \"MIMIC-III\",\n",
    "    tasks = [\"death\", \"readmission\", \"stay\", \"next_diag_6m\", \"next_diag_12m\"], \n",
    "    task_index = 2,  # index of the task to train\n",
    "    token_type = [\"diag\", \"med\", \"lab\", \"pro\"],\n",
    "    special_tokens = [\"[PAD]\", \"[CLS]\"],\n",
    "    attn_mask_dicts = [{1:[6,7], 2:[6,7], 3:[6,7], 4:[6,7], 6:[2,3,4,5,6,7], 7:[2,3,4,5,6,7]}, \n",
    "                       {1:[6,7], 2:[6,7], 3:[6,7], 4:[6,7], 6:[2,3,4,5,6,7], 7:[2,3,4,5,6,7]}],\n",
    "    d_model = 64,\n",
    "    num_heads = 4,\n",
    "    batch_size = 32,\n",
    "    lr = 1e-3,\n",
    "    epochs = 25,\n",
    "    early_stop_patience = 5,\n",
    "    group_code_thre = 5,  # if there are group_code_thre diag codes belongs to the same group ICD code, then the group code is generated\n",
    "    pretrain_mask_rate = 0.7,\n",
    "    cls_ontology_weight = 5e-2,\n",
    "    visit_ontology_weight = 5e-2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b92817ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data_path = f\"./data_process/{config.dataset}-processed/mimic.pkl\"  # for tokenizer\n",
    "pretrain_data_path = f\"./data_process/{config.dataset}-processed/mimic_pretrain.pkl\" # for pretraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95fa33dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max admissions per patient: 8\n"
     ]
    }
   ],
   "source": [
    "ehr_full_data = pickle.load(open(full_data_path, 'rb'))\n",
    "group_code_sentences = [expand_level3()[1]]\n",
    "diag_sentences = ehr_full_data[\"ICD9_CODE\"].values.tolist()\n",
    "med_sentences = ehr_full_data[\"NDC\"].values.tolist()\n",
    "lab_sentences = ehr_full_data[\"LAB_TEST\"].values.tolist()\n",
    "pro_sentences = ehr_full_data[\"PRO_CODE\"].values.tolist()\n",
    "age_sentences = [[str(c)] for c in set(ehr_full_data[\"AGE\"].values.tolist())] # important of [[]]\n",
    "max_admissions = ehr_full_data.groupby(\"SUBJECT_ID\")[\"HADM_ID\"].nunique().max()\n",
    "config.max_num_adms = max_admissions\n",
    "print(f\"Max admissions per patient: {config.max_num_adms}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "92f7a74c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age vocabulary size: 18\n",
      "Group code vocabulary size: 19\n"
     ]
    }
   ],
   "source": [
    "tokenizer = EHRTokenizer(age_sentences, group_code_sentences, diag_sentences, med_sentences, lab_sentences, \n",
    "                         pro_sentences, special_tokens=config.special_tokens)\n",
    "config.label_vocab_size = {\"diag\":tokenizer.token_number(\"diag\"),     \n",
    "                            \"med\":tokenizer.token_number(\"med\"), \n",
    "                            \"lab\":tokenizer.token_number(\"lab\"), \n",
    "                            \"pro\":tokenizer.token_number(\"pro\")}\n",
    "config.global_vocab_size = len(tokenizer.vocab.id2word)\n",
    "config.age_vocab_size = tokenizer.token_number(\"age\")\n",
    "config.group_code_vocab_size = tokenizer.token_number(\"group\")\n",
    "print(f\"Age vocabulary size: {config.age_vocab_size}\")\n",
    "print(f\"Group code vocabulary size: {config.group_code_vocab_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8248322f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pretrain data\n",
    "ehr_pretrain_data = pickle.load(open(pretrain_data_path, 'rb'))\n",
    "# load occurence data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "67e5676c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of pretrain samples: 23146\n"
     ]
    }
   ],
   "source": [
    "pretrain_dataset = PreTrainEHRDataset(ehr_pretrain_data=ehr_pretrain_data, tokenizer=tokenizer, token_type=config.token_type,\n",
    "                                      mask_rate=config.pretrain_mask_rate, group_code_thre=config.group_code_thre, max_num_adms=config.max_num_adms)\n",
    "print(\"Number of pretrain samples:\", len(pretrain_dataset))\n",
    "pretrain_dataloader = DataLoader(pretrain_dataset, batch_size=config.batch_size, \n",
    "                                 collate_fn=batcher(tokenizer, n_token_type=len(config.token_type), is_pretrain=True), shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cac9224e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = HeteroGTPreTrain(tokenizer=tokenizer, token_types=config.token_type, d_model=config.d_model, num_heads=config.num_heads, layer_types=['gnn', 'tf', 'gnn', 'tf'], max_num_adms=config.max_num_adms, \n",
    "                     device=device, label_vocab_size=config.label_vocab_size, attn_mask_dicts=config.attn_mask_dicts,\n",
    "                     use_cls_cat=True).to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=config.lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bb79c16e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'diag': 1.0, 'med': 1.0, 'lab': 1.0, 'pro': 1.0, 'cls_ontology': 0.05, 'visit_ontology': 0.05}\n"
     ]
    }
   ],
   "source": [
    "# 统一权重表：未指定的一律 1.0\n",
    "loss_weights = {\n",
    "    **{t: 1.0 for t in config.token_type},\n",
    "    \"cls_ontology\": float(config.cls_ontology_weight),\n",
    "    \"visit_ontology\": float(config.visit_ontology_weight),\n",
    "}\n",
    "loss_types = list(loss_weights.keys())\n",
    "print(loss_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "809a9fbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 001:   0%|          | 0/724 [00:00<?, ?batch/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 001: 100%|██████████| 724/724 [00:45<00:00, 15.76batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 001] Weighted total loss: 0.2842\n",
      "  Raw losses      | diag: 0.0264, med: 0.1061, lab: 0.0836, pro: 0.0254, cls_ontology: 0.4257, visit_ontology: 0.4275\n",
      "  Contributions   | diag: 0.0264, med: 0.1061, lab: 0.0836, pro: 0.0254, cls_ontology: 0.0213, visit_ontology: 0.0214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 002: 100%|██████████| 724/724 [00:50<00:00, 14.30batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 002] Weighted total loss: 0.2363\n",
      "  Raw losses      | diag: 0.0174, med: 0.0920, lab: 0.0728, pro: 0.0158, cls_ontology: 0.3820, visit_ontology: 0.3853\n",
      "  Contributions   | diag: 0.0174, med: 0.0920, lab: 0.0728, pro: 0.0158, cls_ontology: 0.0191, visit_ontology: 0.0193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 003: 100%|██████████| 724/724 [00:48<00:00, 15.02batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 003] Weighted total loss: 0.2300\n",
      "  Raw losses      | diag: 0.0170, med: 0.0885, lab: 0.0718, pro: 0.0150, cls_ontology: 0.3750, visit_ontology: 0.3773\n",
      "  Contributions   | diag: 0.0170, med: 0.0885, lab: 0.0718, pro: 0.0150, cls_ontology: 0.0187, visit_ontology: 0.0189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 004: 100%|██████████| 724/724 [00:48<00:00, 14.79batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 004] Weighted total loss: 0.2266\n",
      "  Raw losses      | diag: 0.0168, med: 0.0869, lab: 0.0712, pro: 0.0146, cls_ontology: 0.3714, visit_ontology: 0.3725\n",
      "  Contributions   | diag: 0.0168, med: 0.0869, lab: 0.0712, pro: 0.0146, cls_ontology: 0.0186, visit_ontology: 0.0186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 005: 100%|██████████| 724/724 [00:51<00:00, 14.15batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 005] Weighted total loss: 0.2233\n",
      "  Raw losses      | diag: 0.0166, med: 0.0849, lab: 0.0707, pro: 0.0143, cls_ontology: 0.3683, visit_ontology: 0.3695\n",
      "  Contributions   | diag: 0.0166, med: 0.0849, lab: 0.0707, pro: 0.0143, cls_ontology: 0.0184, visit_ontology: 0.0185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 006: 100%|██████████| 724/724 [00:51<00:00, 14.08batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 006] Weighted total loss: 0.2205\n",
      "  Raw losses      | diag: 0.0164, med: 0.0833, lab: 0.0703, pro: 0.0140, cls_ontology: 0.3651, visit_ontology: 0.3670\n",
      "  Contributions   | diag: 0.0164, med: 0.0833, lab: 0.0703, pro: 0.0140, cls_ontology: 0.0183, visit_ontology: 0.0183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 007: 100%|██████████| 724/724 [00:47<00:00, 15.30batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 007] Weighted total loss: 0.2181\n",
      "  Raw losses      | diag: 0.0162, med: 0.0818, lab: 0.0699, pro: 0.0138, cls_ontology: 0.3623, visit_ontology: 0.3637\n",
      "  Contributions   | diag: 0.0162, med: 0.0818, lab: 0.0699, pro: 0.0138, cls_ontology: 0.0181, visit_ontology: 0.0182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 008: 100%|██████████| 724/724 [00:52<00:00, 13.78batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 008] Weighted total loss: 0.2162\n",
      "  Raw losses      | diag: 0.0161, med: 0.0808, lab: 0.0696, pro: 0.0136, cls_ontology: 0.3602, visit_ontology: 0.3619\n",
      "  Contributions   | diag: 0.0161, med: 0.0808, lab: 0.0696, pro: 0.0136, cls_ontology: 0.0180, visit_ontology: 0.0181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 009: 100%|██████████| 724/724 [00:48<00:00, 14.94batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 009] Weighted total loss: 0.2149\n",
      "  Raw losses      | diag: 0.0160, med: 0.0803, lab: 0.0693, pro: 0.0134, cls_ontology: 0.3585, visit_ontology: 0.3602\n",
      "  Contributions   | diag: 0.0160, med: 0.0803, lab: 0.0693, pro: 0.0134, cls_ontology: 0.0179, visit_ontology: 0.0180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 010: 100%|██████████| 724/724 [00:51<00:00, 14.04batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 010] Weighted total loss: 0.2134\n",
      "  Raw losses      | diag: 0.0159, med: 0.0794, lab: 0.0691, pro: 0.0132, cls_ontology: 0.3569, visit_ontology: 0.3584\n",
      "  Contributions   | diag: 0.0159, med: 0.0794, lab: 0.0691, pro: 0.0132, cls_ontology: 0.0178, visit_ontology: 0.0179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 011: 100%|██████████| 724/724 [00:49<00:00, 14.64batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 011] Weighted total loss: 0.2123\n",
      "  Raw losses      | diag: 0.0158, med: 0.0788, lab: 0.0689, pro: 0.0131, cls_ontology: 0.3558, visit_ontology: 0.3581\n",
      "  Contributions   | diag: 0.0158, med: 0.0788, lab: 0.0689, pro: 0.0131, cls_ontology: 0.0178, visit_ontology: 0.0179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 012: 100%|██████████| 724/724 [00:47<00:00, 15.10batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 012] Weighted total loss: 0.2112\n",
      "  Raw losses      | diag: 0.0157, med: 0.0783, lab: 0.0687, pro: 0.0129, cls_ontology: 0.3545, visit_ontology: 0.3564\n",
      "  Contributions   | diag: 0.0157, med: 0.0783, lab: 0.0687, pro: 0.0129, cls_ontology: 0.0177, visit_ontology: 0.0178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 013: 100%|██████████| 724/724 [00:51<00:00, 14.02batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 013] Weighted total loss: 0.2104\n",
      "  Raw losses      | diag: 0.0157, med: 0.0778, lab: 0.0686, pro: 0.0128, cls_ontology: 0.3541, visit_ontology: 0.3560\n",
      "  Contributions   | diag: 0.0157, med: 0.0778, lab: 0.0686, pro: 0.0128, cls_ontology: 0.0177, visit_ontology: 0.0178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 014: 100%|██████████| 724/724 [00:50<00:00, 14.28batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 014] Weighted total loss: 0.2097\n",
      "  Raw losses      | diag: 0.0156, med: 0.0776, lab: 0.0683, pro: 0.0128, cls_ontology: 0.3542, visit_ontology: 0.3556\n",
      "  Contributions   | diag: 0.0156, med: 0.0776, lab: 0.0683, pro: 0.0128, cls_ontology: 0.0177, visit_ontology: 0.0178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 015: 100%|██████████| 724/724 [00:53<00:00, 13.62batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 015] Weighted total loss: 0.2090\n",
      "  Raw losses      | diag: 0.0155, med: 0.0773, lab: 0.0682, pro: 0.0126, cls_ontology: 0.3520, visit_ontology: 0.3535\n",
      "  Contributions   | diag: 0.0155, med: 0.0773, lab: 0.0682, pro: 0.0126, cls_ontology: 0.0176, visit_ontology: 0.0177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 016: 100%|██████████| 724/724 [00:47<00:00, 15.18batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 016] Weighted total loss: 0.2081\n",
      "  Raw losses      | diag: 0.0154, med: 0.0769, lab: 0.0681, pro: 0.0125, cls_ontology: 0.3504, visit_ontology: 0.3520\n",
      "  Contributions   | diag: 0.0154, med: 0.0769, lab: 0.0681, pro: 0.0125, cls_ontology: 0.0175, visit_ontology: 0.0176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 017: 100%|██████████| 724/724 [00:54<00:00, 13.25batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 017] Weighted total loss: 0.2075\n",
      "  Raw losses      | diag: 0.0154, med: 0.0766, lab: 0.0680, pro: 0.0124, cls_ontology: 0.3504, visit_ontology: 0.3520\n",
      "  Contributions   | diag: 0.0154, med: 0.0766, lab: 0.0680, pro: 0.0124, cls_ontology: 0.0175, visit_ontology: 0.0176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 018: 100%|██████████| 724/724 [00:48<00:00, 14.96batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 018] Weighted total loss: 0.2067\n",
      "  Raw losses      | diag: 0.0153, med: 0.0762, lab: 0.0678, pro: 0.0123, cls_ontology: 0.3493, visit_ontology: 0.3502\n",
      "  Contributions   | diag: 0.0153, med: 0.0762, lab: 0.0678, pro: 0.0123, cls_ontology: 0.0175, visit_ontology: 0.0175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 019: 100%|██████████| 724/724 [00:50<00:00, 14.22batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 019] Weighted total loss: 0.2064\n",
      "  Raw losses      | diag: 0.0153, med: 0.0761, lab: 0.0678, pro: 0.0123, cls_ontology: 0.3484, visit_ontology: 0.3499\n",
      "  Contributions   | diag: 0.0153, med: 0.0761, lab: 0.0678, pro: 0.0123, cls_ontology: 0.0174, visit_ontology: 0.0175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 020: 100%|██████████| 724/724 [00:52<00:00, 13.79batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 020] Weighted total loss: 0.2056\n",
      "  Raw losses      | diag: 0.0152, med: 0.0759, lab: 0.0676, pro: 0.0122, cls_ontology: 0.3470, visit_ontology: 0.3486\n",
      "  Contributions   | diag: 0.0152, med: 0.0759, lab: 0.0676, pro: 0.0122, cls_ontology: 0.0174, visit_ontology: 0.0174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 1 + config.epochs):\n",
    "    model.train()\n",
    "    avg_total_loss = 0.0\n",
    "    avg_loss_dict = {t: 0.0 for t in loss_types}         # 未加权分项\n",
    "    avg_contrib_dict = {t: 0.0 for t in loss_types}      # 加权后贡献\n",
    "    step_iter = tqdm(pretrain_dataloader, desc=f\"Epoch {epoch:03d}\", unit=\"batch\")\n",
    "\n",
    "    for step, batch in enumerate(step_iter):\n",
    "        batch = [x.to(device) if isinstance(x, torch.Tensor) else x for x in batch]\n",
    "        loss_dict = model(*batch)   # {loss_type: tensor}\n",
    "\n",
    "        # 总 loss（加权）\n",
    "        total_loss = sum(loss_weights[t] * loss_dict[t] for t in loss_types)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # 累积\n",
    "        avg_total_loss += total_loss.item()\n",
    "        for t in loss_types:\n",
    "            avg_loss_dict[t] += loss_dict[t].item()                       # 原始 loss\n",
    "            avg_contrib_dict[t] += (loss_weights[t] * loss_dict[t]).item()  # 加权后贡献\n",
    "\n",
    "    steps = step + 1\n",
    "    avg_total_loss /= steps\n",
    "    avg_loss_dict = {t: v / steps for t, v in avg_loss_dict.items()}\n",
    "    avg_contrib_dict = {t: v / steps for t, v in avg_contrib_dict.items()}\n",
    "\n",
    "    # 日志字符串\n",
    "    raw_loss_str = \", \".join(f\"{t}: {avg_loss_dict[t]:.4f}\" for t in loss_types)\n",
    "    contrib_str  = \", \".join(f\"{t}: {avg_contrib_dict[t]:.4f}\" for t in loss_types)\n",
    "\n",
    "    print(f\"[Epoch {epoch:03d}] Weighted total loss: {avg_total_loss:.4f}\\n\"\n",
    "          f\"  Raw losses      | {raw_loss_str}\\n\"\n",
    "          f\"  Contributions   | {contrib_str}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6a15c1a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save model: MIMIC-III-0.7-64-0.05-0.05\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "exp_name = (\n",
    "    f\"{config.dataset}-{config.pretrain_mask_rate}-{config.d_model}-{config.cls_ontology_weight}-{config.visit_ontology_weight}\"\n",
    ")\n",
    "save_path = \"./pretrained_models/\" + exp_name\n",
    "if not os.path.exists(save_path):\n",
    "    os.makedirs(save_path)\n",
    "torch.save(model.cpu().state_dict(), f\"{save_path}/pretrained_model.pt\")\n",
    "print(\"Save model:\", exp_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
