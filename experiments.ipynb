{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9bc53801",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Disabling PyTorch because PyTorch >= 2.1 is required but found 1.13.1\n",
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pickle\n",
    "import numpy as np\n",
    "from argparse import Namespace\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "from heterogt.utils.tokenizer import EHRTokenizer\n",
    "from heterogt.utils.dataset import FineTuneEHRDataset, batcher, expand_level3\n",
    "from heterogt.utils.train import train_with_early_stopping\n",
    "from heterogt.utils.seed import set_random_seed\n",
    "from heterogt.model.model import HeteroGT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c42d3e09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Random seed set to 123\n"
     ]
    }
   ],
   "source": [
    "set_random_seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af3d65aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d073b89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Namespace(\n",
    "    dataset = \"MIMIC-III\",\n",
    "    tasks = [\"death\", \"readmission\", \"stay\", \"next_diag_6m\", \"next_diag_12m\"], \n",
    "    task_index = 2,  # index of the task to train\n",
    "    token_type = [\"diag\", \"med\", \"lab\", \"pro\"],\n",
    "    special_tokens = [\"[PAD]\", \"[CLS]\"],\n",
    "    batch_size = 32,\n",
    "    lr = 1e-3,\n",
    "    epochs = 500,\n",
    "    early_stop_patience = 5,\n",
    "    group_code_thre = 5,  # if there are group_code_thre diag codes belongs to the same group ICD code, then the group code is generated\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bbe56943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current task: stay\n"
     ]
    }
   ],
   "source": [
    "full_data_path = f\"./data_process/{config.dataset}-processed/mimic.pkl\"  # for tokenizer\n",
    "curr_task = config.tasks[config.task_index]\n",
    "print(\"Current task:\", curr_task)\n",
    "if curr_task == \"next_diag_6m\":\n",
    "    finetune_data_path = f\"./data_process/{config.dataset}-processed/mimic_nextdiag_6m.pkl\"\n",
    "elif curr_task == \"next_diag_12m\":\n",
    "    finetune_data_path = f\"./data_process/{config.dataset}-processed/mimic_nextdiag_12m.pkl\"\n",
    "else:\n",
    "    finetune_data_path = f\"./data_process/{config.dataset}-processed/mimic_downstream.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57d4378a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max admissions per patient: 8\n"
     ]
    }
   ],
   "source": [
    "ehr_full_data = pickle.load(open(full_data_path, 'rb'))\n",
    "group_code_sentences = [expand_level3()[1]]\n",
    "diag_sentences = ehr_full_data[\"ICD9_CODE\"].values.tolist()\n",
    "med_sentences = ehr_full_data[\"NDC\"].values.tolist()\n",
    "lab_sentences = ehr_full_data[\"LAB_TEST\"].values.tolist()\n",
    "pro_sentences = ehr_full_data[\"PRO_CODE\"].values.tolist()\n",
    "age_sentences = [[str(c)] for c in set(ehr_full_data[\"AGE\"].values.tolist())] # important of [[]]\n",
    "max_admissions = ehr_full_data.groupby(\"SUBJECT_ID\")[\"HADM_ID\"].nunique().max()\n",
    "config.max_num_adms = max_admissions\n",
    "print(f\"Max admissions per patient: {config.max_num_adms}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8db4baa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age vocabulary size: 18\n",
      "Group code vocabulary size: 19\n"
     ]
    }
   ],
   "source": [
    "tokenizer = EHRTokenizer(age_sentences, group_code_sentences, diag_sentences, med_sentences, lab_sentences, \n",
    "                         pro_sentences, special_tokens=config.special_tokens)\n",
    "config.label_vocab_size = len(tokenizer.diag_voc.id2word)  # only for diagnosis\n",
    "config.global_vocab_size = len(tokenizer.vocab.id2word)\n",
    "config.age_vocab_size = tokenizer.token_number(\"age\")\n",
    "config.group_code_vocab_size = tokenizer.token_number(\"group\")\n",
    "print(f\"Age vocabulary size: {config.age_vocab_size}\")\n",
    "print(f\"Group code vocabulary size: {config.group_code_vocab_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a50b960",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of DEATH in test dataset: 28.648477157360407 %\n",
      "Percentage of READMISSION in test dataset: 40.1491116751269 %\n",
      "Percentage of STAY>7 days in test dataset: 50.58692893401015 %\n"
     ]
    }
   ],
   "source": [
    "train_data, val_data, test_data = pickle.load(open(finetune_data_path, 'rb'))\n",
    "# example label percentage\n",
    "print(\"Percentage of DEATH in test dataset:\",\n",
    "      (test_data[\"DEATH\"] == True).mean() * 100, \"%\")\n",
    "\n",
    "print(\"Percentage of READMISSION in test dataset:\",\n",
    "      (test_data[\"READMISSION\"] == 1).mean() * 100, \"%\")\n",
    "\n",
    "print(\"Percentage of STAY>7 days in test dataset:\",\n",
    "      (test_data[\"STAY_DAYS\"] > 7).mean() * 100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "09f0ec18",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = FineTuneEHRDataset(train_data, tokenizer, token_type=config.token_type, task=curr_task, \n",
    "                                   max_num_adms=config.max_num_adms, group_code_thre=config.group_code_thre)\n",
    "val_dataset = FineTuneEHRDataset(val_data, tokenizer, token_type=config.token_type, task=curr_task, \n",
    "                                 max_num_adms=config.max_num_adms, group_code_thre=config.group_code_thre)\n",
    "test_dataset = FineTuneEHRDataset(test_data, tokenizer, token_type=config.token_type, task=curr_task, \n",
    "                                   max_num_adms=config.max_num_adms, group_code_thre=config.group_code_thre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "98c78018",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean group token numer per patient 0.7971893963589908\n"
     ]
    }
   ],
   "source": [
    "num_group_code = []\n",
    "for i in range(len(train_dataset)):\n",
    "    input_ids, token_types, adm_index, age_ids, diag_group_codes, labels = train_dataset[i]\n",
    "    count = (token_types[0] == 6).sum().item()\n",
    "    num_group_code.append(count)\n",
    "print(\"Mean group token numer per patient\", np.mean(num_group_code))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d71f325f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    collate_fn=batcher(tokenizer, n_token_type=len(config.token_type), is_pretrain = False),\n",
    "    shuffle=True,\n",
    "    batch_size=config.batch_size,\n",
    ")\n",
    "\n",
    "val_dataloader = DataLoader(\n",
    "    val_dataset,\n",
    "    collate_fn=batcher(tokenizer, n_token_type=len(config.token_type), is_pretrain = False),\n",
    "    shuffle=False,\n",
    "    batch_size=config.batch_size,\n",
    ")\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset,\n",
    "    collate_fn=batcher(tokenizer, n_token_type=len(config.token_type), is_pretrain = False),\n",
    "    shuffle=False,\n",
    "    batch_size=config.batch_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7b46906f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All pass!\n"
     ]
    }
   ],
   "source": [
    "for batch in train_dataloader:\n",
    "    pass  # just to check if the dataloader works\n",
    "for batch in val_dataloader:\n",
    "    pass  # just to check if the dataloader works\n",
    "for batch in test_dataloader:\n",
    "    pass  # just to check if the dataloader works\n",
    "print(\"All pass!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "10339a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "if curr_task in [\"death\", \"stay\", \"readmission\"]:\n",
    "    eval_metric = \"f1\"\n",
    "    task_type = \"binary\"\n",
    "    loss_fn = F.binary_cross_entropy_with_logits\n",
    "else:\n",
    "    eval_metric = \"f1\"\n",
    "    task_type = \"l2r\"\n",
    "    loss_fn = lambda x, y: F.binary_cross_entropy_with_logits(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d5717b84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input IDs shape: torch.Size([32, 293])\n",
      "Token Types shape: torch.Size([32, 293])\n",
      "Admission Index shape: torch.Size([32, 293])\n",
      "Age IDs shape: torch.Size([32, 8])\n",
      "Diag Code Group Dict number: 32\n",
      "Labels shape: torch.Size([32, 1])\n"
     ]
    }
   ],
   "source": [
    "input_ids, token_types, adm_index, age_ids, diag_code_group_dicts, labels = next(iter(train_dataloader))\n",
    "print(\"Input IDs shape:\", input_ids.shape)\n",
    "print(\"Token Types shape:\", token_types.shape)\n",
    "print(\"Admission Index shape:\", adm_index.shape)\n",
    "print(\"Age IDs shape:\", age_ids.shape)\n",
    "print(\"Diag Code Group Dict number:\", len(diag_code_group_dicts))\n",
    "print(\"Labels shape:\", labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814e9e16",
   "metadata": {},
   "source": [
    "# Model Walkthrough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4ec004c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_mask_dicts = [{1:[6,7], 2:[6,7], 3:[6,7], 4:[6,7], 6:[2,3,4,5,6,7], 7:[2,3,4,5,6,7]}, \n",
    "                   {1:[6,7], 2:[6,7], 3:[6,7], 4:[6,7], 6:[2,3,4,5,6,7], 7:[2,3,4,5,6,7]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0fed5f6-b245-4bc3-b252-f6af0756f18a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 001: 100%|██████████| 98/98 [00:07<00:00, 13.88it/s, loss=0.6937]\n",
      "Running inference: 100%|██████████| 198/198 [00:08<00:00, 22.19it/s]\n",
      "Running inference: 100%|██████████| 197/197 [00:09<00:00, 21.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: {'precision': 0.6182373472935903, 'recall': 0.8886798369366928, 'f1': 0.7291907837864662, 'auc': 0.7807708510983115, 'prauc': 0.7824556976905184}\n",
      "Test:      {'precision': 0.6115810019505279, 'recall': 0.8842897459991086, 'f1': 0.7230769182412495, 'auc': 0.7717335423181714, 'prauc': 0.7736575545837455}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 002: 100%|██████████| 98/98 [00:06<00:00, 15.63it/s, loss=0.6070]\n",
      "Running inference: 100%|██████████| 198/198 [00:09<00:00, 21.96it/s]\n",
      "Running inference: 100%|██████████| 197/197 [00:09<00:00, 21.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: {'precision': 0.6828229027944532, 'recall': 0.8040137974261399, 'f1': 0.738479257703903, 'auc': 0.8046067420358893, 'prauc': 0.8168990861575831}\n",
      "Test:      {'precision': 0.6787148594359338, 'recall': 0.7949200376268583, 'f1': 0.7322356969353889, 'auc': 0.7979962722983853, 'prauc': 0.8132044772530707}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 003: 100%|██████████| 98/98 [00:06<00:00, 15.93it/s, loss=0.5582]\n",
      "Running inference: 100%|██████████| 198/198 [00:08<00:00, 22.39it/s]\n",
      "Running inference: 100%|██████████| 197/197 [00:09<00:00, 21.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: {'precision': 0.8195187165738881, 'recall': 0.5766698024440995, 'f1': 0.6769740426363543, 'auc': 0.8108900056857977, 'prauc': 0.8198505626676416}\n",
      "Test:      {'precision': 0.8082311733764964, 'recall': 0.5788648479128916, 'f1': 0.6745843181746299, 'auc': 0.8027187659022512, 'prauc': 0.816319156690563}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 004: 100%|██████████| 98/98 [00:06<00:00, 15.88it/s, loss=0.5411]\n",
      "Running inference: 100%|██████████| 198/198 [00:09<00:00, 21.74it/s]\n",
      "Running inference: 100%|██████████| 197/197 [00:09<00:00, 21.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: {'precision': 0.8223483195075411, 'recall': 0.5907808090291917, 'f1': 0.6875912360076676, 'auc': 0.8159373442974082, 'prauc': 0.821034688942649}\n",
      "Test:      {'precision': 0.8089792460787422, 'recall': 0.5989338350561338, 'f1': 0.6882882833970951, 'auc': 0.8105847397781399, 'prauc': 0.8234294421384032}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 005: 100%|██████████| 98/98 [00:06<00:00, 15.61it/s, loss=0.4940]\n",
      "Running inference: 100%|██████████| 198/198 [00:09<00:00, 21.94it/s]\n",
      "Running inference: 100%|██████████| 197/197 [00:09<00:00, 21.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: {'precision': 0.7980732177233215, 'recall': 0.6494198808383524, 'f1': 0.7161134113711425, 'auc': 0.8228280207445713, 'prauc': 0.827766555808411}\n",
      "Test:      {'precision': 0.784125766868159, 'recall': 0.6412668548114103, 'f1': 0.7055373419513613, 'auc': 0.8131946342438165, 'prauc': 0.8223019330661526}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 006: 100%|██████████| 98/98 [00:06<00:00, 16.05it/s, loss=0.4506]\n",
      "Running inference: 100%|██████████| 198/198 [00:08<00:00, 22.01it/s]\n",
      "Running inference: 100%|██████████| 197/197 [00:09<00:00, 21.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: {'precision': 0.7232884560277191, 'recall': 0.7917842583857266, 'f1': 0.755988018960052, 'auc': 0.8225153973191046, 'prauc': 0.8247692616973521}\n",
      "Test:      {'precision': 0.7188847369913226, 'recall': 0.7842583882070108, 'f1': 0.7501499650132063, 'auc': 0.8152602721936915, 'prauc': 0.8176290976106607}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 007: 100%|██████████| 98/98 [00:06<00:00, 15.96it/s, loss=0.4260]\n",
      "Running inference: 100%|██████████| 198/198 [00:08<00:00, 22.23it/s]\n",
      "Running inference: 100%|██████████| 197/197 [00:09<00:00, 21.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: {'precision': 0.7920651788849024, 'recall': 0.7011602383170237, 'f1': 0.7438456370652912, 'auc': 0.8352364529262869, 'prauc': 0.8370042955094231}\n",
      "Test:      {'precision': 0.7746773630946122, 'recall': 0.6964565694553263, 'f1': 0.7334874454740645, 'auc': 0.8225070429199088, 'prauc': 0.8304401361340079}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 008: 100%|██████████| 98/98 [00:06<00:00, 16.30it/s, loss=0.3905]\n",
      "Running inference: 100%|██████████| 198/198 [00:09<00:00, 21.86it/s]\n",
      "Running inference: 100%|██████████| 197/197 [00:08<00:00, 21.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: {'precision': 0.7384848484826106, 'recall': 0.7641894010637686, 'f1': 0.7511172703882681, 'auc': 0.8202993026432881, 'prauc': 0.8187441901823803}\n",
      "Test:      {'precision': 0.7263189448419475, 'recall': 0.7597993101261844, 'f1': 0.7426819873374262, 'auc': 0.8120598646933908, 'prauc': 0.8146962436197458}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 009: 100%|██████████| 98/98 [00:06<00:00, 16.13it/s, loss=0.3774]\n",
      "Running inference: 100%|██████████| 198/198 [00:09<00:00, 21.96it/s]\n",
      "Running inference: 100%|██████████| 197/197 [00:09<00:00, 21.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: {'precision': 0.7509079903124973, 'recall': 0.7779868297247476, 'f1': 0.7642076031926538, 'auc': 0.8335723096526237, 'prauc': 0.8366192888043034}\n",
      "Test:      {'precision': 0.7360024081856231, 'recall': 0.7666980244566739, 'f1': 0.7510367021108223, 'auc': 0.8229557160524215, 'prauc': 0.8321821314783768}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 010: 100%|██████████| 98/98 [00:06<00:00, 15.99it/s, loss=0.3403]\n",
      "Running inference: 100%|██████████| 198/198 [00:09<00:00, 21.86it/s]\n",
      "Running inference: 100%|██████████| 197/197 [00:09<00:00, 21.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: {'precision': 0.7354497354475736, 'recall': 0.784571966131124, 'f1': 0.7592171092496182, 'auc': 0.8220537716310744, 'prauc': 0.8168955324389202}\n",
      "Test:      {'precision': 0.7221095334664674, 'recall': 0.7814361868899924, 'f1': 0.7506024046440781, 'auc': 0.8156597191288071, 'prauc': 0.8136602337787939}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 011: 100%|██████████| 98/98 [00:06<00:00, 15.89it/s, loss=0.3102]\n",
      "Running inference: 100%|██████████| 198/198 [00:08<00:00, 22.15it/s]\n",
      "Running inference: 100%|██████████| 197/197 [00:09<00:00, 21.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: {'precision': 0.7499225286620703, 'recall': 0.7588585763538449, 'f1': 0.7543640847733851, 'auc': 0.8265832696079896, 'prauc': 0.8235547766108247}\n",
      "Test:      {'precision': 0.7423088638417841, 'recall': 0.7641894010637686, 'f1': 0.7530902298565768, 'auc': 0.8219437603278122, 'prauc': 0.8247757466506267}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 012: 100%|██████████| 98/98 [00:06<00:00, 15.62it/s, loss=0.2753]\n",
      "Running inference: 100%|██████████| 198/198 [00:09<00:00, 21.81it/s]\n",
      "Running inference: 100%|██████████| 197/197 [00:09<00:00, 21.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: {'precision': 0.836444007854438, 'recall': 0.5340232047647099, 'f1': 0.6518660239491149, 'auc': 0.8217621974126255, 'prauc': 0.8203683172264054}\n",
      "Test:      {'precision': 0.8373435996109849, 'recall': 0.5456255879568968, 'f1': 0.6607176713164107, 'auc': 0.816913879824658, 'prauc': 0.8204478420416552}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 013: 100%|██████████| 98/98 [00:06<00:00, 15.82it/s, loss=0.2655]\n",
      "Running inference: 100%|██████████| 198/198 [00:08<00:00, 22.30it/s]\n",
      "Running inference: 100%|██████████| 197/197 [00:09<00:00, 21.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: {'precision': 0.7136715391209124, 'recall': 0.780809031041766, 'f1': 0.7457322501740747, 'auc': 0.803292598345261, 'prauc': 0.7824360326023453}\n",
      "Test:      {'precision': 0.7064846416362159, 'recall': 0.7789275634970871, 'f1': 0.7409395923251186, 'auc': 0.7991573662877054, 'prauc': 0.7880339026180059}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 014: 100%|██████████| 98/98 [00:06<00:00, 15.35it/s, loss=0.2454]\n",
      "Running inference: 100%|██████████| 198/198 [00:09<00:00, 21.89it/s]\n",
      "Running inference: 100%|██████████| 197/197 [00:09<00:00, 21.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: {'precision': 0.7065277015888466, 'recall': 0.8077767325154978, 'f1': 0.7537673688314125, 'auc': 0.8158211466462585, 'prauc': 0.8077874876075928}\n",
      "Test:      {'precision': 0.7003522080717953, 'recall': 0.8105989338325161, 'f1': 0.7514534833965283, 'auc': 0.8116454686983297, 'prauc': 0.8098451794687016}\n",
      "\n",
      "Early stopping triggered (no improvement for 5 epochs).\n",
      "\n",
      "Best validation performance:\n",
      "{'precision': 0.7509079903124973, 'recall': 0.7779868297247476, 'f1': 0.7642076031926538, 'auc': 0.8335723096526237, 'prauc': 0.8366192888043034}\n",
      "Corresponding test performance:\n",
      "{'precision': 0.7360024081856231, 'recall': 0.7666980244566739, 'f1': 0.7510367021108223, 'auc': 0.8229557160524215, 'prauc': 0.8321821314783768}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 001: 100%|██████████| 98/98 [00:06<00:00, 15.39it/s, loss=0.7032]\n",
      "Running inference: 100%|██████████| 198/198 [00:08<00:00, 22.01it/s]\n",
      "Running inference: 100%|██████████| 197/197 [00:09<00:00, 21.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: {'precision': 0.8037552998134238, 'recall': 0.41611790529816206, 'f1': 0.5483471029406352, 'auc': 0.7669860318667914, 'prauc': 0.7696888149509129}\n",
      "Test:      {'precision': 0.7948717948669423, 'recall': 0.4082784571953331, 'f1': 0.5394655020397823, 'auc': 0.7602900620964823, 'prauc': 0.7563828272213458}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 002: 100%|██████████| 98/98 [00:06<00:00, 15.81it/s, loss=0.6256]\n",
      "Running inference: 100%|██████████| 198/198 [00:09<00:00, 21.79it/s]\n",
      "Running inference: 100%|██████████| 197/197 [00:09<00:00, 21.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: {'precision': 0.7276154571136425, 'recall': 0.7262464722460764, 'f1': 0.7269303151483821, 'auc': 0.8015810315598448, 'prauc': 0.8139979695950348}\n",
      "Test:      {'precision': 0.7276178424526175, 'recall': 0.7212292254602658, 'f1': 0.7244094438167133, 'auc': 0.7966955530825012, 'prauc': 0.8083947367054606}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 003: 100%|██████████| 98/98 [00:06<00:00, 15.79it/s, loss=0.5600]\n",
      "Running inference: 100%|██████████| 198/198 [00:08<00:00, 22.26it/s]\n",
      "Running inference: 100%|██████████| 197/197 [00:09<00:00, 21.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: {'precision': 0.8014557217921494, 'recall': 0.6215114455922812, 'f1': 0.7001059646995257, 'auc': 0.8171718627061202, 'prauc': 0.8289747019881051}\n",
      "Test:      {'precision': 0.7898724082903116, 'recall': 0.6211978676681681, 'f1': 0.6954537426554526, 'auc': 0.8085342018888162, 'prauc': 0.8244293927122426}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 004: 100%|██████████| 98/98 [00:06<00:00, 15.84it/s, loss=0.5230]\n",
      "Running inference:  70%|██████▉   | 138/198 [00:06<00:02, 21.71it/s]"
     ]
    }
   ],
   "source": [
    "final_metrics = []\n",
    "for i in range(10):\n",
    "    model = HeteroGT(tokenizer, d_model=64, num_heads=4, layer_types=['gnn', 'tf', 'gnn', 'tf'], max_num_adms=config.max_num_adms, \n",
    "                     device=device, task=curr_task, label_vocab_size=config.label_vocab_size, attn_mask_dicts=attn_mask_dicts,\n",
    "                     use_cls_cat=True).to(device)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=config.lr)\n",
    "    best_test_metric = train_with_early_stopping(model, train_dataloader, val_dataloader, test_dataloader,\n",
    "                                             optimizer, loss_fn, device, config.early_stop_patience, task_type, config.epochs, \n",
    "                                             val_long_seq_idx=None, test_long_seq_idx=None, eval_metric=eval_metric, return_model=False)\n",
    "    final_metrics.append(best_test_metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b5b571",
   "metadata": {},
   "outputs": [],
   "source": [
    "def topk_avg_performance_formatted(performances, k=5):\n",
    "    metrics = [\"f1\", \"auc\", \"prauc\"]\n",
    "    scores = {m: np.array([p[m] for p in performances]) for m in metrics}\n",
    "\n",
    "    # 计算排名（值越大排名越靠前）\n",
    "    ranks = {m: (-scores[m]).argsort().argsort() + 1 for m in metrics}\n",
    "    avg_ranks = np.mean(np.stack([ranks[m] for m in metrics], axis=1), axis=1)\n",
    "\n",
    "    # 选 top-k\n",
    "    topk_idx = np.argsort(avg_ranks)[:k]\n",
    "    final_avg = {m: np.mean([performances[i][m] for i in topk_idx]) for m in performances[0].keys()}\n",
    "    final_std = {m: np.std([performances[i][m] for i in topk_idx], ddof=0) for m in performances[0].keys()}\n",
    "\n",
    "    # 打印结果\n",
    "    print(\"Final Metrics:\")\n",
    "    for m in performances[0].keys():\n",
    "        print(f\"{m}: {final_avg[m]:.4f}±{final_std[m]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12dd11d-4936-466a-9a97-e10f223539fc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Metrics:\n",
      "precision: 0.7169±0.0089\n",
      "recall: 0.8033±0.0202\n",
      "f1: 0.7574±0.0046\n",
      "auc: 0.8245±0.0014\n",
      "prauc: 0.8311±0.0042\n"
     ]
    }
   ],
   "source": [
    "topk_avg_performance_formatted(final_metrics, 5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
