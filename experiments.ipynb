{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9bc53801",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Disabling PyTorch because PyTorch >= 2.1 is required but found 1.13.1\n",
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pickle\n",
    "import numpy as np\n",
    "from argparse import Namespace\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "from heterogt.utils.tokenizer import EHRTokenizer\n",
    "from heterogt.utils.dataset import FineTuneEHRDataset, batcher, expand_level3\n",
    "from heterogt.utils.train import train_with_early_stopping\n",
    "from heterogt.utils.seed import set_random_seed\n",
    "from heterogt.model.model import HeteroGT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c42d3e09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Random seed set to 123\n"
     ]
    }
   ],
   "source": [
    "set_random_seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af3d65aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d073b89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Namespace(\n",
    "    dataset = \"MIMIC-III\",\n",
    "    tasks = [\"death\", \"readmission\", \"stay\", \"next_diag_6m\", \"next_diag_12m\"], \n",
    "    task_index = 2,  # index of the task to train\n",
    "    token_type = [\"diag\", \"med\", \"lab\", \"pro\"],\n",
    "    special_tokens = [\"[PAD]\", \"[CLS]\"],\n",
    "    batch_size = 32,\n",
    "    lr = 1e-3,\n",
    "    epochs = 500,\n",
    "    early_stop_patience = 5,\n",
    "    group_code_thre = 5,  # if there are group_code_thre diag codes belongs to the same group ICD code, then the group code is generated\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bbe56943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current task: stay\n"
     ]
    }
   ],
   "source": [
    "full_data_path = f\"./data_process/{config.dataset}-processed/mimic.pkl\"  # for tokenizer\n",
    "curr_task = config.tasks[config.task_index]\n",
    "print(\"Current task:\", curr_task)\n",
    "if curr_task == \"next_diag_6m\":\n",
    "    finetune_data_path = f\"./data_process/{config.dataset}-processed/mimic_nextdiag_6m.pkl\"\n",
    "elif curr_task == \"next_diag_12m\":\n",
    "    finetune_data_path = f\"./data_process/{config.dataset}-processed/mimic_nextdiag_12m.pkl\"\n",
    "else:\n",
    "    finetune_data_path = f\"./data_process/{config.dataset}-processed/mimic_downstream.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57d4378a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max admissions per patient: 8\n"
     ]
    }
   ],
   "source": [
    "ehr_full_data = pickle.load(open(full_data_path, 'rb'))\n",
    "group_code_sentences = [expand_level3()[1]]\n",
    "diag_sentences = ehr_full_data[\"ICD9_CODE\"].values.tolist()\n",
    "med_sentences = ehr_full_data[\"NDC\"].values.tolist()\n",
    "lab_sentences = ehr_full_data[\"LAB_TEST\"].values.tolist()\n",
    "pro_sentences = ehr_full_data[\"PRO_CODE\"].values.tolist()\n",
    "age_sentences = [[str(c)] for c in set(ehr_full_data[\"AGE\"].values.tolist())] # important of [[]]\n",
    "max_admissions = ehr_full_data.groupby(\"SUBJECT_ID\")[\"HADM_ID\"].nunique().max()\n",
    "config.max_num_adms = max_admissions\n",
    "print(f\"Max admissions per patient: {config.max_num_adms}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8db4baa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age vocabulary size: 18\n",
      "Group code vocabulary size: 19\n"
     ]
    }
   ],
   "source": [
    "tokenizer = EHRTokenizer(age_sentences, group_code_sentences, diag_sentences, med_sentences, lab_sentences, \n",
    "                         pro_sentences, special_tokens=config.special_tokens)\n",
    "config.label_vocab_size = len(tokenizer.diag_voc.id2word)  # only for diagnosis\n",
    "config.global_vocab_size = len(tokenizer.vocab.id2word)\n",
    "config.age_vocab_size = tokenizer.token_number(\"age\")\n",
    "config.group_code_vocab_size = tokenizer.token_number(\"group\")\n",
    "print(f\"Age vocabulary size: {config.age_vocab_size}\")\n",
    "print(f\"Group code vocabulary size: {config.group_code_vocab_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a50b960",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of DEATH in test dataset: 28.648477157360407 %\n",
      "Percentage of READMISSION in test dataset: 40.1491116751269 %\n",
      "Percentage of STAY>7 days in test dataset: 50.58692893401015 %\n"
     ]
    }
   ],
   "source": [
    "train_data, val_data, test_data = pickle.load(open(finetune_data_path, 'rb'))\n",
    "# example label percentage\n",
    "print(\"Percentage of DEATH in test dataset:\",\n",
    "      (test_data[\"DEATH\"] == True).mean() * 100, \"%\")\n",
    "\n",
    "print(\"Percentage of READMISSION in test dataset:\",\n",
    "      (test_data[\"READMISSION\"] == 1).mean() * 100, \"%\")\n",
    "\n",
    "print(\"Percentage of STAY>7 days in test dataset:\",\n",
    "      (test_data[\"STAY_DAYS\"] > 7).mean() * 100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "09f0ec18",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = FineTuneEHRDataset(train_data, tokenizer, token_type=config.token_type, task=curr_task, \n",
    "                                   max_num_adms=config.max_num_adms, group_code_thre=config.group_code_thre)\n",
    "val_dataset = FineTuneEHRDataset(val_data, tokenizer, token_type=config.token_type, task=curr_task, \n",
    "                                 max_num_adms=config.max_num_adms, group_code_thre=config.group_code_thre)\n",
    "test_dataset = FineTuneEHRDataset(test_data, tokenizer, token_type=config.token_type, task=curr_task, \n",
    "                                   max_num_adms=config.max_num_adms, group_code_thre=config.group_code_thre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "98c78018",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean group token numer per patient 0.7971893963589908\n"
     ]
    }
   ],
   "source": [
    "num_group_code = []\n",
    "for i in range(len(train_dataset)):\n",
    "    input_ids, token_types, adm_index, age_ids, diag_group_codes, labels = train_dataset[i]\n",
    "    count = (token_types[0] == 6).sum().item()\n",
    "    num_group_code.append(count)\n",
    "print(\"Mean group token numer per patient\", np.mean(num_group_code))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d71f325f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    collate_fn=batcher(tokenizer, n_token_type=len(config.token_type), is_pretrain = False),\n",
    "    shuffle=True,\n",
    "    batch_size=config.batch_size,\n",
    ")\n",
    "\n",
    "val_dataloader = DataLoader(\n",
    "    val_dataset,\n",
    "    collate_fn=batcher(tokenizer, n_token_type=len(config.token_type), is_pretrain = False),\n",
    "    shuffle=False,\n",
    "    batch_size=config.batch_size,\n",
    ")\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset,\n",
    "    collate_fn=batcher(tokenizer, n_token_type=len(config.token_type), is_pretrain = False),\n",
    "    shuffle=False,\n",
    "    batch_size=config.batch_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7b46906f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All pass!\n"
     ]
    }
   ],
   "source": [
    "for batch in train_dataloader:\n",
    "    pass  # just to check if the dataloader works\n",
    "for batch in val_dataloader:\n",
    "    pass  # just to check if the dataloader works\n",
    "for batch in test_dataloader:\n",
    "    pass  # just to check if the dataloader works\n",
    "print(\"All pass!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "10339a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "if curr_task in [\"death\", \"stay\", \"readmission\"]:\n",
    "    eval_metric = \"f1\"\n",
    "    task_type = \"binary\"\n",
    "    loss_fn = F.binary_cross_entropy_with_logits\n",
    "else:\n",
    "    eval_metric = \"f1\"\n",
    "    task_type = \"l2r\"\n",
    "    loss_fn = lambda x, y: F.binary_cross_entropy_with_logits(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d5717b84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input IDs shape: torch.Size([32, 293])\n",
      "Token Types shape: torch.Size([32, 293])\n",
      "Admission Index shape: torch.Size([32, 293])\n",
      "Age IDs shape: torch.Size([32, 8])\n",
      "Diag Code Group Dict number: 32\n",
      "Labels shape: torch.Size([32, 1])\n"
     ]
    }
   ],
   "source": [
    "input_ids, token_types, adm_index, age_ids, diag_code_group_dicts, labels = next(iter(train_dataloader))\n",
    "print(\"Input IDs shape:\", input_ids.shape)\n",
    "print(\"Token Types shape:\", token_types.shape)\n",
    "print(\"Admission Index shape:\", adm_index.shape)\n",
    "print(\"Age IDs shape:\", age_ids.shape)\n",
    "print(\"Diag Code Group Dict number:\", len(diag_code_group_dicts))\n",
    "print(\"Labels shape:\", labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814e9e16",
   "metadata": {},
   "source": [
    "# Model Walkthrough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec004c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_mask_dicts = [{1:[6,7], 2:[6,7], 3:[6,7], 4:[6,7], 6:[2,3,4,5,6,7], 7:[2,3,4,5,6,7]}, \n",
    "                   {1:[6,7], 2:[6,7], 3:[6,7], 4:[6,7], 6:[2,3,4,5,6,7], 7:[2,3,4,5,6,7]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0fed5f6-b245-4bc3-b252-f6af0756f18a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 001: 100%|██████████| 98/98 [00:05<00:00, 19.35it/s, loss=0.7380]\n",
      "Running inference: 100%|██████████| 198/198 [00:06<00:00, 30.19it/s]\n",
      "Running inference: 100%|██████████| 197/197 [00:06<00:00, 30.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: {'precision': 0.7077526132373356, 'recall': 0.5095641266838835, 'f1': 0.5925250634986483, 'auc': 0.7216153452838574, 'prauc': 0.7355503104856734}\n",
      "Test:      {'precision': 0.6863340563961547, 'recall': 0.49608027594701765, 'f1': 0.5759009780177781, 'auc': 0.7103284414170501, 'prauc': 0.7292152355217797}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 002: 100%|██████████| 98/98 [00:04<00:00, 20.29it/s, loss=0.6012]\n",
      "Running inference: 100%|██████████| 198/198 [00:06<00:00, 28.30it/s]\n",
      "Running inference: 100%|██████████| 197/197 [00:06<00:00, 30.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: {'precision': 0.6904697986558646, 'recall': 0.8065224208190451, 'f1': 0.7439976808826851, 'auc': 0.805076204660184, 'prauc': 0.8064865102942715}\n",
      "Test:      {'precision': 0.6915688367110684, 'recall': 0.8127939793013083, 'f1': 0.7472970975241866, 'auc': 0.8045596142840532, 'prauc': 0.8079819288475077}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 003: 100%|██████████| 98/98 [00:04<00:00, 20.29it/s, loss=0.5501]\n",
      "Running inference: 100%|██████████| 198/198 [00:06<00:00, 30.05it/s]\n",
      "Running inference: 100%|██████████| 197/197 [00:06<00:00, 30.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: {'precision': 0.719796954312285, 'recall': 0.6669802445886893, 'f1': 0.6923828075049989, 'auc': 0.7874017029662503, 'prauc': 0.8016448235050165}\n",
      "Test:      {'precision': 0.7283316204154563, 'recall': 0.6666666666645762, 'f1': 0.6961362098077528, 'auc': 0.782187666572543, 'prauc': 0.7998410695232843}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 004: 100%|██████████| 98/98 [00:04<00:00, 20.01it/s, loss=0.5252]\n",
      "Running inference: 100%|██████████| 198/198 [00:06<00:00, 30.12it/s]\n",
      "Running inference: 100%|██████████| 197/197 [00:06<00:00, 30.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: {'precision': 0.7357609710527988, 'recall': 0.741298212603508, 'f1': 0.7385192077437802, 'auc': 0.8128826472045396, 'prauc': 0.8204254042109329}\n",
      "Test:      {'precision': 0.733690513707111, 'recall': 0.7300094073354343, 'f1': 0.7318453266544428, 'auc': 0.8106458446898372, 'prauc': 0.8216496869119558}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 005: 100%|██████████| 98/98 [00:04<00:00, 19.95it/s, loss=0.5040]\n",
      "Running inference: 100%|██████████| 198/198 [00:06<00:00, 30.25it/s]\n",
      "Running inference: 100%|██████████| 197/197 [00:06<00:00, 30.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: {'precision': 0.6911452810161953, 'recall': 0.8174976481630056, 'f1': 0.7490303067697397, 'auc': 0.8110522704558856, 'prauc': 0.8199483307430184}\n",
      "Test:      {'precision': 0.6817944705250867, 'recall': 0.8196926936317978, 'f1': 0.7444112153162893, 'auc': 0.8066211752175793, 'prauc': 0.8198271327749029}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 006: 100%|██████████| 98/98 [00:04<00:00, 20.06it/s, loss=0.5030]\n",
      "Running inference: 100%|██████████| 198/198 [00:06<00:00, 29.16it/s]\n",
      "Running inference: 100%|██████████| 197/197 [00:06<00:00, 30.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: {'precision': 0.7532765399713196, 'recall': 0.7209156475361527, 'f1': 0.7367409019059932, 'auc': 0.8161711964660643, 'prauc': 0.8266092177337715}\n",
      "Test:      {'precision': 0.7406564835855033, 'recall': 0.7146440890538895, 'f1': 0.727417805404638, 'auc': 0.8074593795787789, 'prauc': 0.8193239787055301}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 007: 100%|██████████| 98/98 [00:04<00:00, 19.72it/s, loss=0.4751]\n",
      "Running inference: 100%|██████████| 198/198 [00:06<00:00, 29.78it/s]\n",
      "Running inference: 100%|██████████| 197/197 [00:06<00:00, 30.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: {'precision': 0.6794871794854017, 'recall': 0.8143618689218741, 'f1': 0.7408358244495709, 'auc': 0.8037845168061593, 'prauc': 0.813844350130712}\n",
      "Test:      {'precision': 0.6770670826815469, 'recall': 0.8165569143906662, 'f1': 0.7402985025041907, 'auc': 0.8038186543128037, 'prauc': 0.8171942567894872}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 008: 100%|██████████| 98/98 [00:04<00:00, 19.96it/s, loss=0.4707]\n",
      "Running inference: 100%|██████████| 198/198 [00:06<00:00, 30.45it/s]\n",
      "Running inference: 100%|██████████| 197/197 [00:06<00:00, 30.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: {'precision': 0.7588436667905711, 'recall': 0.6255879586057523, 'f1': 0.6858026763777575, 'auc': 0.7877571783573158, 'prauc': 0.7930408223073032}\n",
      "Test:      {'precision': 0.7593144560329385, 'recall': 0.6390718093426182, 'f1': 0.694023492395409, 'auc': 0.7916005913183711, 'prauc': 0.7962041183655018}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 009: 100%|██████████| 98/98 [00:04<00:00, 20.27it/s, loss=0.4602]\n",
      "Running inference: 100%|██████████| 198/198 [00:06<00:00, 30.26it/s]\n",
      "Running inference: 100%|██████████| 197/197 [00:06<00:00, 29.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: {'precision': 0.8105263157857642, 'recall': 0.5553465036044047, 'f1': 0.6590993624962193, 'auc': 0.7974828664980922, 'prauc': 0.8079373475027378}\n",
      "Test:      {'precision': 0.8042991491231335, 'recall': 0.5631859517072336, 'f1': 0.6624861626188776, 'auc': 0.7940303420616717, 'prauc': 0.8059432214726796}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 010: 100%|██████████| 98/98 [00:04<00:00, 19.89it/s, loss=0.4453]\n",
      "Running inference: 100%|██████████| 198/198 [00:06<00:00, 30.38it/s]\n",
      "Running inference: 100%|██████████| 197/197 [00:06<00:00, 28.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: {'precision': 0.7310847766614066, 'recall': 0.7544684854162607, 'f1': 0.7425925875915396, 'auc': 0.8160846385097603, 'prauc': 0.8290326045532767}\n",
      "Test:      {'precision': 0.7289864029643728, 'recall': 0.7397303229829423, 'f1': 0.7343190611458417, 'auc': 0.8076457646595163, 'prauc': 0.818046859238786}\n",
      "\n",
      "Early stopping triggered (no improvement for 5 epochs).\n",
      "\n",
      "Best validation performance:\n",
      "{'precision': 0.6911452810161953, 'recall': 0.8174976481630056, 'f1': 0.7490303067697397, 'auc': 0.8110522704558856, 'prauc': 0.8199483307430184}\n",
      "Corresponding test performance:\n",
      "{'precision': 0.6817944705250867, 'recall': 0.8196926936317978, 'f1': 0.7444112153162893, 'auc': 0.8066211752175793, 'prauc': 0.8198271327749029}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 001: 100%|██████████| 98/98 [00:04<00:00, 20.27it/s, loss=0.7485]\n",
      "Running inference: 100%|██████████| 198/198 [00:06<00:00, 30.16it/s]\n",
      "Running inference: 100%|██████████| 197/197 [00:06<00:00, 30.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: {'precision': 0.76514834934908, 'recall': 0.5741611790511942, 'f1': 0.6560372577292068, 'auc': 0.7748765205289048, 'prauc': 0.7749982414850667}\n",
      "Test:      {'precision': 0.747944078944293, 'recall': 0.5703982439618364, 'f1': 0.6472157929891116, 'auc': 0.7644877782626575, 'prauc': 0.7587338176538708}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 002: 100%|██████████| 98/98 [00:04<00:00, 20.22it/s, loss=0.5965]\n",
      "Running inference: 100%|██████████| 198/198 [00:06<00:00, 29.79it/s]\n",
      "Running inference: 100%|██████████| 197/197 [00:06<00:00, 29.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: {'precision': 0.5854276251693251, 'recall': 0.942301661960043, 'f1': 0.7221821630192413, 'auc': 0.791170666468131, 'prauc': 0.7963961573699322}\n",
      "Test:      {'precision': 0.5824006175210683, 'recall': 0.9463781749735141, 'f1': 0.7210608004423706, 'auc': 0.7849814797757337, 'prauc': 0.7932156341094508}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 003: 100%|██████████| 98/98 [00:04<00:00, 20.31it/s, loss=0.5397]\n",
      "Running inference: 100%|██████████| 198/198 [00:06<00:00, 30.32it/s]\n",
      "Running inference: 100%|██████████| 197/197 [00:06<00:00, 30.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: {'precision': 0.8218048556993962, 'recall': 0.5625587958590074, 'f1': 0.6679076645697313, 'auc': 0.816120356853888, 'prauc': 0.8280217400554739}\n",
      "Test:      {'precision': 0.8137122237220852, 'recall': 0.565694575100139, 'f1': 0.6674065804347912, 'auc': 0.8146573267758803, 'prauc': 0.8277219427680614}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 004: 100%|██████████| 98/98 [00:04<00:00, 20.09it/s, loss=0.5255]\n",
      "Running inference: 100%|██████████| 198/198 [00:06<00:00, 30.43it/s]\n",
      "Running inference: 100%|██████████| 197/197 [00:06<00:00, 28.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: {'precision': 0.7786005183236632, 'recall': 0.6594543744099736, 'f1': 0.7140916758468385, 'auc': 0.8165358149494383, 'prauc': 0.8302396079049714}\n",
      "Test:      {'precision': 0.7677208287867404, 'recall': 0.662276575726992, 'f1': 0.7111111061359029, 'auc': 0.8123657919201589, 'prauc': 0.827755936376541}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 005: 100%|██████████| 98/98 [00:04<00:00, 19.87it/s, loss=0.5076]\n",
      "Running inference: 100%|██████████| 198/198 [00:06<00:00, 29.83it/s]\n",
      "Running inference: 100%|██████████| 197/197 [00:06<00:00, 30.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: {'precision': 0.7750472589762758, 'recall': 0.6428347444319761, 'f1': 0.7027768205467217, 'auc': 0.8101328873111864, 'prauc': 0.8209326004718152}\n",
      "Test:      {'precision': 0.767732451301846, 'recall': 0.6550642834723893, 'f1': 0.7069373892760002, 'auc': 0.8099404201944183, 'prauc': 0.8226191182604862}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 006: 100%|██████████| 98/98 [00:04<00:00, 20.08it/s, loss=0.4837]\n",
      "Running inference: 100%|██████████| 198/198 [00:06<00:00, 30.29it/s]\n",
      "Running inference: 100%|██████████| 197/197 [00:06<00:00, 30.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: {'precision': 0.768987341769448, 'recall': 0.6857949200354789, 'f1': 0.7250124266400042, 'auc': 0.8183729234253962, 'prauc': 0.830218475953222}\n",
      "Test:      {'precision': 0.7640138408278062, 'recall': 0.6923800564418552, 'f1': 0.7264352639684165, 'auc': 0.8137512728092706, 'prauc': 0.8257502808014939}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 007: 100%|██████████| 98/98 [00:04<00:00, 19.73it/s, loss=0.4428]\n",
      "Running inference: 100%|██████████| 198/198 [00:06<00:00, 30.97it/s]\n",
      "Running inference: 100%|██████████| 197/197 [00:06<00:00, 30.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: {'precision': 0.7898443291297634, 'recall': 0.668234556285142, 'f1': 0.7239680602607913, 'auc': 0.8247935344070138, 'prauc': 0.8339251357118654}\n",
      "Test:      {'precision': 0.7864678064722209, 'recall': 0.6779554719326499, 'f1': 0.7281913052304573, 'auc': 0.8248308415716747, 'prauc': 0.83777202290887}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 008: 100%|██████████| 98/98 [00:04<00:00, 19.75it/s, loss=0.4596]\n",
      "Running inference: 100%|██████████| 198/198 [00:06<00:00, 30.92it/s]\n",
      "Running inference: 100%|██████████| 197/197 [00:06<00:00, 29.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: {'precision': 0.7308399754729281, 'recall': 0.7475697710857712, 'f1': 0.7391102104688184, 'auc': 0.8171173055728956, 'prauc': 0.8292420860355559}\n",
      "Test:      {'precision': 0.7252848783470117, 'recall': 0.7384760112864895, 'f1': 0.7318210018346764, 'auc': 0.814665178807367, 'prauc': 0.8300846581324819}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 009: 100%|██████████| 98/98 [00:04<00:00, 19.96it/s, loss=0.4242]\n",
      "Running inference: 100%|██████████| 198/198 [00:06<00:00, 31.09it/s]\n",
      "Running inference: 100%|██████████| 197/197 [00:06<00:00, 30.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: {'precision': 0.7645400070470055, 'recall': 0.6801505174014421, 'f1': 0.7198805127710606, 'auc': 0.8174183243042785, 'prauc': 0.8283192228013387}\n",
      "Test:      {'precision': 0.7692852087729325, 'recall': 0.6817184070220078, 'f1': 0.7228595128877933, 'auc': 0.8200410520312853, 'prauc': 0.8322301488692259}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 010: 100%|██████████| 98/98 [00:04<00:00, 19.86it/s, loss=0.4062]\n",
      "Running inference: 100%|██████████| 198/198 [00:06<00:00, 30.56it/s]\n",
      "Running inference: 100%|██████████| 197/197 [00:06<00:00, 31.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: {'precision': 0.7112056737568476, 'recall': 0.7861398557516898, 'f1': 0.7467977310841732, 'auc': 0.8200933821192663, 'prauc': 0.8267716335549709}\n",
      "Test:      {'precision': 0.7113980909581376, 'recall': 0.794606459702745, 'f1': 0.7507035944797852, 'auc': 0.8198879877508309, 'prauc': 0.8270606267631656}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 011: 100%|██████████| 98/98 [00:04<00:00, 20.00it/s, loss=0.3901]\n",
      "Running inference: 100%|██████████| 198/198 [00:06<00:00, 30.63it/s]\n",
      "Running inference: 100%|██████████| 197/197 [00:06<00:00, 30.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: {'precision': 0.6822311963637501, 'recall': 0.847601128877869, 'f1': 0.7559781799255595, 'auc': 0.8212537008173222, 'prauc': 0.8283912146241508}\n",
      "Test:      {'precision': 0.6725334655412183, 'recall': 0.8507369081190005, 'f1': 0.7512114030685654, 'auc': 0.8149012430873182, 'prauc': 0.8223898638697256}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 012: 100%|██████████| 98/98 [00:04<00:00, 20.29it/s, loss=0.3641]\n",
      "Running inference: 100%|██████████| 198/198 [00:06<00:00, 30.51it/s]\n",
      "Running inference: 100%|██████████| 197/197 [00:06<00:00, 30.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: {'precision': 0.7324212535770525, 'recall': 0.7218563813084922, 'f1': 0.7271004371963249, 'auc': 0.8110979356806565, 'prauc': 0.8188666735499972}\n",
      "Test:      {'precision': 0.7289482046370227, 'recall': 0.7193477579155869, 'f1': 0.7241161566140957, 'auc': 0.8081168362151798, 'prauc': 0.816049999066244}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 013: 100%|██████████| 98/98 [00:05<00:00, 18.73it/s, loss=0.3244]\n",
      "Running inference:  34%|███▍      | 68/198 [00:02<00:04, 31.60it/s]"
     ]
    }
   ],
   "source": [
    "final_metrics = []\n",
    "for i in range(10):\n",
    "    model = HeteroGT(tokenizer, d_model=128, num_heads=4, layer_types=['gnn', 'tf', 'tf'], max_num_adms=config.max_num_adms, \n",
    "                     device=device, task=curr_task, label_vocab_size=config.label_vocab_size, attn_mask_dicts=attn_mask_dicts,\n",
    "                     use_cls_cat=True).to(device)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=config.lr)\n",
    "    best_test_metric = train_with_early_stopping(model, train_dataloader, val_dataloader, test_dataloader,\n",
    "                                             optimizer, loss_fn, device, config.early_stop_patience, task_type, config.epochs, \n",
    "                                             val_long_seq_idx=None, test_long_seq_idx=None, eval_metric=eval_metric, return_model=False)\n",
    "    final_metrics.append(best_test_metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b5b571",
   "metadata": {},
   "outputs": [],
   "source": [
    "def topk_avg_performance_formatted(performances, k=5) -> str:\n",
    "    metrics = [\"f1\", \"auc\", \"prauc\"]\n",
    "    scores = {m: np.array([p[m] for p in performances]) for m in metrics}\n",
    "\n",
    "    # 计算排名（值越大排名越靠前）\n",
    "    ranks = {m: (-scores[m]).argsort().argsort() + 1 for m in metrics}\n",
    "    avg_ranks = np.mean(np.stack([ranks[m] for m in metrics], axis=1), axis=1)\n",
    "\n",
    "    # 选 top-k\n",
    "    topk_idx = np.argsort(avg_ranks)[:k]\n",
    "    final_avg = {m: np.mean([performances[i][m] for i in topk_idx]) for m in performances[0].keys()}\n",
    "    final_std = {m: np.std([performances[i][m] for i in topk_idx], ddof=0) for m in performances[0].keys()}\n",
    "\n",
    "    # 打印结果\n",
    "    lines = [\"Final Metrics:\"]\n",
    "    for m in performances[0].keys():\n",
    "        lines.append(f\"{m}: {final_avg[m]:.4f} ± {final_std[m]:.4f}\")\n",
    "    \n",
    "    return \"\\n\".join(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12dd11d-4936-466a-9a97-e10f223539fc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Metrics:\n",
      "precision: 0.7005 ± 0.0151\n",
      "recall: 0.8074 ± 0.0305\n",
      "f1: 0.7495 ± 0.0070\n",
      "auc: 0.8158 ± 0.0022\n",
      "prauc: 0.8257 ± 0.0029\n"
     ]
    }
   ],
   "source": [
    "topk_avg_performance_formatted(final_metrics, 5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
